{
  "base_url": "https://python.langchain.com/docs/introduction/",
  "total_pages": 2,
  "crawl_timestamp": "2025-08-24 15:46:08",
  "pages": [
    {
      "url": "https://python.langchain.com/docs/introduction/",
      "title": "Introduction | ü¶úÔ∏èüîó LangChain",
      "content": "Introduction | ü¶úÔ∏èüîó LangChain Skip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.On this page LangChain is a framework for developing applications powered by large language models (LLMs). LangChain simplifies every stage of the LLM application lifecycle: Development: Build your applications using LangChain's open-source components and third-party integrations. Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support. Productionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence. Deployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform. LangChain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers. See the integrations page for more. Select chat model:Google Gemini‚ñæOpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexityDeepSeekpip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"): os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelmodel = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\") model.invoke(\"Hello, world!\") noteThese docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library. Architecture‚Äã The LangChain framework consists of multiple open-source libraries. Read more in the Architecture page. langchain-core: Base abstractions for chat models and other components. Integration packages (e.g. langchain-openai, langchain-anthropic, etc.): Important integrations have been split into lightweight packages that are co-maintained by the LangChain team and the integration developers. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. langchain-community: Third-party integrations that are community maintained. langgraph: Orchestration framework for combining LangChain components into production-ready applications with persistence, streaming, and other key features. See LangGraph documentation. Guides‚Äã Tutorials‚Äã If you're looking to build something specific or are more of a hands-on learner, check out our tutorials section. This is the best place to get started. These are the best ones to get started with: Build a Simple LLM Application Build a Chatbot Build an Agent Introduction to LangGraph Explore the full list of LangChain tutorials here, and check out other LangGraph tutorials here. To learn more about LangGraph, check out our first LangChain Academy course, Introduction to LangGraph, available here. How-to guides‚Äã Here you‚Äôll find short answers to ‚ÄúHow do I‚Ä¶.?‚Äù types of questions. These how-to guides don‚Äôt cover topics in depth ‚Äì you‚Äôll find that material in the Tutorials and the API Reference. However, these guides will help you quickly accomplish common tasks using chat models, vector stores, and other common LangChain components. Check out LangGraph-specific how-tos here. Conceptual guide‚Äã Introductions to all the key parts of LangChain you‚Äôll need to know! Here you'll find high level explanations of all LangChain concepts. For a deeper dive into LangGraph concepts, check out this page. Integrations‚Äã LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. If you're looking to get up and running quickly with chat models, vector stores, or other LangChain components from a specific provider, check out our growing list of integrations. API reference‚Äã Head to the reference section for full documentation of all classes and methods in the LangChain Python packages. Ecosystem‚Äã ü¶úüõ†Ô∏è LangSmith‚Äã Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. ü¶úüï∏Ô∏è LangGraph‚Äã Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by Linkedin, Uber, Klarna, GitLab, and many more. Additional resources‚Äã Versions‚Äã See what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more. Security‚Äã Read up on security best practices to make sure you're developing safely with LangChain. Contributing‚Äã Check out the developer's guide for guidelines on contributing and help getting your dev environment set up.ArchitectureGuidesTutorialsHow-to guidesConceptual guideIntegrationsAPI referenceEcosystemü¶úüõ†Ô∏è LangSmithü¶úüï∏Ô∏è LangGraphAdditional resourcesVersionsSecurityContributing",
      "timestamp": "2025-08-24 15:46:01"
    },
    {
      "url": "https://python.langchain.com/docs/tutorials/",
      "title": "Tutorials | ü¶úÔ∏èüîó LangChain",
      "content": "Tutorials | ü¶úÔ∏èüîó LangChain Skip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.On this page New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications. Get started‚Äã Familiarize yourself with LangChain's open-source components by building simple applications. If you're looking to get started with chat models, vector stores, or other LangChain components from a specific provider, check out our supported integrations. Chat models and prompts: Build a simple LLM application with prompt templates and chat models. Semantic search: Build a semantic search engine over a PDF with document loaders, embedding models, and vector stores. Classification: Classify text into categories or labels using chat models with structured outputs. Extraction: Extract structured data from text and other unstructured media using chat models and few-shot examples. Refer to the how-to guides for more detail on using all LangChain components. Orchestration‚Äã Get started using LangGraph to assemble LangChain components into full-featured applications. Chatbots: Build a chatbot that incorporates memory. Agents: Build an agent that interacts with external tools. Retrieval Augmented Generation (RAG) Part 1: Build an application that uses your own documents to inform its responses. Retrieval Augmented Generation (RAG) Part 2: Build a RAG application that incorporates a memory of its user interactions and multi-step retrieval. Question-Answering with SQL: Build a question-answering system that executes SQL queries to inform its responses. Summarization: Generate summaries of (potentially long) texts. Question-Answering with Graph Databases: Build a question-answering system that queries a graph database to inform its responses. LangSmith‚Äã LangSmith allows you to closely trace, monitor and evaluate your LLM application. It seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your chains as you build. LangSmith documentation is hosted on a separate site. You can peruse LangSmith tutorials here. Evaluation‚Äã LangSmith helps you evaluate the performance of your LLM applications. The tutorial below is a great way to get started: Evaluate your LLM application Get startedOrchestrationLangSmithEvaluation",
      "timestamp": "2025-08-24 15:46:05"
    }
  ],
  "sitemap": null
}