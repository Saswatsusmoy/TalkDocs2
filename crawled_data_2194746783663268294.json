{
  "base_url": "https://docs.portialabs.ai/",
  "total_pages": 239,
  "crawl_timestamp": "2025-08-24 06:58:48",
  "pages": [
    {
      "url": "https://docs.portialabs.ai/streams-results",
      "title": "Visualise Stream results | Portia AI Docs",
      "content": "Visualise Stream results | Portia AI Docs Skip to main content Stream metrics are pushed to the Portia dashboard. Clicking on any stream will show the latest metrics for it grouped by the time of run to show you the performance of the stream over time. You can also drill down into the analysis by clicking on any row in the table to see a detailed breakdown of the individual plan or plan runs that were processed. Finally clicking on an individual plan or plan run will show all the specific metrics for that plan run allowing you to see the explanation for scores.",
      "timestamp": "2025-08-24 06:46:48"
    },
    {
      "url": "https://docs.portialabs.ai/clarifications-in-tools",
      "title": "Use clarifications in custom tools | Portia AI Docs",
      "content": "Use clarifications in custom tools | Portia AI Docs Skip to main contentOn this page TL;DRYou can raise a Clarification in any custom tool definition to prompt a plan run to interrupt itself and solicit input (SDK reference ↗). Add a clarification to your custom tool​ Let's pick up the custom tool example we looked at previously (Add custom tools ↗). We will now examine the code that defines a clarification in a tool explicitly. We're going to add a clarification to the FileReaderTool custom tool to handle cases where a file is not found. Instead of throwing an error directly, we will attempt to find the file in other folders in the project directory. We do that by adding the highlighted lines in the FileReaderTool class definition as shown below. my_custom_tools/file_reader_tool.pyfrom pathlib import Pathimport pandas as pdimport jsonfrom pydantic import BaseModel, Fieldfrom portia import ( MultipleChoiceClarification, Tool, ToolHardError, ToolRunContext,)class FileReaderToolSchema(BaseModel): \"\"\"Schema defining the inputs for the FileReaderTool.\"\"\" filename: str = Field(..., description=\"The location where the file should be read from\", )class FileReaderTool(Tool[str]): \"\"\"Finds and reads content from a local file on Disk.\"\"\" id: str = \"file_reader_tool\" name: str = \"File reader tool\" description: str = \"Finds and reads content from a local file on Disk\" args_schema: type[BaseModel] = FileReaderToolSchema output_schema: tuple[str, str] = (\"str\", \"A string dump or JSON of the file content\") def run(self, ctx: ToolRunContext, filename: str) -> str | dict[str,any] | MultipleChoiceClarification: \"\"\"Run the FileReaderTool.\"\"\" file_path = Path(filename) suffix = file_path.suffix.lower() if file_path.is_file(): if suffix == '.csv': return pd.read_csv(file_path).to_string() elif suffix == '.json': with file_path.open('r', encoding='utf-8') as json_file: data = json.load(json_file) return data elif suffix in ['.xls', '.xlsx']: return pd.read_excel(file_path).to_string elif suffix in ['.txt', '.log']: return file_path.read_text(encoding=\"utf-8\") else: raise ToolHardError(f\"Unsupported file format: {suffix}. Supported formats are .txt, .log, .csv, .json, .xls, .xlsx.\") alt_file_paths = self.find_file(filename) if alt_file_paths: return MultipleChoiceClarification( plan_run_id=ctx.plan_run.id, argument_name=\"filename\", user_guidance=f\"Found {filename} in these location(s). Pick one to continue:\\n{alt_file_paths}\", options=alt_file_paths, ) raise ToolHardError(f\"No file found on disk with the path {filename}.\") def find_file(self, filename: str) -> list[Path]: \"\"\"Returns a full file path or None.\"\"\" search_path = Path(\"../\") filepaths = [] for filepath in search_path.rglob(filename): if filepath.is_file(): filepaths.append(str(filepath)) if filepaths: return filepaths return None The block below results in the tool using the find_file method to look for alternative locations and raising this clarification if multiple paths are found in the project directory. Here we're using MultipleChoiceClarification specifically, which takes a options property where the paths found are enumerated. You can explore the other types a Clarification object can take in our documentation (SDK reference ↗). alt_file_paths = self.find_file(filename)if alt_file_paths: return MultipleChoiceClarification( plan_run_id=ctx.plan_run.id, argument_name=\"filename\", user_guidance=f\"Found {filename} in these location(s). Pick one to continue:\\n{alt_file_paths}\", options=alt_file_paths, ) Testing your tool with clarifications​ We're now ready to put our clarification to the test. We won't revisit how clarifications work and are handled in detail here, For that you can check out the section dedicated to clarifications (Understand clarifications↗). Make a weather.txt file for this sectionIn this example, our custom tool FileReaderTool will attempt to open a non-existent local file weather.txt. This should trigger the tool to search for the file across the rest of the project directory and return all matches. Make sure to sprinkle a few copies of a weather.txt file around in the project directory. Note: Our weather.txt file contains \"The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.\" main.pyfrom portia import Portiafrom portia.config import default_configfrom portia.open_source_tools.registry import example_tool_registryfrom my_custom_tools.registry import custom_tool_registryfrom portia.clarification import MultipleChoiceClarificationfrom portia.plan_run import PlanRunState# Load example and custom tool registries into a single onecomplete_tool_registry = example_tool_registry + custom_tool_registry# Instantiate a Portia instance. Load it with the default config and with the tools aboveportia = Portia(tools=complete_tool_registry)# Execute the plan from the user queryplan_run = portia.run('Read the contents of the file \"weather.txt\".')# Check if the plan run was paused due to raised clarificationswhile plan_run.state == PlanRunState.NEED_CLARIFICATION: # If clarifications are needed, resolve them before resuming the plan run for clarification in plan_run.get_outstanding_clarifications(): # For each clarification, prompt the user for input print(f\"{clarification.user_guidance}\") user_input = input(\"Please enter a value:\\n\" + ((\"\\n\".join(clarification.options) + \"\\n\") if \"options\" in clarification else \"\")) # Resolve the clarification with the user input plan_run = portia.resolve_clarification(clarification, user_input, plan_run) # Once clarifications are resolved, resume the plan run plan_run = portia.resume(plan_run)# Serialise into JSON and print the outputprint(plan_run.model_dump_json(indent=2)) For the example query above Read the contents of the file \"weather.txt\"., where the user resolves the clarification by entering one of the options offered by the clarification (in this particular case demo_runs/weather.txt in our project directory momo_sdk_tests), you should see the following plan run state and notice: The multiple choice clarification where the user_guidance was generated by Portia based on your clarification definition in the FileReaderTool class, The response in the second plan run snapshot reflecting the user input, and the change in resolved to true as a result The plan run state will appear to NEED_CLARIFICATION if you look at the logs at the point when the clarification is raised. It then progresses to COMPLETE once you respond to the clarification and the plan run is able to resume: run_state.json{ \"id\": \"prun-54d157fe-4b99-4dbb-a917-8fd8852df63d\", \"plan_id\": \"plan-b87de5ac-41d9-4722-8baa-8015327511db\", \"current_step_index\": 0, \"state\": \"COMPLETE\", \"outputs\": { \"clarifications\": [ { \"id\": \"clar-216c13a1-8342-41ca-99e5-59394cbc7008\", \"category\": \"Multiple Choice\", \"response\": \"../momo_sdk_tests/demo_runs/weather.txt\", \"step\": 0, \"user_guidance\": \"Found weather.txt in these location(s). Pick one to continue:\\n['../momo_sdk_tests/demo_runs/weather.txt', '../momo_sdk_tests/my_custom_tools/__pycache__/weather.txt']\", \"resolved\": true, \"argument_name\": \"filename\", \"options\": [ \"../momo_sdk_tests/demo_runs/weather.txt\", \"../momo_sdk_tests/my_custom_tools/__pycache__/weather.txt\" ] } ], \"step_outputs\": { \"$file_contents\": { \"value\": \"The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.\", \"summary\": null } }, \"final_output\": { \"value\": \"The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.\", \"summary\": null } }} Accessing clarifications in your custom tool​ The above example showed how you can access a clarification in your custom tool when it relates directly to the tool's arguments. If however you wanted to access a clarification from your tool that is not related to the tool's arguments, you can do so by using the ToolRunContext object that is passed to the run method of your tool. from portia import ToolRunContext, MultipleChoiceClarificationdef run(self, ctx: ToolRunContext, filename: str) -> str | dict[str,any] | MultipleChoiceClarification: \"\"\"Run the FileReaderTool.\"\"\" clarifications = ctx.clarifications This allows you to return more complex clarifications from your tool and access them once they have been resolved by the user.Add a clarification to your custom toolTesting your tool with clarificationsAccessing clarifications in your custom tool",
      "timestamp": "2025-08-24 06:46:51"
    },
    {
      "url": "https://docs.portialabs.ai/build-plan",
      "title": "Build a plan manually | Portia AI Docs",
      "content": "Build a plan manually | Portia AI Docs Skip to main contentOn this page AlphaPlanBuilderV2 is currently in Alpha so please expect changes in this area and we'd love your feedback on our Discord channel (↗)! If you prefer to explicitly define a plan step by step rather than rely on our planning agent, e.g. for established processes in your business, you can use the PlanBuilderV2 interface. This requires outlining all the steps, inputs, outputs and tools for your agent manually. The PlanBuilderV2 offers methods to create each part of the plan iteratively: .llm_step() adds a step that sends a query to the underlying LLM .invoke_tool_step() adds a step that directly invokes a tool. Requires mapping of step outputs to tool arguments. .single_tool_agent_step() is similar to .invoke_tool_step() but an LLM call is made to map the inputs to the step to what the tool requires creating flexibility. .function_step() is identical to .invoke_tool_step() but calls a Python function rather than a tool with an ID. .if_(), .else_if_(), .else_() and .endif() are used to add conditional branching to the plan. Example​ plan_builder.pyfrom portia import PlanBuilderV2, StepOutput, Inputplan = ( PlanBuilderV2(\"Write a poem about the price of gold\") .input(name=\"purchase_quantity\", description=\"The quantity of gold to purchase in ounces\") .input(name=\"currency\", description=\"The currency to purchase the gold in\", default_value=\"GBP\") .invoke_tool_step( step_name=\"Search gold price\", tool=\"search_tool\", args={ \"search_query\": f\"What is the price of gold per ounce in {Input('currency')}?\", }, output_schema=CommodityPriceWithCurrency, ) .function_step( function=lambda price_with_currency, purchase_quantity: ( price_with_currency.price * purchase_quantity ), args={ \"price_with_currency\": StepOutput(\"Search gold price\"), \"purchase_quantity\": Input(\"purchase_quantity\"), }, ) .llm_step( task=\"Write a poem about the current price of gold\", inputs=[StepOutput(0), Input(\"currency\")], ) .single_tool_agent_step( task=\"Send the poem to Robbie in an email at donotemail@portialabs.ai\", tool=\"portia:google:gmail:send_email\", inputs=[StepOutput(2)], ) .final_output( output_schema=FinalOutput, ) .build())portia.run_plan(plan, plan_run_inputs={\"purchase_quantity\": 100, \"currency\": \"GBP\"}) Available Step Types​ LLM step​ Use .llm_step() to add a step that directly queries the LLM tool: builder.llm_step( task=\"Analyze the given data and provide insights\", inputs=[StepOutput(\"previous_step\")], output_schema=AnalysisResult, name=\"analyze_data\") The output_schema is a Pydantic model that is used for the structured output. Invoke Tool step​ Use .invoke_tool_step() to add a step that directly invokes a tool: builder.invoke_tool_step( tool=\"portia:tavily::search\", args={\"query\": \"latest news about AI\"}, name=\"search_news\") Function step​ Use .function_step() to add a step that calls a function. This is useful for manipulating data from other steps using code, streaming updates on the plan as it is run or adding in guardrails. def process_data(data): return {\"processed\": data.upper()}builder.function_step( function=process_data, args={\"data\": StepOutput(0)}, name=\"process_raw_data\") Single Tool Agent step​ Use .single_tool_agent_step() to add a step that calls a tool using arguments that are worked out dynamically from the inputs: builder.single_tool_agent_step( tool=\"web_scraper\", task=\"Extract key information from the webpage provided\", inputs=[StepOutput(\"text_blob_with_url\")], name=\"scrape_webpage\") Conditionals​ Use .if_() to start a conditional block for advanced control flow: ( builder .if_( condition=lambda web_page: len(web_page) > 100_000, args={ \"web_page\": StepOutput(\"scrape_webpage\") } ) .llm_step( task=\"Summarise the web page\", inputs=[StepOutput(\"scrape_webpage\")], name=\"summarise_webpage\" ) .endif()) if_() takes a predicate (named condition), which can either be a function, or a natural language string. If it is a function, then the function will be run to return a boolean indicating whether the condition passed. If it is a natural language string, then an LLM will be used to determine whether the string is true or false. args is a dictionary of arguments to pass to the predicate. Like other step types, you can pass references or values (see the Inputs and Outputs section below for more details). Also note that you need to add an endif() at the end of the flow to indicate the end of the conditional branch. Alternative branches can be added to the conditional block using .else_if_() and .else_(): ( builder .if_( condition=lambda web_page: len(web_page) > 100_000, args={ \"web_page\": StepOutput(\"scrape_webpage\") } ) # ... .else_if_( condition=lambda web_page: len(web_page) < 100, args={ \"web_page\": StepOutput(\"scrape_webpage\") } ) .function_step( function=lambda: raise_exception(\"Web page is too short\"), ) .else_() .function_step( function=lambda: print(\"All good!\"), ) .endif()) As mentioned, the condition can be a natural language string. Just write a statement that can be evaluated to true or false and pass the relevant context via the args. ( builder .if_( condition=\"The web page is about large cats\", args={ \"web_page\": StepOutput(\"scrape_webpage\") } )) Conditional blocks can be nested to create even more complex control flow! ( builder .if_( condition=lambda web_page: len(web_page) > 100_000, args={ \"web_page\": StepOutput(\"scrape_webpage\") } ) # Nested conditional block .if_( condition=lambda web_page: len(web_page) > 1_000_000, args={ \"web_page\": StepOutput(\"scrape_webpage\") } ) .function_step( function=lambda: raise_exception(\"Web page is too long\"), ) .endif() # ... back to the outer conditional block) Inputs and Outputs​ Adding Plan Inputs​ Use .input() to define inputs that the plan expects: builder.input( name=\"user_query\", description=\"The user's question or request\") You can also provide the default value for the input, e.g builder.input( name=\"user_query\", description=\"The user's question or request\" # Default values can be overriden in plan_run_inputs but will be used as the fallback. default_value=\"What is the capital of France?\") You can dynamically add the value of the plan at run time, e.g portia.run_plan(plan, plan_run_inputs={\"user_query\": \"What is the capital of Peru?\"}) Referencing Step Outputs​ You can reference outputs from previous steps using StepOutput: from portia import StepOutputbuilder.invoke_tool_step( tool=\"calculator\", args={\"expression\": f\"This is some string {StepOutput(\"previous_step\")} interpolation\"}) You can also reference previous step outputs using their index: from portia import StepOutputbuilder.invoke_tool_step( tool=\"calculator\", args={\"expression\": StepOutput(1)\"}) NoteThe index of a step is the order in which it was added to the plan.Conditional clauses (.if_(), .else_if_(), .else_() and .endif()) are counted as steps and do have an index. Steps within a conditional branch are also counted - the step index is the order the steps appear in the plan, not the runtime index. Final Output Configuration​ Use .final_output() to configure the final output: plan = builder.final_output( output_schema=FinalResult, summarize=True).build()plan_run = portia.run(plan)# Will match `FinalResult` schemafinal_output_value = plan_run.outputs.final_output.value# Provides a succinct summary of the outputs (calls LLM to populate)final_output_summary = plan_run.outputs.final_output.summary Building the Plan​ Once you've defined all your steps, call .build() to create the final plan: plan = builder.build() The returned PlanV2 object is ready to be executed with your Portia instance. [DEPRECATED] Build a plan manually​ Deprecation warningThere is an older form of the plan builder described below which is still functional in the SDK but over time we will be replacing it will PlanBuilderV2. If you prefer to explicitly define a plan step by step rather than rely our planning agent, e.g. for established processes in your business, you can use the PlanBuilder interface. This obviously implies outlining all the steps, inputs, outputs and tools. The PlanBuilder offers methods to create each part of the plan iteratively .step method adds a step to the end of the plan. It takes a task, tool_id and output name as arguments. .input and .condition methods add to the last step added, but can be overwritten with a step_index variable, and map outputs from one step to inputs of chosen (default last step), or considerations .build finally builds the Plan objective plan_builder.pyfrom portia.plan import PlanBuilderquery = \"What is the capital of france and what is the population of the city? If the city has a population of over 1 million, then find the mayor of the city.\"plan = PlanBuilder( query # optional to provide, as the steps are built below, but provides context for storage and plan purpose).step( task=\"Find the capital of france\", # step task tool_id=\"google_search\", # tool id maps to a tool in the tool registry output=\"$capital_of_france\", # output variable name maps step output to variable).step( task=\"Find the population of the capital of france\", tool_id=\"google_search\", output=\"$population_of_capital\",).input( # add an input to step 2 name=\"$capital_of_france\", # input variable name maps to a variable in the plan run outputs from step 1 description=\"Capital of france\" # optional description for the variable).step( task=\"Find the mayor of the city\", tool_id=\"google_search\", output=\"$mayor_of_city\",).condition( condition=\"$population_of_capital > 1000000\", # adding a condition to the step).build() # build the plan once finalizedExampleAvailable Step TypesLLM stepInvoke Tool stepFunction stepSingle Tool Agent stepConditionalsInputs and OutputsAdding Plan InputsReferencing Step OutputsFinal Output ConfigurationBuilding the Plan[DEPRECATED] Build a plan manually",
      "timestamp": "2025-08-24 06:46:54"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-users-for-group",
      "title": "Zendesk - Groups: List Users | Portia AI Docs",
      "content": "Zendesk - Groups: List Users | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:groups:list_users_for_group Tool description: Returns a list of memberships for a group. Memberships include the user ID and metadata about their membership in the group. Returns a maximum of 100 records. Args schema: { \"description\": \"Input schema for ZendeskListUsersForGroupTool.\", \"properties\": { \"group_id\": { \"description\": \"The id of the group\", \"title\": \"Group Id\", \"type\": \"integer\" } }, \"required\": [ \"group_id\" ], \"title\": \"ZendeskListUsersForGroupToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:46:57"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs/docs-get-document",
      "title": "Google Docs - Docs: Get Document | Portia AI Docs",
      "content": "Google Docs - Docs: Get Document | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:docs:get_document Tool description: Get a document from Google Docs in plain text format by ID. The GoogleDriveSearchTool should be used to search for a document by name if an ID is not known. Args schema: { \"description\": \"Schema for the Google Docs get document tool.\", \"properties\": { \"document_id\": { \"description\": \"The ID of the document to get. It can contain letters, numbers, and some special characters.\", \"title\": \"Document Id\", \"type\": \"string\" } }, \"required\": [ \"document_id\" ], \"title\": \"GoogleDocsGetDocumentToolSchema\", \"type\": \"object\"} Output schema: ('str', 'str: The content of the document in plain text format.')UsageTool details",
      "timestamp": "2025-08-24 06:47:00"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/clarification_tool",
      "title": "portia.execution_agents.clarification_tool | Portia AI Docs",
      "content": "portia.execution_agents.clarification_tool | Portia AI Docs Skip to main contentOn this pageTool for raising clarifications if unsure on an arg. ClarificationToolSchema Objects​ class ClarificationToolSchema(BaseModel) Schema defining the inputs for the ClarificationTool. ClarificationTool Objects​ class ClarificationTool(Tool[str]) Raises a clarification if the agent is unsure of an argument. run​ def run(ctx: ToolRunContext, argument_name: str) -> str Run the ClarificationTool.ClarificationToolSchema ObjectsClarificationTool Objects",
      "timestamp": "2025-08-24 06:47:03"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_hooks",
      "title": "portia.execution_hooks | Portia AI Docs",
      "content": "portia.execution_hooks | Portia AI Docs Skip to main contentOn this pageExecution hooks for customizing the behavior of portia during execution. BeforeStepExecutionOutcome Objects​ class BeforeStepExecutionOutcome(PortiaEnum) The Outcome of the before step execution hook. ExecutionHooks Objects​ class ExecutionHooks(BaseModel) Hooks that can be used to modify or add extra functionality to the run of a plan. Hooks can be registered for various execution events: clarification_handler: A handler for clarifications raised during execution before_step_execution: Called before executing each step after_step_execution: Called after executing each step. When there's an error, this is called with the error as the output value. before_plan_run: Called before executing the first step of the plan run. after_plan_run: Called after executing the plan run. This is not called if a clarification is raised, as it is expected that the plan will be resumed after the clarification is handled. before_tool_call: Called before the tool is called after_tool_call: Called after the tool is called clarification_handler​ Handler for clarifications raised during execution. before_step_execution​ Called before executing each step. Arguments: plan - The plan being executed plan_run - The current plan run step - The step about to be executed Returns: BeforeStepExecutionOutcome | None: Whether to continue with the step execution or skip it. If None is returned, the default behaviour is to continue with the step execution. after_step_execution​ Called after executing each step. When there's an error, this is called with the error as the output value. Arguments: plan - The plan being executed plan_run - The current plan run step - The step that was executed output - The output from the step execution before_plan_run​ Called before executing the first step of the plan run. Arguments: plan - The plan being executed plan_run - The current plan run after_plan_run​ Called after executing the plan run. This is not called if a clarification is raised, as it is expected that the plan will be resumed after the clarification is handled. Arguments: plan - The plan that was executed plan_run - The completed plan run output - The final output from the plan execution before_tool_call​ Called before the tool is called. Arguments: tool - The tool about to be called args - The args for the tool call. These are mutable and so can be modified in place as required. plan_run - The current plan run step - The step being executed Returns: Clarification | None: A clarification to raise, or None to proceed with the tool call after_tool_call​ Called after the tool is called. Arguments: tool - The tool that was called output - The output returned from the tool call plan_run - The current plan run step - The step being executed Returns: Clarification | None: A clarification to raise, or None to proceed. If a clarification is raised, when we later resume the plan, the same step will be executed again clarify_on_all_tool_calls​ def clarify_on_all_tool_calls(tool: Tool, args: dict[str, Any], plan_run: PlanRun, step: Step) -> Clarification | None Raise a clarification to check the user is happy with all tool calls before proceeding. Example usage: portia = Portia( execution_hooks=ExecutionHooks( before_tool_call=clarify_on_all_tool_calls, ) ) clarify_on_tool_calls​ def clarify_on_tool_calls( tool: str | Tool | list[str] | list[Tool]) -> Callable[[Tool, dict[str, Any], PlanRun, Step], Clarification | None] Return a hook that raises a clarification before calls to the specified tool. Arguments: tool - The tool or tools to raise a clarification for before running Example usage: portia = Portia( execution_hooks=ExecutionHooks( before_tool_call=clarify_on_tool_calls(\"my_tool_id\"), ) ) Or with Tool objects: portia = Portia( execution_hooks=ExecutionHooks( before_tool_call=clarify_on_tool_calls([tool1, tool2]), ) ) log_step_outputs​ def log_step_outputs(plan: Plan, plan_run: PlanRun, step: Step, output: Output) -> None Log the output of a step in the plan.BeforeStepExecutionOutcome ObjectsExecutionHooks Objects",
      "timestamp": "2025-08-24 06:47:06"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/browserbase",
      "title": "Browserbase | Portia AI Docs",
      "content": "Browserbase | Portia AI Docs Skip to main contentOn this page Description​ Automate web browsers remotely on a cloud environment. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"browserbase\", command=\"npx\", args=[\"@browserbasehq/mcp\"], env={\"BROWSERBASE_API_KEY\": \"<api_key>\", \"BROWSERBASE_PROJECT_ID\": \"<project_id>\"},) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"browserbase\", command=\"npx\", args=[\"@browserbasehq/mcp\"], env={\"BROWSERBASE_API_KEY\": \"<api_key>\", \"BROWSERBASE_PROJECT_ID\": \"<project_id>\"},) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:47:09"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail",
      "title": "Google Gmail Tools | Portia AI Docs",
      "content": "Google Gmail Tools | Portia AI Docs Skip to main content Gmail: DraftDrafts an email for the recipients indicated. Should not be used with the send email tool. Instead to send a draft email use the portia:google:gmail:send_draft_email. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Gmail: SearchSearches for emails and drafts in the user's inbox and returns emails content that match the query. Gmail: SendSends an email to the recipients indicated. Should not be used with the draft email tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Gmail: Send DraftSends a previously drafted email with the email title, body and recipients indicated in the draft. Requires a draft id which is obtained from the DraftEmailTool. Only use this tool if you actually want to send an email, not if the user just wants to draft an email.",
      "timestamp": "2025-08-24 06:47:12"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/tool_decorator",
      "title": "portia.tool_decorator | Portia AI Docs",
      "content": "portia.tool_decorator | Portia AI Docs Skip to main contentOn this pageTool decorator for creating tools from functions. tool​ def tool(fn: Callable[..., T]) -> type[Tool[T]] Convert a function into a Tool class. This decorator automatically creates a Tool subclass from a function by: Using the function's docstring as the tool description Creating an ID and name based on the function name Generating input schema from function parameters and type hints Determining output schema from return type annotation Example: @tool def add_numbers(a: int, b: int) -> int: \"\"\"Add two numbers together.\"\"\" return a + b Arguments: fn - The function to convert to a Tool class Returns: A Tool subclass that wraps the original function Raises: ValueError - If the function has invalid signature or return type",
      "timestamp": "2025-08-24 06:47:15"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/execution_utils",
      "title": "portia.execution_agents.execution_utils | Portia AI Docs",
      "content": "portia.execution_agents.execution_utils | Portia AI Docs Skip to main contentOn this pageAgent execution utilities. This module contains utility functions for managing agent execution flow. AgentNode Objects​ class AgentNode(str, Enum) Nodes for agent execution. This enumeration defines the different types of nodes that can be encountered during the agent execution process. Attributes: TOOL_AGENT str - A node representing the tool agent. SUMMARIZER str - A node representing the summarizer. TOOLS str - A node representing the tools. ARGUMENT_VERIFIER str - A node representing the argument verifier. ARGUMENT_PARSER str - A node representing the argument parser. MEMORY_EXTRACTION str - A node representing the memory extraction step. is_clarification​ def is_clarification(artifact: Any) -> bool Check if the artifact is a clarification or list of clarifications. tool_call_or_end​ def tool_call_or_end(state: MessagesState) -> Literal[AgentNode.TOOLS, END] Determine if tool execution should continue. This function checks if the current state indicates that the tool execution should continue, or if the run should end. Arguments: state MessagesState - The current state of the messages. Returns: Literal[AgentNode.TOOLS, END]: The next state to transition to. get_arg_value_with_templating​ def get_arg_value_with_templating(step_inputs: list[StepInput], arg: Any) -> Any Return the value of an argument, handling any templating required. template_in_required_inputs​ def template_in_required_inputs(response: BaseMessage, step_inputs: list[StepInput]) -> BaseMessage Template any required inputs into the tool calls. process_output​ def process_output( step: Step, messages: list[BaseMessage], tool: Tool | None = None, clarifications: list[Clarification] | None = None) -> Output Process the output of the agent. This function processes the agent's output based on the type of message received. It raises errors if the tool encounters issues and returns the appropriate output. Arguments: step Step - The step that produced the output. messages list[BaseMessage] - The set of messages received from the agent's plan_run. tool Tool | None - The tool associated with the agent, if any. clarifications list[Clarification] | None - A list of clarifications, if any. Returns: Output - The processed output, which can be an error, tool output, or clarification. Raises: ToolRetryError - If there was a soft error with the tool and retries are allowed. ToolFailedError - If there was a hard error with the tool. InvalidAgentOutputError - If the output from the agent is invalid. is_soft_tool_error​ def is_soft_tool_error(message: BaseMessage) -> bool Check if the message is a soft tool error.AgentNode Objects",
      "timestamp": "2025-08-24 06:47:18"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/update-ticket",
      "title": "Zendesk - Tickets: Update | Portia AI Docs",
      "content": "Zendesk - Tickets: Update | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:tickets:update Tool description: Updates an existing ticket in Zendesk with the provided details. For fields requiring group and user ID fields, use the ZendeskSearchGroupsTool and ZendeskSearchUsersTool to get the IDs. This tool can be run once with multiple details updated on the ticket or multiple times with a single detail updated on the ticket. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Args schema: { \"$defs\": { \"TicketPriority\": { \"description\": \"Ticket priority.\", \"enum\": [ \"urgent\", \"high\", \"normal\", \"low\" ], \"title\": \"TicketPriority\", \"type\": \"string\" }, \"TicketStatus\": { \"description\": \"Ticket status.\", \"enum\": [ \"new\", \"open\", \"pending\", \"hold\", \"solved\", \"closed\" ], \"title\": \"TicketStatus\", \"type\": \"string\" }, \"TicketType\": { \"description\": \"Ticket type.\", \"enum\": [ \"problem\", \"incident\", \"question\", \"task\" ], \"title\": \"TicketType\", \"type\": \"string\" } }, \"description\": \"Input schema for ZendeskUpdateTicketTool.\", \"properties\": { \"ticket_id\": { \"description\": \"The ID of the ticket to update\", \"title\": \"Ticket Id\", \"type\": \"integer\" }, \"subject\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The subject of the ticket\", \"title\": \"Subject\" }, \"comment\": { \"anyOf\": [ { \"additionalProperties\": true, \"type\": \"object\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Optional comment to add. Format is a JSON dictionary with keys 'body' and 'public' - e.g. {'body': 'comment text', 'public': true/false}\", \"title\": \"Comment\" }, \"priority\": { \"anyOf\": [ { \"$ref\": \"#/$defs/TicketPriority\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The ticket priority. Can be 'urgent', 'high', 'normal', or 'low'\" }, \"status\": { \"anyOf\": [ { \"$ref\": \"#/$defs/TicketStatus\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The state of the ticket. Can be 'new', 'open', 'pending', 'hold', 'solved', or 'closed'\" }, \"type\": { \"anyOf\": [ { \"$ref\": \"#/$defs/TicketType\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The type of the ticket. Can be 'problem', 'incident', 'question', or 'task'\" }, \"assignee_id\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The ID of the agent to assign the ticket to\", \"title\": \"Assignee Id\" }, \"group_id\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The ID of the group to assign the ticket to\", \"title\": \"Group Id\" }, \"collaborator_ids\": { \"anyOf\": [ { \"items\": { \"type\": \"integer\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Array of user IDs to CC on the ticket\", \"title\": \"Collaborator Ids\" } }, \"required\": [ \"ticket_id\" ], \"title\": \"ZendeskUpdateTicketToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Returns the updated ticket data from Zendesk API. This includes information from the schema and other immutable ticket data')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:47:21"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/linear",
      "title": "Linear | Portia AI Docs",
      "content": "Linear | Portia AI Docs Skip to main contentOn this page Description​ Access your Linear data to manage your projects and issues in a simple and secure way. Authorisation​ This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail here (↗). Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to authorise with the server via OAuth when you enable it. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:47:24"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-modify-event",
      "title": "Google Calendar - Calendar: Modify Event | Portia AI Docs",
      "content": "Google Calendar - Calendar: Modify Event | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:gcalendar:modify_event Tool description: Modifies an existing Google Calendar event. You must provide the event ID to modify, and can optionally provide new values if desired for the title, start time, end time, description, and attendees. Args schema: { \"description\": \"Schema for modifying a Google Calendar event.\", \"properties\": { \"event_id\": { \"description\": \"The ID of the event to modify, likely retrieved from portia:google:gcalendar:get_events_by_properties\", \"title\": \"Event Id\", \"type\": \"string\" }, \"event_title\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The new title of the calendar event\", \"title\": \"Event Title\" }, \"start_time\": { \"anyOf\": [ { \"format\": \"date-time\", \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The new start time in ISO format without timezone, e.g 2024-09-20T20:00:00\", \"title\": \"Start Time\" }, \"end_time\": { \"anyOf\": [ { \"format\": \"date-time\", \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The new end time in ISO format without timezone, e.g 2024-09-20T20:00:00\", \"title\": \"End Time\" }, \"event_description\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The new description of the event\", \"title\": \"Event Description\" }, \"attendees\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"New list of attendees email addresses\", \"title\": \"Attendees\" } }, \"required\": [ \"event_id\" ], \"title\": \"GoogleCalendarModifyEventSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Output of the tool')UsageTool details",
      "timestamp": "2025-08-24 06:47:27"
    },
    {
      "url": "https://docs.portialabs.ai/intro-to-tools",
      "title": "Introduction to tools | Portia AI Docs",
      "content": "Introduction to tools | Portia AI Docs Skip to main contentOn this page Understand tools at Portia and add your own. TL;DR Tools are used by LLMs as part of their response to indicate that a particular software service or data store is required to fulfil a user's query. We represent a tool with the Tool class (SDK reference ↗). The LLM parses the tool properties, namely its name, description, input and output schemas to determine whether the tool is relevant to its response and how to invoke it. Tools at Portia​ A tool is a natural language wrapper around a data source or software service that the LLM can point to in order to accomplish tasks beyond its inherent capabilities. As a simple example, an LLM could respond to the user query email avrana@kern.ai and tell her that spiders are now sentient by suggesting a call to the email sending service wrapped in the send_email tool. We represent a tool with the Tool class (SDK reference ↗). Let's look at the weather_tool provided with our SDK as an example: weather_tool.py\"\"\"Tool to get the weather from openweathermap.\"\"\"import osimport httpxfrom pydantic import BaseModel, Fieldfrom portia.errors import ToolHardError, ToolSoftErrorfrom portia.tool import Tool, ToolRunContextclass WeatherToolSchema(BaseModel): \"\"\"Input for WeatherTool.\"\"\" city: str = Field(..., description=\"The city to get the weather for\")class WeatherTool(Tool[str]): \"\"\"Get the weather for a given city.\"\"\" id: str = \"weather_tool\" name: str = \"Weather Tool\" description: str = \"Get the weather for a given city\" args_schema: type[BaseModel] = WeatherToolSchema output_schema: tuple[str, str] = (\"str\", \"String output of the weather with temp and city\") def run(self, _: ToolRunContext, city: str) -> str: \"\"\"Run the WeatherTool.\"\"\" api_key = os.getenv(\"OPENWEATHERMAP_API_KEY\") if not api_key or api_key == \"\": raise ToolHardError(\"OPENWEATHERMAP_API_KEY is required\") url = ( f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&units=metric\" ) response = httpx.get(url) response.raise_for_status() data = response.json() if \"weather\" not in data: raise ToolSoftError(f\"No data found for: {city}\") weather = data[\"weather\"][0][\"description\"] if \"main\" not in data: raise ToolSoftError(f\"No main data found for city: {city}\") temp = data[\"main\"][\"temp\"] return f\"The current weather in {city} is {weather} with a temperature of {temp}°C.\" Here are the key points to look out for: All properties of a tool are parsed by the LLM to determine whether that tool is salient to a user's query and should therefore be invoked in response to it. The args_schema property describes the tool inputs. This is important to help the LLM understand what parameters it can invoke a tool with. The output_schema property describes the expected output of the tool. This helps the LLM know what to expect from the tool and informs its sequencing decisions for tool calls as well. Optionally, you can override the should_summarize property to determine whether the tool output should be summarised. When this setting is turned on, it uses an additional LLM call to populate the summary field in the step's output of the plan run object. Every tool has a run function which is the actual tool implementation. The method always takes ToolRunContext which is contextual information implicitly passed by Portia. We will look into this more deeply in a future section (Manage execution context ↗). The only thing to note now is that you have to include this argument and always import the underlying dependency. Track tool calls in logsYou can track tool calls live as they occur through the logs by setting default_log_level to DEBUG in the Config of your Portia instance (Manage logging ↗).Tools at Portia",
      "timestamp": "2025-08-24 06:47:30"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-drive/",
      "title": "Google Drive Tools | Portia AI Docs",
      "content": "Google Drive Tools | Portia AI Docs Skip to main content Drive: SearchSearch for files and folders in Google Drive. Google Drive stores proprietary files like Google Docs, Sheets, and Slides. It also stores regular files like PDFs, images, and videos or even files from other apps like Microsoft docx, xlsx, pptx, etc. Use this tool to search for files using a search query. This tool should be used to resolve name / file descriptions into concrete file IDs for other Google tools to use when needed.",
      "timestamp": "2025-08-24 06:47:33"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github/list-repo-issues",
      "title": "GitHub - Issue: List | Portia AI Docs",
      "content": "GitHub - Issue: List | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:github::list_repo_issues Tool description: List issues in a GitHub repository. Args schema: { \"description\": \"Schema for the StarGitHubRepoTool input.\", \"properties\": { \"repo\": { \"description\": \"The repository to list issues. For example: PortiaAI/portia-sdk-python\", \"title\": \"Repo\", \"type\": \"string\" } }, \"required\": [ \"repo\" ], \"title\": \"ListGitHubRepoIssuesToolSchema\", \"type\": \"object\"} Output schema: ('list', 'A list of issues in the GitHub repository.')UsageTool details",
      "timestamp": "2025-08-24 06:47:35"
    },
    {
      "url": "https://docs.portialabs.ai/evals-overview",
      "title": "Overview and basic usage | Portia AI Docs",
      "content": "Overview and basic usage | Portia AI Docs Skip to main contentOn this page Evals are static, ground truth datasets designed to be run multiple times against your agents to assess their performance. These datasets are comprised of multiple test cases which are pairs of inputs (query or plan) and outputs (plan or plan run). Running an Eval simply means putting the input of the test case through your agents, and comparing the output it yields with the test case output to make sure it's still behaving reliably. Any number of changes in the agents can cause a divergence from the expected output e.g. changes to your underlying system prompts, tool definitions, LLM choice etc. Get your Portia API keyPlease make sure you have a PORTIA_API_KEY set up in your environment to use Steel Thread, as it relies on plans and plan runs stored in Portia cloud. Basic usage​ The overall flow is: From the Portia dashboard, create a new eval dataset including at least one test case. You can add existing plans / plan runs directly from the dashboard to use as test cases so you don't need to create them from scratch. Note that the query and tools will be automatically populated as test case inputs, but you can still edit those. You can rely on the default evaluators offered by Portia or create your own. Feel free to explore the available defautl evaluators in the dashboard. We will explain those in more detail below. Run your Evals by passing the name of the Eval dataset to your Steel Thread instance along with your preferred evaluators. Visualize the metrics from each run in the Portia UI. Here is a step-by-step walkthrough with screenshots from the Portia UI. Eval Test cases are designed to be generated from existing data making it easy to do. You can also create a new test case from blank though if you'd like to! Step one of the process is about specifying the input to Portia. Either a query or an existing plan can be provided depending on your use case. Step two involves the assertions that we will make when the plan_run is complete. This allows you to use the built in evaluators or to use custom tags. Finally give the test case a description to make it easy to understand whats going on it in. A shortcut to adding existing plan runsYou can add plan runs into an existing Eval dataset directly from the Plan Run view. When you're in the Plan Runs tab in the dashboard, click on the plan run you want to add to your Eval dataset, and look for the 'Add to Evals' button in the Plan Run view modal. This is perfect when you're iterating on an agent in development, so that you can immediately add your ideal plan run to your Evals once you manage to produce it. With the setup above completed you're now ready to run this basic example. from portia import Config, Portiafrom steelthread.steelthread import SteelThread, EvalConfig# Initialize Portiaconfig = Config.from_default()portia = Portia(config=config)# Initialize SteelThread with the dataset and evaluators set in the dashboardst = SteelThread()st.run_evals( portia, EvalConfig( eval_dataset_name=\"your-dataset-name-here\", config=config, iterations=5, ),) Default evaluators​ Steel Thread comes with a decent helping of evaluators by default. The EvalConfig object above takes a list of evaluators (of type Evaluator) as an argument. SteelThread's DefaultEvaluator is available off the shelf and is used by default when no evaluators are specified. It picks up all the evaluators you set up in the dashboard, of which the available options currently include: Final plan run state -- this not only helps you test for a successful plan completion (State = COMPLETE), but it also helps you test for plans that should fail or trigger a clarification e.g. for auth. Tool calls -- you can confirm whether all the tools you expected to be called were indeed called (and include an exclusion set as well e.g. to track tool selection confusion). Latency -- how long a plan run took to complete. LLM judge on plan run -- feed the whole plan run with some guidance to an LLM as judge. Basic usageDefault evaluators",
      "timestamp": "2025-08-24 06:47:39"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/",
      "title": "Google Gmail Tools | Portia AI Docs",
      "content": "Google Gmail Tools | Portia AI Docs Skip to main content Gmail: DraftDrafts an email for the recipients indicated. Should not be used with the send email tool. Instead to send a draft email use the portia:google:gmail:send_draft_email. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Gmail: SearchSearches for emails and drafts in the user's inbox and returns emails content that match the query. Gmail: SendSends an email to the recipients indicated. Should not be used with the draft email tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Gmail: Send DraftSends a previously drafted email with the email title, body and recipients indicated in the draft. Requires a draft id which is obtained from the DraftEmailTool. Only use this tool if you actually want to send an email, not if the user just wants to draft an email.",
      "timestamp": "2025-08-24 06:47:42"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/local_file_reader_tool",
      "title": "portia.open_source_tools.local_file_reader_tool | Portia AI Docs",
      "content": "portia.open_source_tools.local_file_reader_tool | Portia AI Docs Skip to main contentOn this pageTool for reading files from disk. FileReaderToolSchema Objects​ class FileReaderToolSchema(BaseModel) Schema defining the inputs for the FileReaderTool. FileReaderTool Objects​ class FileReaderTool(Tool[str]) Finds and reads content from a local file on Disk. run​ def run(ctx: ToolRunContext, filename: str) -> str | Clarification Run the FileReaderTool. find_file​ def find_file(file_path: Path) -> list[str] Return a full file path or None.FileReaderToolSchema ObjectsFileReaderTool Objects",
      "timestamp": "2025-08-24 06:47:44"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-get-event-details",
      "title": "Google Calendar - Calendar: Get Event | Portia AI Docs",
      "content": "Google Calendar - Calendar: Get Event | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:gcalendar:get_event_details Tool description: Gets Google Calendar event using an event ID. Args schema: { \"description\": \"Schema for getting details about a Google Calendar event.\", \"properties\": { \"event_id\": { \"description\": \"The event details to retrieve\", \"title\": \"Event Id\", \"type\": \"string\" } }, \"required\": [ \"event_id\" ], \"title\": \"GoogleCalendarGetEventDetailsSchema\", \"type\": \"object\"} Output schema: ('dict', 'A dictionary containing information about a single calendar event')UsageTool details",
      "timestamp": "2025-08-24 06:47:47"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/elevenlabs",
      "title": "ElevenLabs | Portia AI Docs",
      "content": "ElevenLabs | Portia AI Docs Skip to main contentOn this page Description​ Integrates with ElevenLabs to provide high-quality text-to-speech, voice cloning, and conversational capabilities with customizable voice profiles and audio processing features. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"elevenlabs\", command=\"uvx\", args=[\"elevenlabs-mcp\"], env={\"ELEVENLABS_API_KEY\": \"<api_key>\"}) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"elevenlabs\", command=\"uvx\", args=[\"elevenlabs-mcp\"], env={\"ELEVENLABS_API_KEY\": \"<api_key>\"}) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:47:50"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/send-message",
      "title": "Slack - Message: Send | Portia AI Docs",
      "content": "Slack - Message: Send | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Slack tools with Portia AI​ You will need to create your own Slack App to use with Portia AI. This is so you can control the name and appearance of slack bot activity initiated via the Portia AI framework. Once your slack app is created you can configure your client ID and secret in the Portia dashboard. Install a Slack app​ Head over to api.slack.com/apps ↗ Create an app from scratch and select the Slack workplace you would like to use it in. Note down the client ID and secret on the Basic Information page. We will need this in a couple of steps from now! In the OAuth & Permissions tab further down in the left hand nav, add as Redirect URL the following URL https://api.portialabs.ai/api/v0/oauth/slack (don't forget to hit that Save URLs button!). Under Bot Token Scopes, be sure to add the scopes channels:history -- View messages and other content in public channels that your Slack app has been added to. channels:read -- View basic information about public channels in a workspace. chat:write -- Send messages as @{your slack app name}. users:read -- View people in a workspace. Under User Token Scopes, be sure to add the scope search:read to support searching workplace content. Now scroll up to the top of the OAuth & Permissions page and hit the Install to {your workplace name} button. Once that is done, open your Slack app and hit 'Add apps` and be sure to select your new app. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the client ID and secret of your Slack app as collected in step 3 of the Slack installation process above. You are now ready to call Slack tools on our cloud! Tool details​ Tool ID: portia:slack:bot:send_message Tool description: Send a message to a specific Slack channel or user by ID. Requires an ID provided by other tools. Args schema: { \"description\": \"Input for SendSlackMessageTool.\", \"properties\": { \"target_id\": { \"description\": \"Slack channel ID (i.e. C084F1FSTFC), or user ID (i.e. U084F1FSTFC) where themessage will be sent. This can be provided by other tools like list_conversation_idsor list_user_ids.\", \"title\": \"Target Id\", \"type\": \"string\" }, \"message\": { \"description\": \"The message content to send.\", \"title\": \"Message\", \"type\": \"string\" } }, \"required\": [ \"target_id\", \"message\" ], \"title\": \"SendSlackMessageToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Output of the message sent')UsageConfigure your Slack tools with Portia AIInstall a Slack appConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:47:53"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/output",
      "title": "portia.execution_agents.output | Portia AI Docs",
      "content": "portia.execution_agents.output | Portia AI Docs Skip to main contentOn this pageOutputs from a plan run step. These are stored and can be used as inputs to future steps BaseOutput Objects​ class BaseOutput(BaseModel) Base interface for concrete output classes to implement. get_value​ @abstractmethoddef get_value() -> Serializable | None Return the value of the output. This should not be so long that it is an issue for LLM prompts. serialize_value​ @abstractmethoddef serialize_value() -> str Serialize the value to a string. full_value​ @abstractmethoddef full_value(agent_memory: AgentMemory) -> Serializable | None Get the full value, fetching from remote storage or file if necessary. This value may be long and so is not suitable for use in LLM prompts. get_summary​ @abstractmethoddef get_summary() -> str | None Return the summary of the output. LocalDataValue Objects​ class LocalDataValue(BaseOutput) Output that is stored locally. get_value​ def get_value() -> Serializable | None Get the value of the output. serialize_value​ def serialize_value() -> str Serialize the value to a string. full_value​ def full_value(agent_memory: AgentMemory) -> Serializable | None Return the full value. As the value is stored locally, this is the same as get_value() for this type of output. get_summary​ def get_summary() -> str | None Return the summary of the output. serialize_value_field​ @field_serializer(\"value\")def serialize_value_field(value: Serializable | None) -> str Serialize the value to a string. Arguments: value SERIALIZABLE_TYPE_VAR | None - The value to serialize. Returns: str - The serialized value as a string. AgentMemoryValue Objects​ class AgentMemoryValue(BaseOutput) Output that is stored in agent memory. get_value​ def get_value() -> Serializable | None Return the summary of the output as the value is too large to be retained locally. serialize_value​ def serialize_value() -> str Serialize the value to a string. We use the summary as the value is too large to be retained locally. full_value​ def full_value(agent_memory: AgentMemory) -> Serializable | None Get the full value, fetching from remote storage or file if necessary. get_summary​ def get_summary() -> str Return the summary of the output. LocalOutput Objects​ @deprecated( \"LocalOutput is deprecated and will be removed in the 0.4 release - \" \"use LocalDataValue instead\")class LocalOutput(LocalDataValue) Alias of LocalDataValue kept for backwards compatibility. AgentMemoryOutput Objects​ @deprecated( \"AgentMemoryOutput is deprecated and will be removed in the 0.4 release - \" \"use AgentMemoryValue instead\")class AgentMemoryOutput(AgentMemoryValue) Alias of AgentMemoryValue kept for backwards compatibility.BaseOutput ObjectsLocalDataValue ObjectsAgentMemoryValue ObjectsLocalOutput ObjectsAgentMemoryOutput Objects",
      "timestamp": "2025-08-24 06:47:56"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/builder/plan_v2",
      "title": "portia.builder.plan_v2 | Portia AI Docs",
      "content": "portia.builder.plan_v2 | Portia AI Docs Skip to main contentOn this pageA plan built using the PlanBuilder. PlanV2 Objects​ class PlanV2(BaseModel) A sequence of steps to be run by Portia. validate_plan​ @model_validator(mode=\"after\")def validate_plan() -> PlanV2 Validate the plan. to_legacy_plan​ def to_legacy_plan(plan_context: PlanContext) -> Plan Convert the Portia plan to a legacy plan. step_output_name​ def step_output_name(step: int | str | StepV2) -> str Get the name of the output of a step in the plan. idx_by_name​ def idx_by_name(name: str) -> int Get the index of a step by name.PlanV2 Objects",
      "timestamp": "2025-08-24 06:47:59"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/minimax",
      "title": "MiniMax | Portia AI Docs",
      "content": "MiniMax | Portia AI Docs Skip to main contentOn this page Description​ Enables high-quality text-to-speech, voice cloning, and video generation capabilities through MiniMax's API with robust error handling and file management features. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"minmax\", command=\"uvx\", args=[ \"minimax-mcp\", \"-y\", ], env={ \"MINIMAX_API_KEY\": \"<api_key>\", \"MINIMAX_MCP_BASE_PATH\": \"<path_to_minimax>\", \"MINIMAX_API_HOST\": \"https://api.minimax.io\", \"MINIMAX_API_RESOURCE_MODE\": \"url\", },) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"minmax\", command=\"uvx\", args=[ \"minimax-mcp\", \"-y\", ], env={ \"MINIMAX_API_KEY\": \"<api_key>\", \"MINIMAX_MCP_BASE_PATH\": \"<path_to_minimax>\", \"MINIMAX_API_HOST\": \"https://api.minimax.io\", \"MINIMAX_API_RESOURCE_MODE\": \"url\", },) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:48:02"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/intercom",
      "title": "Intercom | Portia AI Docs",
      "content": "Intercom | Portia AI Docs Skip to main contentOn this page Description​ Enables AI systems to securely access Intercom's customer conversation data, user profiles, and tickets in real-time for identifying patterns, troubleshooting issues, and driving business decisions. Authorisation​ This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail here (↗). Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to authorise with the server via OAuth when you enable it. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:48:05"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-send-email",
      "title": "Google Gmail - Gmail: Send | Portia AI Docs",
      "content": "Google Gmail - Gmail: Send | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:gmail:send_email Tool description: Sends an email to the recipients indicated. Should not be used with the draft email tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Args schema: { \"description\": \"Input for SendEmailTool.\", \"properties\": { \"recipients\": { \"description\": \"The recipients that the email should be sent to (should be a list of email addresses)\", \"items\": { \"type\": \"string\" }, \"title\": \"Recipients\", \"type\": \"array\" }, \"email_title\": { \"description\": \"The title of the email to be sent\", \"title\": \"Email Title\", \"type\": \"string\" }, \"email_body\": { \"description\": \"The body of the email to be sent\", \"title\": \"Email Body\", \"type\": \"string\" } }, \"required\": [ \"recipients\", \"email_title\", \"email_body\" ], \"title\": \"SendEmailToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Output of the email sent')UsageTool details",
      "timestamp": "2025-08-24 06:48:08"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/yepcode",
      "title": "YepCode | Portia AI Docs",
      "content": "YepCode | Portia AI Docs Skip to main contentOn this page Description​ Enables secure execution of LLM-generated scripts and processes in isolated environments with environment variable management for teams needing to run code directly from AI assistants. Authorisation​ To use this MCP server, you need API credentials in your environment. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to provide your API key when you enable the server. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:48:11"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/shopify-dev",
      "title": "Shopify Dev | Portia AI Docs",
      "content": "Shopify Dev | Portia AI Docs Skip to main contentOn this page Description​ Integrates with Shopify Dev. Supports various tools to interact with different Shopify APIs. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"shopify-dev\", command=\"npx\", args=[\"@shopify/dev-mcp@latest\"],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"shopify-dev\", command=\"npx\", args=[\"@shopify/dev-mcp@latest\"],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:48:14"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-search-email",
      "title": "Microsoft Outlook - Outlook: Search | Portia AI Docs",
      "content": "Microsoft Outlook - Outlook: Search | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Selecting Microsoft Tools​ Microsoft tools are included in Portia's cloud registry but are not included in the default DefaultToolRegistry class. This is due to tool clashes with the Google tools (i.e. the agent wouldn't know whether to check Gmail or Outlook for email tasks). In order to use Microsoft tools rather than Google tools, simply filter out the Google tools from the Portia cloud registry rather than using the default registry: from portia import PortiaToolRegistry, default_configregistry = PortiaToolRegistry(default_config()).filter_tools(lambda tool: not tool.id.startswith(\"portia:google:\"))registry = PortiaToolRegistry(default_config()).filter_tools( lambda tool: not tool.id.startswith(\"portia:google:\")) Tool details​ Tool ID: portia:microsoft:outlook:search_email Tool description: Searches for emails in the user's Outlook inbox and returns emails content that match the query. Args schema: { \"description\": \"Input for SearchEmailTool.\", \"properties\": { \"query\": { \"description\": \"The query to search for emails. This supports basic search terms and can include filters like 'from:', 'subject:', etc.\", \"title\": \"Query\", \"type\": \"string\" } }, \"required\": [ \"query\" ], \"title\": \"SearchEmailToolSchema\", \"type\": \"object\"} Output schema: ('list[dict[str, str]]', 'list[dict[str, str]]: List of emails with the following keys: from, to, subject, date, body.')UsageSelecting Microsoft ToolsTool details",
      "timestamp": "2025-08-24 06:48:17"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/end_user",
      "title": "portia.end_user | Portia AI Docs",
      "content": "portia.end_user | Portia AI Docs Skip to main contentOn this pageModels for end user management. EndUser Objects​ class EndUser(BaseModel) Represents an actual user of the system. set_additional_data​ def set_additional_data(key_name: str, key_value: str) -> None Set a field in the additional data blob. remove_additional_data​ def remove_additional_data(key_name: str) -> None Set a field in the additional data blob. get_additional_data​ def get_additional_data(key_name: str) -> str | None Get a field from the additional data blob.EndUser Objects",
      "timestamp": "2025-08-24 06:48:20"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github/list-repos",
      "title": "GitHub - Repository: List | Portia AI Docs",
      "content": "GitHub - Repository: List | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:github::list_repos Tool description: Lists all public repositories for a GitHub organization. Args schema: { \"description\": \"Schema for the ListGitHubReposTool input.\", \"properties\": { \"org\": { \"description\": \"The organization name.\", \"title\": \"Org\", \"type\": \"string\" } }, \"required\": [ \"org\" ], \"title\": \"ListGitHubReposSchema\", \"type\": \"object\"} Output schema: ('list', 'A list of public repositories.')UsageTool details",
      "timestamp": "2025-08-24 06:48:23"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-organizations",
      "title": "Zendesk - Organizations: Search | Portia AI Docs",
      "content": "Zendesk - Organizations: Search | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:organizations:search Tool description: Retrieves a list of organizations in Zendesk matching the query. Args schema: { \"description\": \"Input schema for ZendeskSearchOrganizationsTool.\", \"properties\": { \"query\": { \"description\": \"The query to search for to find organizations. It can be a natural language query or use the syntax of the Zendesk API. Organizations support the following keyword fields in Zendesk syntax: `name`, `created`, `notes`, `details`, and `tags`. e.g. 'name:Acme' or 'health'.\", \"title\": \"Query\", \"type\": \"string\" } }, \"required\": [ \"query\" ], \"title\": \"ZendeskSearchOrganizationsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', \"application/json: Payload from API containing a list of organizations in Zendesk matching the provided query. This includes (but is not limited to) the organization's name, details, and domain.\")UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:48:26"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/aws-documentation",
      "title": "AWS Documentation | Portia AI Docs",
      "content": "AWS Documentation | Portia AI Docs Skip to main contentOn this page Description​ Provides tools to access AWS documentation, search for content, and get recommendations. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"aws-docs\", command=\"uvx\", args=[\"awslabs.aws-documentation-mcp-server@latest\"],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"aws-docs\", command=\"uvx\", args=[\"awslabs.aws-documentation-mcp-server@latest\"],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:48:29"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/introspection_agents/introspection_agent",
      "title": "portia.introspection_agents.introspection_agent | Portia AI Docs",
      "content": "portia.introspection_agents.introspection_agent | Portia AI Docs Skip to main contentOn this pageBaseIntrospectionAgent is the interface for all introspection agents. PreStepIntrospectionOutcome Objects​ class PreStepIntrospectionOutcome(PortiaEnum) The Outcome of the introspection. PreStepIntrospection Objects​ class PreStepIntrospection(BaseModel) The outcome of a pre-step introspection. BaseIntrospectionAgent Objects​ class BaseIntrospectionAgent(ABC) Interface for introspection. This class defines the interface for introspection. By introspection we mean looking at the state of a plan run and making decisions about whether to continue. Attributes: config Config - Configuration settings for the PlanningAgent. __init__​ def __init__(config: Config, agent_memory: AgentMemory) -> None Initialize the BaseIntrospectionAgent with configuration. Arguments: config Config - The configuration to initialize the BaseIntrospectionAgent. agent_memory AgentMemory - The agent memory to use pre_step_introspection​ @abstractmethoddef pre_step_introspection(plan: Plan, plan_run: PlanRun) -> PreStepIntrospection pre_step_introspection is introspection run before a plan happens.. apre_step_introspection​ async def apre_step_introspection(plan: Plan, plan_run: PlanRun) -> PreStepIntrospection pre_step_introspection is introspection run before a plan happens..PreStepIntrospectionOutcome ObjectsPreStepIntrospection ObjectsBaseIntrospectionAgent Objects",
      "timestamp": "2025-08-24 06:48:32"
    },
    {
      "url": "https://docs.portialabs.ai/run-plan",
      "title": "Run a plan | Portia AI Docs",
      "content": "Run a plan | Portia AI Docs Skip to main contentOn this page Learn how to run a plan run from an existing plan or end-to-end. TL;DR A plan run is (uncontroversially) a unique run of a plan. It is represented by the PlanRun class (SDK reference ↗). An agent is spun up to execute every step in the plan run. The PlanRun object tracks the state of the plan run and is enriched at every step by the relevant agent. A plan run can be generated from a plan using the run_plan method. You can also plan a query response, then create and execute a plan run in one fell swoop using the run method of the Portia instance class (SDK reference ↗). Overview of plan runs in Portia​ Portia captures the state of a plan run at every step in an auditable way. This includes: A step index tracking at which step we are in the plan run. The actual plan run state e.g. NOT_STARTED, IN_PROGRESS, COMPLETE, READY_TO_RESUME or NEED_CLARIFICATION. A list of step outputs that is populated throughout the plan run. In a later section we will also see that a plan run state also tracks the list of instances where human input was solicited during plan run, known as Clarification. Plan run states are captured in the PlanRun class (SDK reference ↗). In the previous section (Generate a plan ↗), we generated a plan in response to the query Which stock price grew faster in 2024, Amazon or Google?. Let's examine the final state once we run that plan: Generated planPlan run in final stateplan-1dcd74a4-0af5-490a-a7d0-0df4fd983977.json{ \"id\": \"plan-1dcd74a4-0af5-490a-a7d0-0df4fd983977\", \"plan_context\": { \"query\": \"Which stock price grew faster, Amazon or Google?\", \"tool_ids\": [ \"calculator_tool\", \"weather_tool\", \"search_tool\" ] }, \"steps\": [ { \"task\": \"Search for the latest stock price growth data for Amazon.\", \"inputs\": [], \"tool_id\": \"search_tool\", \"output\": \"$amazon_stock_growth\" }, { \"task\": \"Search for the latest stock price growth data for Google.\", \"inputs\": [], \"tool_id\": \"search_tool\", \"output\": \"$google_stock_growth\" }, { \"task\": \"Compare the stock price growth of Amazon and Google.\", \"inputs\": [ { \"name\": \"$amazon_stock_growth\", \"description\": \"The stock price growth data for Amazon.\" }, { \"name\": \"$google_stock_growth\", \"description\": \"The stock price growth data for Google.\" } ], \"tool_id\": \"llm_tool\", \"output\": \"$stock_growth_comparison\" } ]}prun-18d9aa91-0066-413f-af32-b979bce89821.json{ \"id\": \"prun-18d9aa91-0066-413f-af32-b979bce89821\", \"plan_id\": \"plan-a89efeb0-51ef-4f2c-b435-a936c27c3cfc\", \"current_step_index\": 2, \"state\": \"COMPLETE\", \"outputs\": { \"clarifications\": [], \"step_outputs\": { \"$amazon_stock_growth\": { \"value\": \"Amazon stock closed at an all-time high of $214.10 in November...\", \"summary\": null }, \"$google_stock_growth\": { \"value\": \"In 2024, Google's parent company Alphabet surged 35.5% according to...\", \"summary\": null }, \"$faster_growth\": { \"value\": \"In 2024, Amazon's stock price grew by 52%, while Google's parent company Alphabet saw a stock price surge of 35.5%.\", \"summary\": null } }, \"final_output\": { \"value\": \"In 2024, Amazon's stock price grew by 52%, while Google's parent company Alphabet saw a stock price surge of 35.5%.\", \"summary\": null } }} Every plan run has a unique id and relates to a unique plan_id. If you were to attempt running the same plan multiple times, you would generate multiple PlanRun objects each with a unique id but all with the same plan_id property. Plan run state changes​ As Portia cycles through a plan run, an execution agent is instantiated at every step and that agent will call the tool designated for that. The plan run state is enriched with step outputs at every step of the execution as well. Note that in this example the main tool used is the 'Search Tool' provided in this SDK in the example_tool_registry, and wraps around the Tavily API. We will discuss tools in more depth in the next section. You should be able to inspect the state changes for the above plan run in the logs when you run the code. Animation above made on the brilliant snappify.com ↗. Run from a pre-expressed plan​ Tavily API key requiredWe will use a simple GET endpoint from Tavily in this section. Please sign up to obtain an API key from them (↗) and set it in the environment variable TAVILY_API_KEY. To get to an output that looks like the plan run example above, let's expand on the code we used to generate a plan in the previous section (↗) by adding code to create and execute a plan run from that plan. This approach gives you the opportunity to serve that plan to the user and get their feedback / iterate on it before running the plan run for example. Here is the code to do that: main.pyfrom dotenv import load_dotenvfrom portia import ( Portia, example_tool_registry,)load_dotenv()# Instantiate a Portia instance. Load it with the default config and with the example tools.portia = Portia(tools=example_tool_registry)# Generate the plan from the user queryplan = portia.plan('Which stock price grew faster in 2024, Amazon or Google?')# [OPTIONAL] INSERT CODE WHERE YOU SERVE THE PLAN TO THE USER OR ITERATE ON IT IN ANY WAY# Run the generated planplan_run = portia.run_plan(plan)# Serialise into JSON and print the outputprint(plan_run.model_dump_json(indent=2)) Here we are storing the Plan object returned by the plan method. We then use the run_plan method to start a PlanRun. infoIf you want to see an example where a user iterates on a plan before we proceed with plan run, take a look at the intro example in our examples repo (↗). Run directly from a user query​ Tavily API key requiredWe will use a simple GET endpoint from Tavily in this section. Please sign up to obtain an API key from them (↗) and set it in the environment variable TAVILY_API_KEY. You can also run a plan immediately from the user query, without examining the Plan object in between. This would generate a plan as an intermediate step as well but will also immediately spawn a plan run from it. You would simply use the run method from your Portia instance class like so: main.pyfrom dotenv import load_dotenvfrom portia import ( Portia, example_tool_registry,)load_dotenv()# Instantiate a Portia instance. Load it with the default config and with the example tools.portia = Portia(tools=example_tool_registry)# Generate the plan from the user queryplan_run = portia.run('Which stock price grew faster in 2024, Amazon or Google?')# Serialise into JSON and print the outputprint(plan_run.model_dump_json(indent=2)) Track plan run states in logsYou can track plan run state changes live as they occur through the logs by setting default_log_level to DEBUG in the Config of your Portia instance (Manage logging ↗). Run a plan stored in Portia cloud​ When you set the storage_class property to CLOUD in the config of your Portia instance (see Manage storage options ↗ for more details), plans will automatically be stored in the cloud once created. You can then easily retrieve plans from storage in order to run them: from dotenv import load_dotenvfrom portia import ( Portia, default_config, Config, StorageClass, PlanUUID)# Load the Portia API keyload_dotenv()# Set up the Portia instance to use cloud storageconfig = Config.from_default(storage_class=StorageClass.CLOUD)portia = Portia(config=config)# This will create a plan that is stored in Portia Cloudplan = portia.plan('Which stock price grew faster in 2024, Amazon or Google?')# We can then either run the plan directly from the object...run = portia.run_plan(plan=plan)# Or we can use the ID so that the plan is loaded from storagerun = portia.run_plan(plan=PlanUUID.from_string(\"plan-f8003b53-9b62-44e2-ac67-887146c07949\")) This can be very useful if you want to run a plan from a different process to the one that created the plan.Overview of plan runs in PortiaPlan run state changesRun from a pre-expressed planRun directly from a user queryRun a plan stored in Portia cloud",
      "timestamp": "2025-08-24 06:48:36"
    },
    {
      "url": "https://docs.portialabs.ai/install",
      "title": "Install and setup | Portia AI Docs",
      "content": "Install and setup | Portia AI Docs Skip to main contentOn this page Let's get you set up and run a test query to make sure everything is in order. RequirementsPortia requires python v3.11 and above. If you need to update your python version please visit their docs. If you are unsure what python version you have, you can check usingpython3 --version Install the Portia Python SDK​ Run the following command to install our SDK and its dependencies. The command below assumes you're using pip as your installer. For poetry the install command would be poetry add ... and for uv it's uv add .... The args otherwise remain the same. pip install portia-sdk-python Out of the box the SDK comes with dependencies for OpenAI (and Azure OpenAI) + Anthropic. We additionally support Amazon Bedrock, Mistral and Google GenAI (Gemini). These dependencies can be added with: pip install \"portia-sdk-python[all]\"# Or only with Amazon Bedrock extra dependenciespip install \"portia-sdk-python[amazon]\"# Or only with Google GenAI extra dependenciespip install \"portia-sdk-python[google]\"# Or only with Mistral extra dependenciespip install \"portia-sdk-python[mistral]\" Configure access to your preferred LLM​ Set environment variables to connect to one of our currently supported LLMs. We are currently expanding this list. See Configure LLM options ↗ for more information on how to configure Portia for different LLM providers and models. Open AIAnthropicMistralGoogle GenAIAzure OpenAIAmazon Bedrockgpt-4.1 is set as the default model. You can sign up to their platform hereexport OPENAI_API_KEY='your-api-key-here'sonnet-3.7 and `sonnet-3.5 are both used by default. You can sign up to their platform hereexport ANTHROPIC_API_KEY='your-api-key-here'mistral-large-latest is set as the default model. You can sign up to their platform hereEnsure Mistral dependencies are installed with pip install \"portia-sdk-python[mistral]\" or \"portia-sdk-python[all]\"export MISTRAL_API_KEY='your-api-key-here'gemini-2.5-pro and gemini-2.5-flash are both used by default. You can sign up to their platform hereEnsure Google GenAI dependencies are installed with pip install \"portia-sdk-python[google]\" or \"portia-sdk-python[all]\"export GOOGLE_API_KEY='your-api-key-here'gpt-4.1 is set as the default model. You can sign up to their platform hereexport AZURE_OPENAI_API_KEY='your-api-key-here'export AZURE_OPENAI_ENDPOINT='your-api-key-here'eu.anthropic.claude-3-7-sonnet-20250219-v1:0 is set as the default model. You can sign up to their platform hereEnsure Amazon dependencies are installed with pip install \"portia-sdk-python[amazon]\" or \"portia-sdk-python[all]\"export AWS_ACCESS_KEY_ID = 'your-access-key-id'export AWS_SECRET_ACCESS_KEY = 'your-secret-access-key'export AWS_DEFAULT_REGION = 'your-default-region'# OR if you want using you ~/.aws/credentialsexport AWS_CREDENTIALS_PROFILE_NAME = 'your-credentials-profile-name' Test your installation from the command line​ Let's submit a basic prompt to your LLM using our framework to make sure it's all working fine. We will submit a simple maths question, which should invoke one of the open source tools in our SDK: Open AIAnthropicMistralGoogle GenAIAzure OpenAIAmazon BedrockOpen AI is the default LLM provider. Just run:portia-cli run \"add 1 + 2\"To use Anthropic from the CLI, just run:portia-cli run --llm-provider=\"anthropic\" \"add 1 + 2\"To use Mistral from the CLI, just run:portia-cli run --llm-provider=\"mistralai\" \"add 1 + 2\"To use Google GenAI from the CLI, just run:portia-cli run --llm-provider=\"google\" \"add 1 + 2\"To use Azure OpenAI from the CLI, just run:portia-cli run --llm-provider=\"azure-openai\" \"add 1 + 2\"To use Amazon Bedrock models from the CLI, just run:portia-cli run --llm-provider=\"amazon\" \"add 1 + 2\" Are you stuck? Try this 😅Remember to use the command specific to your installer. The instructions above are for pip specifically. For other installers use one of the commands below (args don't change): For poetry, the run command is poetry run portia-cli .... For uv, the run command is uv run portia-cli .... Make sure you're in the right directory or venv as well (where your lock file is)! Portia will return the final state of the plan run created in response to the submitted prompt. We will delve into plan run states more deeply in a later section but for now you want to be sure you can see \"state\": \"COMPLETE\" and the answer to your maths question e.g. \"final_output\": {\"value\": 3.0} as part of that returned state. Here's an example output: { \"id\": \"prun-13a97e70-2ca6-41c9-bc49-b7f84f6d3982\", \"plan_id\": \"plan-96693022-598e-458c-8d2f-44ba51d4f0b5\", \"current_step_index\": 0, \"clarifications\": [], \"state\": \"COMPLETE\", \"step_outputs\": { \"$result\": { \"value\": 3.0 } }, \"final_output\": { \"value\": 3.0 }} Test your installation from a Python file​ As a final verification step for your installation, set up the required environment variables in the .env of a project directory of your choice, namely the relevant LLM API keys. We can now replicate the CLI-driven test above from a python file within that directory. Open AIAnthropicMistralGoogle GenAIAmazon BedrockAzure OpenAIIn your local .env file, set up your API key as an environment variable using OPENAI_API_KEY. Then create a file e.g. main.py in your project directory and paste the following code in.main.pyfrom dotenv import load_dotenvfrom portia import ( Portia, default_config, example_tool_registry,)load_dotenv()# Instantiate Portia with the default config which uses Open AI, and with some example tools.portia = Portia(tools=example_tool_registry)# Run the test query and print the output!plan_run = portia.run('add 1 + 2')print(plan_run.model_dump_json(indent=2))In your local .env file, set up your API key as an environment variable using ANTHROPIC_API_KEY. Then create a file e.g. main.py in your project directory and paste the following code in.main.pyimport osfrom dotenv import load_dotenvfrom portia import ( Config, LLMProvider, Portia, example_tool_registry,)load_dotenv()ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')# Create a default Portia config with LLM provider set to Anthropic and to the Sonnet 3.5 modelanthropic_config = Config.from_default( llm_provider=LLMProvider.ANTHROPIC, default_model=\"anthropic/claude-3-5-sonnet-latest\", anthropic_api_key=ANTHROPIC_API_KEY)# Instantiate a Portia instance. Load it with the config and with the example tools.portia = Portia(config=anthropic_config, tools=example_tool_registry)# Run the test query and print the output!plan_run = portia.run('add 1 + 2')print(plan_run.model_dump_json(indent=2))In your local .env file, set up your API key as an environment variable using MISTRAL_API_KEY. Then create a file e.g. main.py in your project directory and paste the following code in.main.pyimport osfrom dotenv import load_dotenvfrom portia import ( Config, LLMProvider, Portia, example_tool_registry,)load_dotenv()MISTRAL_API_KEY = os.getenv('MISTRAL_API_KEY')# Create a default Portia config with LLM provider set to Mistral AI and the latest Mistral Large modelmistral_config = Config.from_default( llm_provider=LLMProvider.MISTRALAI, default_model=\"mistralai/mistral-large-latest\", mistralai_api_key=MISTRAL_API_KEY)# Instantiate a Portia instance. Load it with the config and with the example tools.portia = Portia(config=mistral_config, tools=example_tool_registry)# Run the test query and print the output!plan_run = portia.run('add 1 + 2')print(plan_run.model_dump_json(indent=2))In your local .env file, set up your API key as an environment variable using GOOGLE_API_KEY. Then create a file e.g. main.py in your project directory and paste the following code in.main.pyimport osfrom dotenv import load_dotenvfrom portia import ( Config, LLMProvider, Portia, example_tool_registry,)load_dotenv()GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')# Create a default Portia config with LLM provider set to Google GenAI and model set to Gemini 2.0 Flashgoogle_config = Config.from_default( llm_provider=LLMProvider.GOOGLE, default_model=\"google/gemini-2.0-flash\", google_api_key=GOOGLE_API_KEY)# Instantiate a Portia instance. Load it with the config and with the example tools.portia = Portia(config=google_config, tools=example_tool_registry)# Run the test query and print the output!plan_run = portia.run('add 1 + 2')print(plan_run.model_dump_json(indent=2))In your local .env file, set up your API key as an environment variable using AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_DEFAULT_REGION. You can also use the local aws credentials file e.g. ~/.aws/credentials by just specifying the aws_credentials_profile_name parameter. Then create a file e.g. main.py in your project directory and paste the following code in.main.pyimport osfrom dotenv import load_dotenvfrom portia import ( Config, LLMProvider, Portia, example_tool_registry,)load_dotenv()AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')AWS_DEFAULT_REGION = os.getenv('AWS_DEFAULT_REGION')# Create a default Portia config ussing aws access keys with LLM provider set to AMAZON and model set to anthropic within Bedrock (make sure you enable the model in your Bedrock model access settings).amazon_config = Config.from_default( llm_provider=LLMProvider.AMAZON, default_model=\"amazon/eu.anthropic.claude-sonnet-4-20250514-v1:0\", aws_access_key_id=AWS_ACCESS_KEY_ID, aws_secret_access_key=AWS_SECRET_ACCESS_KEY, aws_default_region=AWS_DEFAULT_REGION,)# Config using the aws_credentials_profile_name, if you're using ~/.aws/credentials (generated by `aws configure`).AWS_CREDENTIALS_PROFILE_NAME = os.getenv('AWS_CREDENTIALS_PROFILE_NAME') | \"default\"amazon_config2 = Config.from_default( llm_provider=LLMProvider.AMAZON, default_model=\"amazon/eu.anthropic.claude-sonnet-4-20250514-v1:0\", aws_credentials_profile_name=AWS_CREDENTIALS_PROFILE_NAME,)portia = Portia(config=amazon_config, tools=example_tool_registry)# Run the test query and print the output!plan_run = portia.run('add 1 + 2')print(plan_run.model_dump_json(indent=2))In your local .env file, set up your API key and API endpoint as environment variables using AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT. Then create a file e.g. main.py in your project directory and paste the following code in.main.pyimport osfrom dotenv import load_dotenvfrom portia import ( Config, LLMProvider, Portia, example_tool_registry,)load_dotenv()AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')# Create a default Portia config with LLM provider set to Azure OpenAI and model to GPT 4oazure_config = Config.from_default( llm_provider=LLMProvider.AZURE_OPENAI, default_model=\"azure-openai/gpt-4o\", azure_openai_api_key=AZURE_OPENAI_API_KEY, azure_openai_endpoint=AZURE_OPENAI_ENDPOINT,)# Instantiate a Portia instance. Load it with the config and with the example tools.portia = Portia(config=azure_config, tools=example_tool_registry)# Run the test query and print the output!plan_run = portia.run('add 1 + 2')print(plan_run.model_dump_json(indent=2)) You should see a similar output to the the CLI-driven test we ran in step 4. We will review the various elements in main.py in more detail in later sections. For now you should remember that: You will use a Portia instance to handle user prompts. A Portia instance expects a Config. This is where you can specify things like the model you want to use and where you want to store plan runs. A Portia instance also expects tools. This can be a list of tools, or a ToolRegistry (i.e a collection of tools you want to use). If you got this far then we're off to the races 🐎. Let's get you set up with a Portia account so you can also use our cloud features. Don't worry it comes with a free trial (Pricing page ↗) 😉Install the Portia Python SDKConfigure access to your preferred LLMTest your installation from the command lineTest your installation from a Python file",
      "timestamp": "2025-08-24 06:48:39"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-request",
      "title": "Zendesk - Requests: Show | Portia AI Docs",
      "content": "Zendesk - Requests: Show | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:requests:show Tool description: Retrieves information about a specific request in Zendesk. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Args schema: { \"description\": \"Input schema for ZendeskShowRequestTool.\", \"properties\": { \"request_id\": { \"description\": \"The ID of the request\", \"title\": \"Request Id\", \"type\": \"integer\" } }, \"required\": [ \"request_id\" ], \"title\": \"ZendeskShowRequestToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:48:42"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/",
      "title": "portia.portia | Portia AI Docs",
      "content": "portia.portia | Portia AI Docs Skip to main contentOn this pagePortia classes that plan and execute runs for queries. This module contains the core classes responsible for generating, managing, and executing plans in response to queries. The Portia class serves as the main entry point, orchestrating the planning and execution process. It uses various agents and tools to carry out tasks step by step, saving the state of the run at each stage. It also handles error cases, clarification requests, and run state transitions. The Portia class provides methods to: Generate a plan for executing a query. Create and manage runs. Execute runs step by step, using agents to handle the execution of tasks. Resolve clarifications required during the execution of runs. Wait for runs to reach a state where they can be resumed. Modules in this file work with different storage backends (memory, disk, cloud) and can handle complex queries using various planning and execution agent configurations. RunContext Objects​ class RunContext(BaseModel) Data that is returned from a step. Portia Objects​ class Portia() Portia client is the top level abstraction and entrypoint for most programs using the SDK. It is responsible for intermediating planning via PlanningAgents and execution via ExecutionAgents. __init__​ def __init__(config: Config | None = None, tools: ToolRegistry | list[Tool] | None = None, execution_hooks: ExecutionHooks | None = None, telemetry: BaseProductTelemetry | None = None) -> None Initialize storage and tools. Arguments: config Config - The configuration to initialize the Portia client. If not provided, the default configuration will be used. tools ToolRegistry | list[Tool] - The registry or list of tools to use. If not provided, the open source tool registry will be used, alongside the default tools from Portia cloud if a Portia API key is set. execution_hooks ExecutionHooks | None - Hooks that can be used to modify or add extra functionality to the run of a plan. telemetry BaseProductTelemetry | None - Anonymous telemetry service. initialize_end_user​ def initialize_end_user(end_user: str | EndUser | None = None) -> EndUser Handle initializing the end_user based on the provided type. ainitialize_end_user​ async def ainitialize_end_user( end_user: str | EndUser | None = None) -> EndUser Handle initializing the end_user based on the provided type. run​ def run(query: str, tools: list[Tool] | list[str] | None = None, example_plans: Sequence[Plan | PlanUUID | str] | None = None, end_user: str | EndUser | None = None, plan_run_inputs: list[PlanInput] | list[dict[str, str]] | dict[str, str] | None = None, structured_output_schema: type[BaseModel] | None = None, use_cached_plan: bool = False) -> PlanRun End-to-end function to generate a plan and then execute it. This is the simplest way to plan and execute a query using the SDK. Arguments: query str - The query to be executed. tools list[Tool] | list[str] | None - List of tools to use for the query. If not provided all tools in the registry will be used. example_plans Sequence[Plan | PlanUUID | str] | None - Optional list of example plans or plan IDs. This can include Plan objects, PlanUUID objects, or plan ID strings (starting with \"plan-\"). Plan IDs will be loaded from storage. If not provided, a default set of example plans will be used. end_user str | EndUser | None = None - The end user for this plan run. plan_run_inputs (list[PlanInput] | list[dict[str, str]] | dict[str, str] | None): Provides input values for the run. This can be a list of PlanInput objects, a list of dicts with keys \"name\", \"description\" (optional) and \"value\", or a dict of plan run input name to value. structured_output_schema type[BaseModel] | None - The optional structured output schema for the query. This is passed on to plan runs created from this plan but will not be stored with the plan itself if using cloud storage and must be re-attached to the plan run if using cloud storage. use_cached_plan bool - Whether to use a cached plan if it exists. Returns: PlanRun - The run resulting from executing the query. arun​ async def arun(query: str, tools: list[Tool] | list[str] | None = None, example_plans: Sequence[Plan | PlanUUID | str] | None = None, end_user: str | EndUser | None = None, plan_run_inputs: list[PlanInput] | list[dict[str, str]] | dict[str, str] | None = None, structured_output_schema: type[BaseModel] | None = None, use_cached_plan: bool = False) -> PlanRun End-to-end function to generate a plan and then execute it. This is the simplest way to plan and execute a query using the SDK. Arguments: query str - The query to be executed. tools list[Tool] | list[str] | None - List of tools to use for the query. If not provided all tools in the registry will be used. example_plans Sequence[Plan | PlanUUID | str] | None - Optional list of example plans or plan IDs. This can include Plan objects, PlanUUID objects, or plan ID strings (starting with \"plan-\"). Plan IDs will be loaded from storage. If not provided, a default set of example plans will be used. end_user str | EndUser | None = None - The end user for this plan run. plan_run_inputs (list[PlanInput] | list[dict[str, str]] | dict[str, str] | None): Provides input values for the run. This can be a list of PlanInput objects, a list of dicts with keys \"name\", \"description\" (optional) and \"value\", or a dict of plan run input name to value. structured_output_schema type[BaseModel] | None - The optional structured output schema for the query. This is passed on to plan runs created from this plan but will not be stored with the plan itself if using cloud storage and must be re-attached to the plan run if using cloud storage. use_cached_plan bool - Whether to use a cached plan if it exists. Returns: PlanRun - The run resulting from executing the query. plan​ def plan(query: str, tools: list[Tool] | list[str] | None = None, example_plans: Sequence[Plan | PlanUUID | str] | None = None, end_user: str | EndUser | None = None, plan_inputs: list[PlanInput] | list[dict[str, str]] | list[str] | None = None, structured_output_schema: type[BaseModel] | None = None, use_cached_plan: bool = False) -> Plan Plans how to do the query given the set of tools and any examples. Arguments: query str - The query to generate the plan for. tools list[Tool] | list[str] | None - List of tools to use for the query. If not provided all tools in the registry will be used. example_plans Sequence[Plan | PlanUUID | str] | None - Optional list of example plans or plan IDs. This can include Plan objects, PlanUUID objects, or plan ID strings (starting with \"plan-\"). Plan IDs will be loaded from storage. If not provided, a default set of example plans will be used. end_user str | EndUser | None = None - The optional end user for this plan. plan_inputs list[PlanInput] | list[dict[str, str]] | list[str] | None - Optional list of inputs required for the plan. This can be a list of Planinput objects, a list of dicts with keys \"name\" and \"description\" (optional), or a list of plan run input names. If a value is provided with a PlanInput object or in a dictionary, it will be ignored as values are only used when running the plan. structured_output_schema type[BaseModel] | None - The optional structured output schema for the query. This is passed on to plan runs created from this plan but will be not be stored with the plan itself if using cloud storage and must be re-attached to the plan run if using cloud storage. use_cached_plan bool - Whether to use a cached plan if it exists. Returns: Plan - The plan for executing the query. Raises: PlanError - If there is an error while generating the plan. aplan​ async def aplan(query: str, tools: list[Tool] | list[str] | None = None, example_plans: Sequence[Plan | PlanUUID | str] | None = None, end_user: str | EndUser | None = None, plan_inputs: list[PlanInput] | list[dict[str, str]] | list[str] | None = None, structured_output_schema: type[BaseModel] | None = None, use_cached_plan: bool = False) -> Plan Plans how to do the query given the set of tools and any examples asynchronously. Arguments: query str - The query to generate the plan for. tools list[Tool] | list[str] | None - List of tools to use for the query. If not provided all tools in the registry will be used. example_plans list[Plan] | None - Optional list of example plans. If not provide a default set of example plans will be used. end_user str | EndUser | None = None - The optional end user for this plan. plan_inputs list[PlanInput] | list[dict[str, str]] | list[str] | None - Optional list of inputs required for the plan. This can be a list of Planinput objects, a list of dicts with keys \"name\" and \"description\" (optional), or a list of plan run input names. If a value is provided with a PlanInput object or in a dictionary, it will be ignored as values are only used when running the plan. structured_output_schema type[BaseModel] | None - The optional structured output schema for the query. This is passed on to plan runs created from this plan but will be not be stored with the plan itself if using cloud storage and must be re-attached to the plan run if using cloud storage. use_cached_plan bool - Whether to use a cached plan if it exists. Returns: Plan - The plan for executing the query. Raises: PlanError - If there is an error while generating the plan. run_plan​ def run_plan( plan: Plan | PlanUUID | UUID | PlanV2, end_user: str | EndUser | None = None, plan_run_inputs: list[PlanInput] | list[dict[str, Serializable]] | dict[str, Serializable] | None = None, structured_output_schema: type[BaseModel] | None = None) -> PlanRun Run a plan. Arguments: plan Plan | PlanUUID | UUID | PlanV2 - The plan to run, or the ID of the plan to load from storage. end_user str | EndUser | None = None - The end user to use. plan_run_inputs (list[PlanInput] | list[dict[str, Serializable]] | dict[str, Serializable] | None): Provides input values for the run. This can be a list of PlanInput objects, a list of dicts with keys \"name\", \"description\" (optional) and \"value\", or a dict of plan run input name to value. structured_output_schema type[BaseModel] | None - The optional structured output schema for the plan run. This is passed on to plan runs created from this plan but will be Returns: PlanRun - The resulting PlanRun object. arun_plan​ async def arun_plan( plan: Plan | PlanUUID | UUID | PlanV2, end_user: str | EndUser | None = None, plan_run_inputs: list[PlanInput] | list[dict[str, Serializable]] | dict[str, Serializable] | None = None, structured_output_schema: type[BaseModel] | None = None) -> PlanRun Run a plan asynchronously. Arguments: plan Plan | PlanUUID | UUID - The plan to run, or the ID of the plan to load from storage. end_user str | EndUser | None = None - The end user to use. plan_run_inputs (list[PlanInput] | list[dict[str, Serializable]] | dict[str, Serializable] | None): Provides input values for the run. This can be a list of PlanInput objects, a list of dicts with keys \"name\", \"description\" (optional) and \"value\", or a dict of plan run input name to value. structured_output_schema type[BaseModel] | None - The optional structured output schema for the plan run. This is passed on to plan runs created from this plan but will be Returns: PlanRun - The resulting PlanRun object. resume​ def resume(plan_run: PlanRun | None = None, plan_run_id: PlanRunUUID | str | None = None, plan: PlanV2 | None = None) -> PlanRun Resume a PlanRun. If a clarification handler was provided as part of the execution hooks, it will be used to handle any clarifications that are raised during the execution of the plan run. If no clarification handler was provided and a clarification is raised, the run will be returned in the NEED_CLARIFICATION state. The clarification will then need to be handled by the caller before the plan run is resumed. Arguments: plan_run PlanRun | None - The PlanRun to resume. Defaults to None. plan_run_id RunUUID | str | None - The ID of the PlanRun to resume. Defaults to None. plan PlanV2 | None - If using a plan built with the Plan Builder, the plan must be passed in here in order to resume. Returns: PlanRun - The resulting PlanRun after execution. Raises: ValueError - If neither plan_run nor plan_run_id is provided. InvalidPlanRunStateError - If the plan run is not in a valid state to be resumed. aresume​ async def aresume(plan_run: PlanRun | None = None, plan_run_id: PlanRunUUID | str | None = None, plan: PlanV2 | None = None) -> PlanRun Resume a PlanRun. If a clarification handler was provided as part of the execution hooks, it will be used to handle any clarifications that are raised during the execution of the plan run. If no clarification handler was provided and a clarification is raised, the run will be returned in the NEED_CLARIFICATION state. The clarification will then need to be handled by the caller before the plan run is resumed. Arguments: plan_run PlanRun | None - The PlanRun to resume. Defaults to None. plan_run_id RunUUID | str | None - The ID of the PlanRun to resume. Defaults to None. plan PlanV2 | None - If using a plan built with the Plan Builder, the plan must be passed in here in order to resume. Returns: PlanRun - The resulting PlanRun after execution. Raises: ValueError - If neither plan_run nor plan_run_id is provided. InvalidPlanRunStateError - If the plan run is not in a valid state to be resumed. execute_plan_run_and_handle_clarifications​ def execute_plan_run_and_handle_clarifications(plan: Plan, plan_run: PlanRun) -> PlanRun Execute a plan run and handle any clarifications that are raised. aexecute_plan_run_and_handle_clarifications​ async def aexecute_plan_run_and_handle_clarifications( plan: Plan, plan_run: PlanRun) -> PlanRun Execute a plan run and handle any clarifications that are raised. resolve_clarification​ def resolve_clarification(clarification: Clarification, response: object, plan_run: PlanRun) -> PlanRun Resolve a clarification updating the run state as needed. Arguments: clarification Clarification - The clarification to resolve. response object - The response to the clarification. plan_run PlanRun | None - Optional - the plan run being updated. Returns: PlanRun - The updated PlanRun. error_clarification​ def error_clarification(clarification: Clarification, error: object, plan_run: PlanRun) -> PlanRun Mark that there was an error handling the clarification. wait_for_ready​ def wait_for_ready(plan_run: PlanRun, max_retries: int = 6, backoff_start_time_seconds: int = 7 * 60, backoff_time_seconds: int = 2) -> PlanRun Wait for the run to be in a state that it can be re-plan_run. This is generally because there are outstanding clarifications that need to be resolved. Arguments: plan_run PlanRun - The PlanRun to wait for. max_retries int - The maximum number of retries to wait for the run to be ready after the backoff period starts. backoff_start_time_seconds int - The time after which the backoff period starts. backoff_time_seconds int - The time to wait between retries after the backoff period starts. Returns: PlanRun - The updated PlanRun once it is ready to be re-plan_run. Raises: InvalidRunStateError - If the run cannot be waited for. create_plan_run​ def create_plan_run(plan: Plan, end_user: str | EndUser | None = None, plan_run_inputs: list[PlanInput] | None = None) -> PlanRun Create a PlanRun from a Plan. Arguments: plan Plan - The plan to create a plan run from. end_user str | EndUser | None = None - The end user this plan run is for. plan_run_inputs list[PlanInput] | None = None - The plan inputs for the plan run with their values. Returns: PlanRun - The created PlanRun object. acreate_plan_run​ async def acreate_plan_run( plan: Plan, end_user: str | EndUser | None = None, plan_run_inputs: list[PlanInput] | None = None) -> PlanRun Create a PlanRun from a Plan. Arguments: plan Plan - The plan to create a plan run from. end_user str | EndUser | None = None - The end user this plan run is for. plan_run_inputs list[PlanInput] | None = None - The plan inputs for the plan run with their values. Returns: PlanRun - The created PlanRun object. get_tool​ def get_tool(tool_id: str | None, plan_run: PlanRun) -> Tool | None Get the tool for a step. get_agent_for_step​ def get_agent_for_step(step: Step, plan: Plan, plan_run: PlanRun) -> BaseExecutionAgent Get the appropriate agent for executing a given step. Arguments: step Step - The step for which the agent is needed. plan Plan - The plan associated with the step. plan_run PlanRun - The run associated with the step. Returns: BaseAgent - The agent to execute the step. run_builder_plan​ @traceable(name=\"Portia - Run Plan\")async def run_builder_plan( plan: PlanV2, end_user: EndUser, plan_run_inputs: list[PlanInput] | list[dict[str, Serializable]] | dict[str, Serializable] | None = None, structured_output_schema: type[BaseModel] | None = None) -> PlanRun Run a Portia plan. resume_builder_plan​ async def resume_builder_plan(plan: PlanV2, plan_run: PlanRun, end_user: EndUser | None = None, legacy_plan: Plan | None = None) -> PlanRun Resume a Portia plan.RunContext ObjectsPortia Objects",
      "timestamp": "2025-08-24 06:48:45"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/tool_call",
      "title": "portia.tool_call | Portia AI Docs",
      "content": "portia.tool_call | Portia AI Docs Skip to main contentOn this pageTool Call module contains classes that record the outcome of a single tool call. The ToolCallStatus enum defines the various states a tool call can be in, such as in progress, successful, requiring clarification, or failing. The ToolCallRecord class is a Pydantic model used to capture details about a specific tool call, including its status, input, output, and associated metadata. ToolCallStatus Objects​ class ToolCallStatus(PortiaEnum) The status of the tool call. Attributes: IN_PROGRESS - The tool is currently in progress. NEED_CLARIFICATION - The tool raise a clarification. SUCCESS - The tool executed successfully. FAILED - The tool raised an error. ToolCallRecord Objects​ class ToolCallRecord(BaseModel) Model that records the details of an individual tool call. This class captures all relevant information about a single tool call within a PlanRun including metadata, input and output data, and status. Attributes: tool_name str - The name of the tool being called. plan_run_id RunUUID - The unique identifier of the run to which this tool call belongs. step int - The step number of the tool call in the PlanRun. end_user_id str | None - The ID of the end user, if applicable. Can be None. status ToolCallStatus - The current status of the tool call (e.g., IN_PROGRESS, SUCCESS). input Any - The input data passed to the tool call. output Any - The output data returned from the tool call. latency_seconds float - The latency in seconds for the tool call to complete. serialize_input​ def serialize_input() -> Any Handle serialization of inputs. serialize_output​ def serialize_output() -> Any Handle serialization of outputs.ToolCallStatus ObjectsToolCallRecord Objects",
      "timestamp": "2025-08-24 06:48:48"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs/docs-get-structured-document",
      "title": "Google Docs - Docs: Get Structured Document | Portia AI Docs",
      "content": "Google Docs - Docs: Get Structured Document | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:docs:get_structured_document Tool description: Get a document from Google Docs in a machine readable format. Do not use unless you reallyneed a structured document. Args schema: { \"description\": \"Schema for the Google Docs get document tool.\", \"properties\": { \"document_id\": { \"description\": \"The ID of the document to get. It can contain letters, numbers, and some special characters.\", \"title\": \"Document Id\", \"type\": \"string\" } }, \"required\": [ \"document_id\" ], \"title\": \"GoogleDocsGetStructuredDocumentToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Containing information about the document in a structured format.Includes title, a structured body and other metadata like file type')UsageTool details",
      "timestamp": "2025-08-24 06:48:51"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/token_check",
      "title": "portia.token_check | Portia AI Docs",
      "content": "portia.token_check | Portia AI Docs Skip to main contentOn this pageToken counting utilities with fallback for offline environments. estimate_tokens​ def estimate_tokens(text: str) -> int Estimate the number of tokens in a string using character-based estimation. We used to do a proper count using tiktoken, but that loads encodings from the internet at runtime, which doens't work in environments where we don't have internet access / where network access is locked down. As our current usages only require an estimate, this suffices for now. exceeds_context_threshold​ def exceeds_context_threshold(value: Any, model: GenerativeModel, threshold_percentage: float = 1) -> bool Check if a value is under a given threshold percentage of a model's context window size. Arguments: value - The value to check (will be converted to string for token estimation) model - The generative model to get context window size from threshold_percentage - A percentage threshold to apply. For example, 0.9 means that this will return True if the value exceeds 90% of the context window size. Returns: bool - True if the estimated tokens are less than the threshold, False otherwise",
      "timestamp": "2025-08-24 06:48:54"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/browser_tool",
      "title": "portia.open_source_tools.browser_tool | Portia AI Docs",
      "content": "portia.open_source_tools.browser_tool | Portia AI Docs Skip to main contentOn this pageBrowser tools. This module contains tools that can be used to navigate to a URL, authenticate the user, and complete tasks. The browser tool can run locally or using Browserbase. If using Browserbase, a Browserbase API key is required and project ID is required, and the tool can handle separate end user authentication. The browser tool can be used to navigate to a URL and complete tasks. If authentication is required, the tool will return an ActionClarification with the user guidance and login URL. If authentication is not required, the tool will return the task output. It uses (BrowserUse)[https://browser-use.com/] for the task navigation. BrowserToolForUrlSchema Objects​ class BrowserToolForUrlSchema(BaseModel) Input schema for the BrowserToolForUrl. This schema defines the expected input parameters for the BrowserToolForUrl class. Attributes: task str - The task description that should be performed by the browser tool. This is a required field that specifies what actions should be taken on the predefined URL. task_data list[Any] | str | None - Task data that should be used to complete the task. Can be a string, a list of strings, or a list of objects that will be converted to strings. Important: This should include all relevant data in their entirety, from the first to the last character (i.e. NOT a summary). BrowserToolSchema Objects​ class BrowserToolSchema(BaseModel) Input schema for the BrowserTool. This schema defines the expected input parameters for the BrowserTool class. Attributes: url str - The URL that the browser tool should navigate to. This is a required field specifying the target webpage. task str - The task description that should be performed by the browser tool. This is a required field that specifies what actions should be taken on the provided URL. task_data list[Any] | str | None - Task data that should be used to complete the task. Can be a string, a list of strings, or a list of objects that will be converted to strings. Important: This should include all relevant data in their entirety, from the first to the last character (i.e. NOT a summary). BrowserTaskOutput Objects​ class BrowserTaskOutput(BaseModel, Generic[T]) Output schema for browser task execution. This class represents the response from executing a browser task, including both the task result and any authentication requirements. Attributes: task_output T - The result or output from executing the requested task. human_login_required bool - Indicates if manual user authentication is needed. Defaults to False. login_url str, optional - The URL where the user needs to go to authenticate. Only provided when human_login_required is True. user_login_guidance str, optional - Instructions for the user on how to complete the login process. Only provided when human_login_required is True. BrowserInfrastructureOption Objects​ class BrowserInfrastructureOption(Enum) Enumeration of supported browser infrastructure providers. This enum defines the available options for running browser automation tasks. Attributes: LOCAL - Uses a local Chrome browser instance for automation. Suitable for development and testing. BROWSERBASE - Uses the Browserbase cloud service for automation. Provides better scalability and isolation between users. BrowserTool Objects​ class BrowserTool(Tool[str | BaseModel]) General purpose browser tool. Customizable to user requirements. This tool is designed to be used for tasks that require a browser. If authentication is required, the tool will return an ActionClarification with the user guidance and login URL. If authentication is not required, the tool will return the task output. It uses (BrowserUse)[https://browser-use.com/] for the task navigation. When using the tool, you should ensure that once the user has authenticated, that they indicate that authentication is completed and resume the plan run. The tool supports both local and BrowserBase infrastructure providers for running the web based tasks. If using local, a local Chrome instance will be used, and the tool will not support end_user_id. If using BrowserBase, a BrowserBase API key is required and the tool can handle separate end users. The infrastructure provider can be specified using the infrastructure_option argument. Arguments: id str, optional - Custom identifier for the tool. Defaults to \"browser_tool\". name str, optional - Display name for the tool. Defaults to \"Browser Tool\". description str, optional - Custom description of the tool's purpose. Defaults to a general description of the browser tool's capabilities. infrastructure_option BrowserInfrastructureOption, optional - The infrastructure provider to use. Can be either BrowserInfrastructureOption.LOCAL or BrowserInfrastructureOption.REMOTE. Defaults to BrowserInfrastructureOption.REMOTE. custom_infrastructure_provider BrowserInfrastructureProvider, optional - A custom infrastructure provider to use. If not provided, the infrastructure provider will be resolved from the infrastructure_option argument. id0 BaseModel, optional - A Pydantic model to use for structured output. If not provided, the tool will return a string. infrastructure_provider​ @cached_propertydef infrastructure_provider() -> BrowserInfrastructureProvider Get the infrastructure provider instance (cached). process_task_data​ @staticmethoddef process_task_data(task_data: list[Any] | str | None) -> str Process task_data into a string, handling different input types. Arguments: task_data - Data that can be a None, a string or a list of objects. Returns: A string representation of the data, with list items joined by newlines. run​ def run( ctx: ToolRunContext, url: str, task: str, task_data: list[Any] | str | None = None) -> str | BaseModel | ActionClarification Run the BrowserTool. arun​ async def arun( ctx: ToolRunContext, url: str, task: str, task_data: list[Any] | str | None = None) -> str | BaseModel | ActionClarification Run the BrowserTool asynchronously. BrowserToolForUrl Objects​ class BrowserToolForUrl(BrowserTool) Browser tool for a specific URL. This tool is designed to be used for browser-based tasks on the specified URL. If authentication is required, the tool will return an ActionClarification with the user guidance and login URL. If authentication is not required, the tool will return the task output. It uses (BrowserUse)[https://browser-use.com/] for the task navigation. When using the tool, the developer should ensure that once the user has completed authentication, that they resume the plan run. The tool supports both local and BrowserBase infrastructure providers for running the web based tasks. If using local, a local Chrome instance will be used, and the tool will not support end_user_id. If using BrowserBase, a BrowserBase API key is required and the tool can handle separate end users. The infrastructure provider can be specified using the infrastructure_option argument. Arguments: url str - The URL that this browser tool will navigate to for all tasks. id str, optional - Custom identifier for the tool. If not provided, will be generated based on the URL's domain. name str, optional - Display name for the tool. If not provided, will be generated based on the URL's domain. description str, optional - Custom description of the tool's purpose. If not provided, will be generated with the URL. infrastructure_option BrowserInfrastructureOption, optional - The infrastructure provider to use. Can be either BrowserInfrastructureOption.LOCAL or BrowserInfrastructureOption.REMOTE. Defaults to BrowserInfrastructureOption.REMOTE. custom_infrastructure_provider BrowserInfrastructureProvider, optional - A custom infrastructure provider to use. If not provided, the infrastructure provider will be resolved from the infrastructure_option argument. __init__​ def __init__( url: str, id: str | None = None, name: str | None = None, description: str | None = None, model: GenerativeModel | None | str = NotSet, infrastructure_option: BrowserInfrastructureOption | None = NotSet) -> None Initialize the BrowserToolForUrl. run​ def run( ctx: ToolRunContext, task: str, task_data: list[Any] | str | None = None) -> str | BaseModel | ActionClarification Run the BrowserToolForUrl. BrowserInfrastructureProvider Objects​ class BrowserInfrastructureProvider(ABC) Abstract base class for browser infrastructure providers. setup_browser​ @abstractmethoddef setup_browser(ctx: ToolRunContext) -> Browser Get a Browser instance. This is called at the start of every step using this tool. construct_auth_clarification_url​ @abstractmethoddef construct_auth_clarification_url(ctx: ToolRunContext, sign_in_url: str) -> HttpUrl Construct the URL for the auth clarification. step_complete​ @abstractmethoddef step_complete(ctx: ToolRunContext) -> None Call when the step is complete to e.g. release the session if needed. BrowserInfrastructureProviderLocal Objects​ class BrowserInfrastructureProviderLocal(BrowserInfrastructureProvider) Browser infrastructure provider for local browser instances. __init__​ def __init__(chrome_path: str | None = None, extra_chromium_args: list[str] | None = None) -> None Initialize the BrowserInfrastructureProviderLocal. setup_browser​ def setup_browser(ctx: ToolRunContext) -> Browser Get a Browser instance. Note: This provider does not support end_user_id. Arguments: ctx ToolRunContext - The context for the tool run, containing execution context and other relevant information. Returns: Browser - A configured Browser instance for local browser automation. construct_auth_clarification_url​ def construct_auth_clarification_url(ctx: ToolRunContext, sign_in_url: str) -> HttpUrl Construct the URL for the auth clarification. Arguments: ctx ToolRunContext - The context for the tool run, containing execution context and other relevant information. sign_in_url str - The URL that the user needs to sign in to. Returns: HttpUrl - The URL for the auth clarification, which in this case is simply the sign-in URL passed directly through. get_chrome_instance_path​ def get_chrome_instance_path() -> str Get the path to the Chrome instance based on the operating system or env variable. Returns: str - The path to the Chrome executable. First checks for the PORTIA_BROWSER_LOCAL_CHROME_EXEC environment variable, then falls back to default locations based on the operating system. Raises: RuntimeError - If the platform is not supported (not macOS, Windows, or Linux) and the env variable isn't set. step_complete​ def step_complete(ctx: ToolRunContext) -> None Call when the step is complete to e.g release the session. get_extra_chromium_args​ def get_extra_chromium_args() -> list[str] | None Get the extra Chromium arguments. Returns: list[str] | None: A list of extra Chromium arguments if the environment variable is set, otherwise None.BrowserToolForUrlSchema ObjectsBrowserToolSchema ObjectsBrowserTaskOutput ObjectsBrowserInfrastructureOption ObjectsBrowserTool ObjectsBrowserToolForUrl ObjectsBrowserInfrastructureProvider ObjectsBrowserInfrastructureProviderLocal Objects",
      "timestamp": "2025-08-24 06:48:57"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/gemini_langsmith_wrapper",
      "title": "portia.gemini_langsmith_wrapper | Portia AI Docs",
      "content": "portia.gemini_langsmith_wrapper | Portia AI Docs Skip to main contentOn this pageCustom LangSmith wrapper for Google Generative AI (Gemini). wrap_gemini​ def wrap_gemini(client: genai.Client) -> genai.Client Wrap a Google Generative AI model to enable LangSmith tracing.",
      "timestamp": "2025-08-24 06:49:00"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/",
      "title": "Zendesk Tools | Portia AI Docs",
      "content": "Zendesk Tools | Portia AI Docs Skip to main content Articles: Create CommentsCreate a comment on a zendesk article. Articles: ListList up to 100 Zendesk articles. An article is a piece of content that is createdby Zendesk. Use this tool to get articles without a search query. Articles: List CommentsReturns up to 100 comments made by all users on a specific article. Articles: SearchReturns up to 25 articles relevant to the search query, which must be provided. Articles: ShowShows the properties of a Zendesk article. An article is a piece of content that is created by Zendesk. Groups: List UsersReturns a list of memberships for a group. Memberships include the user ID and metadata about their membership in the group. Returns a maximum of 100 records. Groups: List for UserReturns a list of groups that a user (Agent or Admin) is a member of. Returns a maximum of 100 records. Groups: SearchSearch for groups in Zendesk. It can be a natural language query or use the syntax of the Zendesk API. Groups: ShowReturns a group. Organizations: SearchRetrieves a list of organizations in Zendesk matching the query. Organizations: ShowGets information about a specific organization in Zendesk. Posts: List CommentsLists all comments on a specific post. Posts: ShowGets information about a given post. A post is community content that is created by a user and is not the same as an article. Request Comments: ListLists comments on a Zendesk request. Returns a maximum of 100 comments. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Request Comments: ShowRetrieves information about a specific comment on a request in Zendesk. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Requests: SearchSearch for requests in Zendesk. Returns a maximum of 100 requests. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Requests: ShowRetrieves information about a specific request in Zendesk. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Sections: List ArticlesLists all articles in a given section of the Zendesk Help Center. Sections group related articles together. Sections: ShowReturns a section of the Zendesk Help Center articles. Sections group related articles together. Tickets: CountReturns an approximate count of tickets in the account. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Tickets: Count CommentsReturns an approximate count of the comments added to the ticket. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Tickets: CreateCreate a Zendesk Ticket. This populates the ticket with the provided subject and description. This should be followed up with calls to the ZendeskUpdateTicketTool to add or change details if needed. {SHARED_TICKET_DESCRIPTION} Tickets: List CommentsReturns the comments added to the ticket. Each comment may include a `content_url` for an attachment or a `recording_url` for a voice comment that points to a file that may be hosted externally. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Tickets: SearchSearches for tickets in Zendesk based on a natural language query or the Zendesk API syntax. Returns up to 1000 tickets that match the query. Tickets: ShowReturns a number of ticket properties though not the ticket comments. To get the comments, use the ZendeskListTicketCommentsTool. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Tickets: Show MetricsReturns metrics for a specific ticket, including first response time, full resolution time, number of reopens, and other performance metrics. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Tickets: UpdateUpdates an existing ticket in Zendesk with the provided details. For fields requiring group and user ID fields, use the ZendeskSearchGroupsTool and ZendeskSearchUsersTool to get the IDs. This tool can be run once with multiple details updated on the ticket or multiple times with a single detail updated on the ticket. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Users: SearchReturns an array of users who meet the search criteria. Returns a maximum of 100 users. This may include (but is not limited to) the user's name, contact information, role, permissions, locale, organization, and other information. Users: ShowReturns information about a specific user in Zendesk.",
      "timestamp": "2025-08-24 06:49:03"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/builder/plan_builder_v2",
      "title": "portia.builder.plan_builder_v2 | Portia AI Docs",
      "content": "portia.builder.plan_builder_v2 | Portia AI Docs Skip to main contentOn this pageBuilder for Portia plans. PlanBuilderError Objects​ class PlanBuilderError(ValueError) Error in Plan definition. PlanBuilderV2 Objects​ class PlanBuilderV2() Builder for Portia plans. __init__​ def __init__(label: str = \"Run the plan built with the Plan Builder\") -> None Initialize the builder. Arguments: label - The label of the plan. This is used to identify the plan in the Portia dashboard. input​ def input(*, name: str, description: str | None = None, default_value: Any | None = None) -> PlanBuilderV2 Add an input to the plan. Arguments: name - The name of the input. description - The description of the input. default_value - The default value of the input. if_​ def if_(condition: Callable[..., bool] | str, args: dict[str, Any] | None = None) -> PlanBuilderV2 Add a step that checks a condition. else_if_​ def else_if_(condition: Callable[..., bool], args: dict[str, Any] | None = None) -> PlanBuilderV2 Add a step that checks a condition. else_​ def else_() -> PlanBuilderV2 Add a step that checks a condition. endif​ def endif() -> PlanBuilderV2 Exit a conditional block. llm_step​ def llm_step(*, task: str, inputs: list[Any] | None = None, output_schema: type[BaseModel] | None = None, step_name: str | None = None) -> PlanBuilderV2 Add a step that sends a query to the underlying LLM. Arguments: task - The task to perform. inputs - The inputs to the task. The inputs can be references to previous step outputs / plan inputs (using StepOutput / Input) or just plain values. They are passed in as additional context to the LLM when it is completing the task. output_schema - The schema of the output. step_name - Optional name for the step. If not provided, will be auto-generated. invoke_tool_step​ def invoke_tool_step(*, tool: str | Tool, args: dict[str, Any] | None = None, output_schema: type[BaseModel] | None = None, step_name: str | None = None) -> PlanBuilderV2 Add a step that directly invokes a tool. Arguments: tool - The tool to invoke. Should either be the id of the tool to call, the Tool instance to call, or a python function that should be called. args - The arguments to the tool. If any of these values are instances of StepOutput or Input, the corresponding values will be substituted in when the plan is run. output_schema - The schema of the output. step_name - Optional name for the step. If not provided, will be auto-generated. function_step​ def function_step(*, function: Callable[..., Any], args: dict[str, Any] | None = None, output_schema: type[BaseModel] | None = None, step_name: str | None = None) -> PlanBuilderV2 Add a step that directly invokes a function. Arguments: function - The function to invoke. args - The arguments to the function. If any of these values are instances of StepOutput or Input, the corresponding values will be substituted in when the plan is run. output_schema - The schema of the output. step_name - Optional name for the step. If not provided, will be auto-generated. single_tool_agent_step​ def single_tool_agent_step(*, tool: str, task: str, inputs: list[Any] | None = None, output_schema: type[BaseModel] | None = None, step_name: str | None = None) -> PlanBuilderV2 Add a step that uses the execution agent with a tool. Arguments: tool - The tool to use. task - The task to perform. inputs - The inputs to the task. If any of these values are instances of StepOutput or Input, the corresponding values will be substituted in when the plan is run. output_schema - The schema of the output. step_name - Optional name for the step. If not provided, will be auto-generated. add_step​ def add_step(step: StepV2) -> PlanBuilderV2 Add a pre-built step to the plan. This can be used to add custom steps into the plan. add_steps​ def add_steps(plan: PlanV2 | Iterable[StepV2]) -> PlanBuilderV2 Add steps to the plan. Step can be provided as a sequence or as a plan. If provided as a plan, we will also take plan inputs from the plan, provided there are no duplicates (if there are duplicates, a PlanBuilderError will be raised). final_output​ def final_output(output_schema: type[BaseModel] | None = None, summarize: bool = False) -> PlanBuilderV2 Set the final output of the plan. Arguments: output_schema - The schema for the final output. If provided, an LLM will be used to coerce the output to this schema. summarize - Whether to summarize the final output. If True, a summary of the final output will be provided along with the value. build​ def build() -> PlanV2 Return the plan, ready to run.PlanBuilderError ObjectsPlanBuilderV2 Objects",
      "timestamp": "2025-08-24 06:49:06"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/browser",
      "title": "Open Source - Browser Use | Portia AI Docs",
      "content": "Open Source - Browser Use | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: browser_tool Tool description: General purpose browser tool. Can be used to navigate to a URL and complete tasks. Should only be used if the task requires a browser and you are sure of the URL. This tool handles a full end to end task. It is capable of doing multiple things across different URLs within the same root domain as part of the end to end task. As a result, do not call this tool more than once back to back unless it is for different root domains - just call it once with the combined task and the URL set to the root domain. Usage notes: Also see the BrowserToolForUrl tool, which you can initialise with a URL to run your browser tasks from. Args schema: { \"description\": \"Input schema for the BrowserTool.\\n\\nThis schema defines the expected input parameters for the BrowserTool class.\\n\\nAttributes:\\n url (str): The URL that the browser tool should navigate to.\\n This is a required field specifying the target webpage.\\n task (str): The task description that should be performed by the browser tool.\\n This is a required field that specifies what actions should be taken\\n on the provided URL.\\n task_data (list[Any] | str | None): Task data that should be used to complete the task.\\n Can be a string, a list of strings, or a list of objects that will be converted to\\n strings. Important: This should include all relevant data in their entirety,\\n from the first to the last character (i.e. NOT a summary).\", \"properties\": { \"url\": { \"description\": \"The URL to navigate to.\", \"title\": \"Url\", \"type\": \"string\" }, \"task\": { \"description\": \"The task to be completed by the Browser tool.\", \"title\": \"Task\", \"type\": \"string\" }, \"task_data\": { \"anyOf\": [ { \"items\": {}, \"type\": \"array\" }, { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Task data that should be used to complete the task. Can be a string, a list of strings, or a list of objects that will be converted to strings. Important: This should include all relevant data in their entirety, from the first to the last character (i.e. NOT a summary).\", \"title\": \"Task Data\" } }, \"required\": [ \"url\", \"task\" ], \"title\": \"BrowserToolSchema\", \"type\": \"object\"} Output schema: ('str', \"The Browser tool's response to the user query.\")UsageTool details",
      "timestamp": "2025-08-24 06:49:09"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/version",
      "title": "portia.version | Portia AI Docs",
      "content": "portia.version | Portia AI Docs Skip to main contentOn this pageVersion utilities for Portia SDK. get_version​ def get_version() -> str Get the current version of the Portia SDK. This function works both when the package is installed as a dependency and when run directly from source. When run from source, it attempts to read the version from pyproject.toml. Returns: str - The current version of the Portia SDK",
      "timestamp": "2025-08-24 06:49:12"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/plan_run",
      "title": "portia.plan_run | Portia AI Docs",
      "content": "portia.plan_run | Portia AI Docs Skip to main contentOn this pagePlan runs are executing instances of a Plan. A plan run encapsulates all execution state, serving as the definitive record of its progress. As the run runs, its PlanRunState, current_step_index, and outputs evolve to reflect the current execution state. The run also retains an ExecutionContext, which provides valuable insights for debugging and analytics, capturing contextual information relevant to the run's execution. Key Components​ RunState: Tracks the current status of the run (e.g., NOT_STARTED, IN_PROGRESS). current_step_index: Represents the step within the plan currently being executed. outputs: Stores the intermediate and final results of the PlanRun. ExecutionContext: Provides contextual metadata useful for logging and performance analysis. PlanRunState Objects​ class PlanRunState(PortiaEnum) The current state of the Plan Run. Attributes: NOT_STARTED - The run has not been started yet. IN_PROGRESS - The run is currently in progress. NEED_CLARIFICATION - The run requires further clarification before proceeding. READY_TO_RESUME - The run is ready to resume after clarifications have been resolved. COMPLETE - The run has been successfully completed. FAILED - The run has encountered an error and failed. PlanRunOutputs Objects​ class PlanRunOutputs(BaseModel) Outputs of a Plan Run including clarifications. Attributes: clarifications ClarificationListType - Clarifications raised by this plan run. step_outputs dict[str, Output] - A dictionary containing outputs of individual steps. Outputs are indexed by the value given by the step.output field of the plan. final_output Output | None - The final consolidated output of the PlanRun if available. PlanRun Objects​ class PlanRun(BaseModel) A plan run represents a running instance of a Plan. Attributes: id PlanRunUUID - A unique ID for this plan_run. plan_id PlanUUID - The ID of the Plan this run uses. current_step_index int - The current step that is being executed. state PlanRunState - The current state of the PlanRun. outputs PlanRunOutputs - Outputs of the PlanRun including clarifications. plan_run_inputs dict[str, LocalDataValue] - Dict mapping plan input names to their values. get_outstanding_clarifications​ def get_outstanding_clarifications() -> ClarificationListType Return all outstanding clarifications. Returns: ClarificationListType - A list of outstanding clarifications that have not been resolved. get_clarifications_for_step​ def get_clarifications_for_step( step: int | None = None) -> ClarificationListType Return clarifications for the given step. Arguments: step int | None - the step to get clarifications for. Defaults to current step. Returns: ClarificationListType - A list of clarifications for the given step. get_clarification_for_step​ def get_clarification_for_step( category: ClarificationCategory, step: int | None = None) -> Clarification | None Return a clarification of the given category for the given step if it exists. Arguments: step int | None - the step to get a clarification for. Defaults to current step. category ClarificationCategory | None - the category of the clarification to get. get_potential_step_inputs​ def get_potential_step_inputs() -> dict[str, Output] Return a dictionary of potential step inputs for future steps. __str__​ def __str__() -> str Return the string representation of the PlanRun. Returns: str - A string representation containing key run attributes. ReadOnlyPlanRun Objects​ class ReadOnlyPlanRun(PlanRun) A read-only copy of a Plan Run passed to agents for reference. This class provides a non-modifiable view of a plan run instance, ensuring that agents can access run details without altering them. from_plan_run​ @classmethoddef from_plan_run(cls, plan_run: PlanRun) -> ReadOnlyPlanRun Create a read-only plan run from a normal PlanRun. Arguments: plan_run PlanRun - The original run instance to create a read-only copy from. Returns: ReadOnlyPlanRun - A new read-only instance of the provided PlanRun. Key ComponentsPlanRunState ObjectsPlanRunOutputs ObjectsPlanRun ObjectsReadOnlyPlanRun Objects",
      "timestamp": "2025-08-24 06:49:15"
    },
    {
      "url": "https://docs.portialabs.ai/inputs-outputs",
      "title": "Inputs and Outputs | Portia AI Docs",
      "content": "Inputs and Outputs | Portia AI Docs Skip to main contentOn this page Inputs and outputs are the core of any agentic workflow, and Portia provides a flexible way to define and use them. Inputs are managed via the plan input interface, while structured outputs are managed via the plan structured output interface in conjunction with Pydantic BaseModels. Plan Inputs​ So far the starting point for all plan runs is a user query for a specific set of inputs e.g. \"get the weather in Beirut\". This is in contrast to a generalised query e.g. \"get the weather for a given city\" where the city is provided dynamically per plan run. The PlanInput abstraction allows you to use a generalised query or plan \"template\" where the input differs with every plan run. In the planning stage, you would define the list of plan inputs, providing a name and optional description for each, and pass those along with a generalised query as arguments to the portia.plan method. The planning agent is capable of generating a plan with \"placeholders\" for each plan input. To run that generalised plan, Portia then expects you to provide specific values for the inputs at each run. For example, consider a simple agent that tells you the weather in a particular city, with the city provided as a plan input. To set this up, we define the plan input for the planner as follows: from portia import Portiaportia = Portia()# Specify the inputs you will use in the planplan_input = {\"name\":\"$city\", \"description\": \"The city to get the temperature for\"}plan = portia.plan(\"Get the temperature for the provided city\", plan_inputs=[plan_input]) This will create a single step plan that uses the weather tool with $city as an input to that tool. Then, when running the plan, we pass in a value for the input. In this case, we select \"London\". This value will then be used for the $city input in the plan and we will find the temperature in London. # Specify the values for those inputs when you run the planplan_run_inputs = {\"name\": \"$city\", \"value\": \"London\"}plan_run = portia.run(\"Get the temperature for the provided city\", plan_run_inputs=[plan_run_inputs]) Plan Structured Outputs​ For some plans you might want to have a structured output at the end of a plan, for this we allow the ability to attach a structured output schema to the plan that the summarizer agent will attempt to coerce the results to. This is optional and is based on Pydantic BaseModels ↗. To use, attach to the Plan object, and any Plan Runs that are created from this will attempt to use structured output for the final result, this can pull information from any point of the plan steps and is not just the final step. To attach a schema, you can do it through the PlanBuilder or the Plan interfaces, as below. plan_structured_output.pyfrom portia.plan import PlanBuilderfrom pydantic import BaseModelfrom dotenv import load_dotenvfrom portia import ( Portia, default_config, example_tool_registry,)load_dotenv()portia = Portia(tools=example_tool_registry)# Final output schema type to coerce toclass FinalPlanOutput(BaseModel): result: float # result here is an integer output from calculator tool, but will be converted # to a float via structured output you can also add other fields here, and they will be # included in the output, as per any other Pydantic BaseModel# Example via plan builder, attach to the plan at top levelplan = PlanBuilder( \"Add 1 + 1\", structured_output_schema=FinalPlanOutput).step( \"Add 1 + 1\", tool_id='calculator_tool').build()# Example via plan interfaceplan2 = portia.plan(\"Add 1 + 1\", structured_output_schema=FinalPlanOutput) Run the plan as normal and the final output will be an instance of the attached schema. It will be coerced to the type of the BaseModel provided and follows all the same rules as a pydantic model, including validation and description for fields. LLM Tool Outputs​ The LLMTool allows structured outputs to be returned from a tool call, and these will be coerced to the type of the BaseModel provided. This follows all the same rules as a pydantic model, including validation and description for fields in the same way as the plan structured output above, but only for an LLM tool call within the plan. llm_tool_output.pyfrom portia import Portia, config, PlanBuilderfrom portia.open_source_tools.llm_tool import LLMToolfrom portia.open_source_tools.weather import WeatherToolimport dotenvfrom pydantic import BaseModel, Field# basicsdotenv.load_dotenv(override=True)config = config.Config.from_default()# structured output schemaclass WeatherOutput(BaseModel): temperature: float description: str = Field(description=\"A description of the weather\")structured_llm_tool = LLMTool(structured_output_schema=WeatherOutput) # structured output schema attachedtools = [structured_llm_tool, WeatherTool()] # structured_llm_tool has a structured output schema attachedportia = Portia(config, tools=tools) # register the tools with the portia instance, including the structured_llm_toolplan = PlanBuilder( \"get the weather in london and summarize the weather\").step( \"get the weather in london\", tool_id=weather_tool.id).step( \"summarize the weather\", tool_id=structured_llm_tool.id).build() Browser Tool Outputs​ The BrowserTool allows structured outputs to be returned from a browser tool call, and these will be coerced to the type of the basemodel provided and follows all the same rules as a pydantic model, including validation and description for fields in the same way as the plan structured output above, but only for a browser tool call within the plan. browser_tool_output.pyfrom portia import Portia, config, PlanBuilderfrom portia.open_source_tools.browser_tool import BrowserToolimport dotenvfrom pydantic import BaseModel, Field# basicsdotenv.load_dotenv(override=True)config = config.Config.from_default()class Recipes(BaseModel): recipe_names: list[str] = Field(description=\"List of recipe names found on the page\")browsertool = BrowserTool(structured_output_schema=Recipes) # structured output schema attachedtools = [browsertool]portia = Portia(config, tools=tools)plan = PlanBuilder( \"Get the top recipes from bbcgoodfood\").step( \"get all the names of recipes on the frontpage of bbcgoodfood.com\", tool_id=browsertool.id).build()Plan InputsPlan Structured OutputsLLM Tool OutputsBrowser Tool Outputs",
      "timestamp": "2025-08-24 06:49:18"
    },
    {
      "url": "https://docs.portialabs.ai/generate-and-run-plans",
      "title": "Generate and run plans | Portia AI Docs",
      "content": "Generate and run plans | Portia AI Docs Skip to main content📄️ Generate a planLearn how to create structured, multi-agent plans using your LLM of choice and familiarise yourself with the structure of plans created using Portia.📄️ Build a plan manuallyPlanBuilderV2 is currently in Alpha so please expect changes in this area and we'd love your feedback on our Discord channel (↗)!📄️ Run a planLearn how to run a plan run from an existing plan or end-to-end.📄️ Plan run states on Portia cloudUse our Run service to save and retrieve serialised plan run states on our cloud.📄️ Inputs and OutputsInputs and outputs are the core of any agentic workflow, and Portia provides a flexible way to define and use them. Inputs are managed via the plan input interface, while structured outputs are managed via the plan structured output interface in conjunction with Pydantic BaseModels.",
      "timestamp": "2025-08-24 06:49:21"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/builder/step_v2",
      "title": "portia.builder.step_v2 | Portia AI Docs",
      "content": "portia.builder.step_v2 | Portia AI Docs Skip to main contentOn this pageInterface for steps that are run as part of a PlanV2. StepV2 Objects​ class StepV2(BaseModel, ABC) Interface for steps that are run as part of a plan. run​ @abstractmethodasync def run(run_data: RunContext) -> Any Execute the step. to_legacy_step​ @abstractmethoddef to_legacy_step(plan: PlanV2) -> Step Convert this step to a Step from plan.py. A Step is the legacy representation of a step in the plan, and is still used in the Portia backend. If this step doesn't need to be represented in the plan sent to the Portia backend, return None. LLMStep Objects​ class LLMStep(StepV2) A step that runs a given task through an LLM (without any tools). __str__​ def __str__() -> str Return a description of this step for logging purposes. run​ @override@traceable(name=\"LLM Step - Run\")async def run(run_data: RunContext) -> str | BaseModel Run the LLM query. to_legacy_step​ @overridedef to_legacy_step(plan: PlanV2) -> Step Convert this LLMStep to a Step. InvokeToolStep Objects​ class InvokeToolStep(StepV2) A step that calls a tool with the given args (no LLM involved, just a direct tool call). __str__​ def __str__() -> str Return a description of this step for logging purposes. run​ @override@traceable(name=\"Invoke Tool Step - Run\")async def run(run_data: RunContext) -> Any Run the tool. to_legacy_step​ @overridedef to_legacy_step(plan: PlanV2) -> Step Convert this InvokeToolStep to a legacy Step. FunctionStep Objects​ class FunctionStep(StepV2) Calls a function with the given args (no LLM involved, just a direct function call). __str__​ def __str__() -> str Return a description of this step for logging purposes. run​ @override@traceable(name=\"Function Step - Run\")async def run(run_data: RunContext) -> Any Run the function. to_legacy_step​ @overridedef to_legacy_step(plan: PlanV2) -> Step Convert this FunctionStep to a legacy Step. tool_id_is_local_function​ @classmethoddef tool_id_is_local_function(cls, tool_id: str) -> bool Check if the tool id is a local function. SingleToolAgentStep Objects​ class SingleToolAgentStep(StepV2) A step where an LLM agent uses a single tool (calling it only once) to complete a task. __str__​ def __str__() -> str Return a description of this step for logging purposes. run​ @override@traceable(name=\"Single Tool Agent Step - Run\")async def run(run_data: RunContext) -> None Run the agent step. to_legacy_step​ @overridedef to_legacy_step(plan: PlanV2) -> Step Convert this SingleToolAgentStep to a Step. ConditionalStep Objects​ class ConditionalStep(StepV2) A step that represents a conditional clause in a conditional block. I.E. if, else-if, else, end-if clauses. validate_conditional_block​ @field_validator(\"conditional_block\", mode=\"after\")@classmethoddef validate_conditional_block(cls, v: ConditionalBlock | None) -> ConditionalBlock Validate the conditional block. block​ @propertydef block() -> ConditionalBlock Get the conditional block for this step. __str__​ def __str__() -> str Return a description of this step for logging purposes. run​ @override@traceable(name=\"Conditional Step - Run\")async def run(run_data: RunContext) -> Any Run the conditional step. to_legacy_step​ @overridedef to_legacy_step(plan: PlanV2) -> Step Convert this ConditionalStep to a PlanStep.StepV2 ObjectsLLMStep ObjectsInvokeToolStep ObjectsFunctionStep ObjectsSingleToolAgentStep ObjectsConditionalStep Objects",
      "timestamp": "2025-08-24 06:49:24"
    },
    {
      "url": "https://docs.portialabs.ai/handle-auth-clarifications",
      "title": "Handle auth and clarifications | Portia AI Docs",
      "content": "Handle auth and clarifications | Portia AI Docs Skip to main content📄️ Understand clarificationsDefine clarifications to bring structured input into a plan run.📄️ Run Portia tools with authenticationUse clarifications to leverage Portia tools' native authentication support.",
      "timestamp": "2025-08-24 06:49:27"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/count-ticket-comments",
      "title": "Zendesk - Tickets: Count Comments | Portia AI Docs",
      "content": "Zendesk - Tickets: Count Comments | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:tickets:count_comments Tool description: Returns an approximate count of the comments added to the ticket. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Args schema: { \"description\": \"Input schema for ZendeskCountTicketCommentsTool.\", \"properties\": { \"ticket_id\": { \"description\": \"The ID of the ticket\", \"title\": \"Ticket Id\", \"type\": \"integer\" } }, \"required\": [ \"ticket_id\" ], \"title\": \"ZendeskCountTicketCommentsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API containing the approximate count of comments on a Zendesk ticket.')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:49:30"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/utils/step_summarizer",
      "title": "portia.execution_agents.utils.step_summarizer | Portia AI Docs",
      "content": "portia.execution_agents.utils.step_summarizer | Portia AI Docs Skip to main contentOn this pageStepSummarizer implementation. The StepSummarizer can be used by agents to summarize the output of a given tool. SummarizerOutputModel Objects​ class SummarizerOutputModel(BaseModel) Protocol for the summarizer output model. StepSummarizer Objects​ class StepSummarizer() Class to summarize the output of a tool using llm. This is used only on the tool output message. Attributes: summarizer_prompt ChatPromptTemplate - The prompt template used to generate the summary. model GenerativeModel - The language model used for summarization. summary_max_length int - The maximum length of the summary. step Step - The step that produced the output. __init__​ def __init__(config: Config, model: GenerativeModel, tool: Tool, step: Step, summary_max_length: int = 500) -> None Initialize the model. Arguments: config Config - The configuration for the run. model GenerativeModel - The language model used for summarization. tool Tool - The tool used for summarization. step Step - The step that produced the output. summary_max_length int - The maximum length of the summary. Default is 500 characters. invoke​ def invoke(state: MessagesState) -> dict[str, Any] Invoke the model with the given message state. This method processes the last message in the state, checks if it's a tool message with an output, and if so, generates a summary of the tool's output. The summary is then added to the artifact of the last message. Arguments: state MessagesState - The current state of the messages, which includes the output. Returns: dict[str, Any]: A dict containing the updated message state, including the summary. Raises: Exception - If an error occurs during the invocation of the summarizer model. ainvoke​ async def ainvoke(state: MessagesState) -> dict[str, Any] Async implementation of invoke. This method processes the last message in the state, checks if it's a tool message with an output, and if so, generates a summary of the tool's output. The summary is then added to the artifact of the last message. Arguments: state MessagesState - The current state of the messages, which includes the output. Returns: dict[str, Any]: A dict containing the updated message state, including the summary. Raises: Exception - If an error occurs during the invocation of the summarizer model. SummarizerOutputModel ObjectsStepSummarizer Objects",
      "timestamp": "2025-08-24 06:49:33"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/file-writer",
      "title": "Open Source - File Writer | Portia AI Docs",
      "content": "Open Source - File Writer | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: file_writer_tool Tool description: Writes content to a file locally Args schema: { \"description\": \"Schema defining the inputs for the FileWriterTool.\", \"properties\": { \"filename\": { \"description\": \"The location where the file should be saved\", \"title\": \"Filename\", \"type\": \"string\" }, \"content\": { \"description\": \"The content to write to the file\", \"title\": \"Content\", \"type\": \"string\" } }, \"required\": [ \"filename\", \"content\" ], \"title\": \"FileWriterToolSchema\", \"type\": \"object\"} Output schema: ('str', 'A string indicating where the content was written to')UsageTool details",
      "timestamp": "2025-08-24 06:49:36"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/search_tool",
      "title": "portia.open_source_tools.search_tool | Portia AI Docs",
      "content": "portia.open_source_tools.search_tool | Portia AI Docs Skip to main contentOn this pageSimple Search Tool. SearchToolSchema Objects​ class SearchToolSchema(BaseModel) Input for SearchTool. SearchTool Objects​ class SearchTool(Tool[str]) Searches the internet to find answers to the search query provided.. run​ def run(_: ToolRunContext, search_query: str) -> str Run the Search Tool. arun​ async def arun(_: ToolRunContext, search_query: str) -> str Run the Search Tool asynchronously.SearchToolSchema ObjectsSearchTool Objects",
      "timestamp": "2025-08-24 06:49:39"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/llm",
      "title": "Open Source - LLM | Portia AI Docs",
      "content": "Open Source - LLM | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: llm_tool Tool description: Jack of all trades tool to respond to a prompt by relying solely on LLM capabilities. YOU NEVER CALL OTHER TOOLS. You use your native capabilities as an LLM only. This includes using your general knowledge and your in-built reasoning. This tool can be used to summarize the outputs of other tools, make general language model queries or to answer questions. This should be used only as a last resort when no other tool satisfies a step in a task, however if there are no other tools that can be used to complete a step or for steps that don't require a tool call, this SHOULD be used. MAKE SURE the task_data includes ALL INPUT VARIABLES IN THE CONTEXT. DO NOT use this tool if you require input from user. Args schema: { \"description\": \"Input for LLM Tool.\", \"properties\": { \"task\": { \"description\": \"The task to be completed by the LLM tool\", \"title\": \"Task\", \"type\": \"string\" }, \"task_data\": { \"anyOf\": [ { \"items\": {}, \"type\": \"array\" }, { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Task data that should be used to complete the task. Can be a string, a list of strings, or a list of objects that will be converted to strings. Important: This should include all relevant data in their entirety, from the first to the last character (i.e. NOT a summary).\", \"title\": \"Task Data\" } }, \"required\": [ \"task\" ], \"title\": \"LLMToolSchema\", \"type\": \"object\"} Output schema: ('str', \"The LLM's response to the user query.\")UsageTool details",
      "timestamp": "2025-08-24 06:49:42"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-request-comment",
      "title": "Zendesk - Request Comments: Show | Portia AI Docs",
      "content": "Zendesk - Request Comments: Show | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:requests:show_comment Tool description: Retrieves information about a specific comment on a request in Zendesk. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Args schema: { \"description\": \"Input schema for ZendeskShowRequestCommentTool.\", \"properties\": { \"request_id\": { \"description\": \"The ID of the request\", \"title\": \"Request Id\", \"type\": \"integer\" }, \"ticket_comment_id\": { \"description\": \"The ID of the ticket comment\", \"title\": \"Ticket Comment Id\", \"type\": \"integer\" } }, \"required\": [ \"request_id\", \"ticket_comment_id\" ], \"title\": \"ZendeskShowRequestCommentToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:49:45"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-create-event",
      "title": "Google Calendar - Calendar: Create Event | Portia AI Docs",
      "content": "Google Calendar - Calendar: Create Event | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:gcalendar:create_event Tool description: Creates a Google Calendar event. DO NOT call portia:google:gcalendar:check_availability before using this tool, unless the user explicitly asks you to check their availability. Args schema: { \"description\": \"Schema for creating a Google Calendar event.\", \"properties\": { \"event_title\": { \"description\": \"The title of the calendar event\", \"title\": \"Event Title\", \"type\": \"string\" }, \"start_time\": { \"description\": \"The start time of the event in ISO format without timezone, e.g 2024-09-20T20:00:00\", \"format\": \"date-time\", \"title\": \"Start Time\", \"type\": \"string\" }, \"end_time\": { \"description\": \"The end time of the event in ISO format without timezone, e.g 2024-09-20T20:00:00\", \"format\": \"date-time\", \"title\": \"End Time\", \"type\": \"string\" }, \"event_description\": { \"description\": \"The description of the event\", \"title\": \"Event Description\", \"type\": \"string\" }, \"attendees\": { \"description\": \"List of attendees' email addresses\", \"items\": { \"type\": \"string\" }, \"title\": \"Attendees\", \"type\": \"array\" } }, \"required\": [ \"event_title\", \"start_time\", \"end_time\", \"event_description\", \"attendees\" ], \"title\": \"GoogleCalendarCreateEventSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Output of the tool')UsageTool details",
      "timestamp": "2025-08-24 06:49:48"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/introspection_agents/default_introspection_agent",
      "title": "portia.introspection_agents.default_introspection_agent | Portia AI Docs",
      "content": "portia.introspection_agents.default_introspection_agent | Portia AI Docs Skip to main contentOn this pageThe default introspection agent. This agent looks at the state of a plan run between steps and makes decisions about whether execution should continue. DefaultIntrospectionAgent Objects​ class DefaultIntrospectionAgent(BaseIntrospectionAgent) Default Introspection Agent. Implements the BaseIntrospectionAgent interface using an LLM to make decisions about what to do. Attributes: config Config - Configuration settings for the DefaultIntrospectionAgent. __init__​ def __init__(config: Config, agent_memory: AgentMemory) -> None Initialize the DefaultIntrospectionAgent with configuration. Arguments: config Config - The configuration to initialize the DefaultIntrospectionAgent. agent_memory AgentMemory - The agent memory to use pre_step_introspection​ def pre_step_introspection(plan: Plan, plan_run: PlanRun) -> PreStepIntrospection Ask the LLM whether to continue, skip or fail the plan_run. apre_step_introspection​ async def apre_step_introspection(plan: Plan, plan_run: PlanRun) -> PreStepIntrospection pre_step_introspection is introspection run before a plan happens..DefaultIntrospectionAgent Objects",
      "timestamp": "2025-08-24 06:49:51"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/chargebee",
      "title": "Chargebee | Portia AI Docs",
      "content": "Chargebee | Portia AI Docs Skip to main contentOn this page Description​ Integration with Chargebee products and API services to facilitate billing for subscription businesses. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"chargebee\", command=\"npx\", args=[\"-y\", \"@chargebee/mcp@latest\"],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"chargebee\", command=\"npx\", args=[\"-y\", \"@chargebee/mcp@latest\"],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:49:54"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/pdf-reader",
      "title": "Open Source - PDF Reader | Portia AI Docs",
      "content": "Open Source - PDF Reader | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: pdf_reader_tool Tool description: Read a PDF file and extract its text content using Mistral OCR Usage notes: You must have a MistralAI API key set in the environment variable MISTRAL_API_KEY to use this tool. Args schema: { \"description\": \"Input for PDFReaderTool.\", \"properties\": { \"file_path\": { \"description\": \"The path to the PDF file to be read.\", \"title\": \"File Path\", \"type\": \"string\" } }, \"required\": [ \"file_path\" ], \"title\": \"PDFReaderToolSchema\", \"type\": \"object\"} Output schema: ('str', 'The extracted text content from the PDF file.')UsageTool details",
      "timestamp": "2025-08-24 06:49:57"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/planning_agents/context",
      "title": "portia.planning_agents.context | Portia AI Docs",
      "content": "portia.planning_agents.context | Portia AI Docs Skip to main contentOn this pageContext helpers for PlanningAgents. render_prompt_insert_defaults​ def render_prompt_insert_defaults( query: str, tool_list: list[Tool], end_user: EndUser, examples: list[Plan] | None = None, plan_inputs: list[PlanInput] | None = None, previous_errors: list[str] | None = None) -> str Render the prompt for the PlanningAgent with defaults inserted if not provided. default_query_system_context​ def default_query_system_context() -> list[str] Return the default system context. get_tool_descriptions_for_tools​ def get_tool_descriptions_for_tools( tool_list: list[Tool]) -> list[dict[str, str]] Given a list of tool names, return the descriptions of the tools.",
      "timestamp": "2025-08-24 06:50:00"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/",
      "title": "Google Calendar Tools | Portia AI Docs",
      "content": "Google Calendar Tools | Portia AI Docs Skip to main content Calendar: Check AvailabilityChecks the availability of this authenticated user for a given time range. DO NOT use this to validate availability of people the user wants to meet with. DO NOT use this unless the user specifically asks for availability checking, e.g by saying 'find when I am free', or 'check my availability'. Either the day, end_time, or start_time must be provided. Pay close attention to the task if it says 'before' or 'after'. Calendar: Create EventCreates a Google Calendar event. DO NOT call portia:google:gcalendar:check_availability before using this tool, unless the user explicitly asks you to check their availability. Calendar: Delete EventDeletes the Google Calendar event associated with the ID. Calendar: Get EventGets Google Calendar event using an event ID. Calendar: Get Events By PropertiesGets Google Calendar events by properties, returning the matching event details. You do not need to provide all the properties, only the ones you have provided with. Calendar: Modify EventModifies an existing Google Calendar event. You must provide the event ID to modify, and can optionally provide new values if desired for the title, start time, end time, description, and attendees.",
      "timestamp": "2025-08-24 06:50:03"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/deepwiki",
      "title": "DeepWiki | Portia AI Docs",
      "content": "DeepWiki | Portia AI Docs Skip to main contentOn this page Description​ Provides AI assistants with access to GitHub repository documentation and search capabilities for code understanding, architecture exploration, and technical question answering. Authorisation​ To use this MCP server, you need API credentials in your environment. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to provide your API key when you enable the server. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:50:06"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/monday.com",
      "title": "Monday.com | Portia AI Docs",
      "content": "Monday.com | Portia AI Docs Skip to main contentOn this page Description​ Integrates with monday.com API to enable direct access to boards, workflows, and data for automating tasks and managing resources without context switching. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"monday.com\", command=\"npx\", args=[ \"@mondaydotcomorg/monday-api-mcp\", \"-t\", \"<api_key>\", ],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"monday.com\", command=\"npx\", args=[ \"@mondaydotcomorg/monday-api-mcp\", \"-t\", \"<api_key>\", ],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:50:09"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-check-availability",
      "title": "Google Calendar - Calendar: Check Availability | Portia AI Docs",
      "content": "Google Calendar - Calendar: Check Availability | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:gcalendar:check_availability Tool description: Checks the availability of this authenticated user for a given time range. DO NOT use this to validate availability of people the user wants to meet with. DO NOT use this unless the user specifically asks for availability checking, e.g by saying 'find when I am free', or 'check my availability'. Either the day, end_time, or start_time must be provided. Pay close attention to the task if it says 'before' or 'after'. Args schema: { \"description\": \"Schema for checking Google Calendar availability.\", \"properties\": { \"start_time\": { \"anyOf\": [ { \"format\": \"date-time\", \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Start time to check availability in ISO format, e.g 2024-09-20T20:00:00. Do not include the timezone in this field.\", \"title\": \"Start Time\" }, \"end_time\": { \"anyOf\": [ { \"format\": \"date-time\", \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"End time to check availability in ISO format, can be omitted e.g 2024-09-20T20:00:00. Do not include the timezone in this field.\", \"title\": \"End Time\" }, \"day\": { \"anyOf\": [ { \"format\": \"date-time\", \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The day to check availability for in ISO format, e.g 2024-09-20.\", \"title\": \"Day\" } }, \"title\": \"GoogleCalendarCheckAvailabilitySchema\", \"type\": \"object\"} Output schema: ('list[dict[str, str]]', 'Returns a list of times when the user is available. An empty list means the user is unavailable.')UsageTool details",
      "timestamp": "2025-08-24 06:50:12"
    },
    {
      "url": "https://docs.portialabs.ai/extend-run-tools",
      "title": "Extend and run tools | Portia AI Docs",
      "content": "Extend and run tools | Portia AI Docs Skip to main content📄️ Introduction to toolsUnderstand tools at Portia and add your own.📄️ Integrating toolsLearn how to integrate tools that your agent can use to answer a user query.📄️ Remote MCP and cloud toolsWhen your agents are connected to Portia Cloud, they gain access to an extensive tool registry with powerful integrations. The registry includes by default popular services like Gmail, Google Calendar, Slack, GitHub, Zendesk, and is extensible to many more by integrating remote MCP servers. You can check out and configure the integrations you want access to in the dashboard (↗). This will update update the tools available to your DefaultToolRegistry (see here if you need a recap on how tool registries work).📄️ Integrating an MCP server with the SDKThe Model Context Protocol (MCP) makes it very easy to integrate third-party tools into your Portia AI project.📄️ Add custom toolsLet's build two custom tools that allow an LLM to write / read content to / from a local file. We'll start building the tool using the @tool decorator, which provides a simple and straightforward way to create custom tools from Python functions.📄️ Use clarifications in custom toolsYou can raise a Clarification in any custom tool definition to prompt a plan run to interrupt itself and solicit input (SDK reference ↗).📄️ Using browser toolsBrowser tools (SDK ↗) can deploy an agent to browse the internet and retrieve data or enact actions on your behalf. Portia will use Browser tools when it recognises there is a web-based task to be performed. We use the Browser Use (↗) library to offer a multi-modal web agent that will visually and textually analyse a website in order to navigate it and carry out a task.",
      "timestamp": "2025-08-24 06:50:15"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools",
      "title": "Portia Tool Catalogue | Portia AI Docs",
      "content": "Portia Tool Catalogue | Portia AI Docs Skip to main content Portia offer both open source and cloud base tools. See the tools docs ↗ to get started using tools. Open Source Browser UseGeneral purpose browser tool. Can be used to navigate to a URL and complete tasks. Should only be used if the task requires a browser and you are sure of the URL. This tool handles a full end to end task. It is capable of doing multiple things across different URLs within the same root domain as part of the end to end task. As a result, do not call this tool more than once back to back unless it is for different root domains - just call it once with the combined task and the URL set to the root domain. CrawlCrawls websites using graph-based website traversal tool that can explore hundreds of paths in parallel with built-in extraction and intelligent discovery. Provide a starting URL and optional instructions for what to find, and the tool will navigate and extract relevant content from multiple pages. Supports depth control, domain filtering, and path selection for comprehensive site exploration. ExtractExtracts web page content from one or more specified URLs using Tavily Extract and returns the raw content, images, and metadata from those pages. The extract tool can access publicly available web pages but cannot extract content from pages that block automated access File ReaderFinds and reads content from a local file on Disk File WriterWrites content to a file locally Image UnderstandingTool for understanding images from a URL. Capable of tasks like object detection, OCR, scene recognition, and image-based Q&A. This tool uses its native capabilities to analyze images and provide insights. LLMJack of all trades tool to respond to a prompt by relying solely on LLM capabilities. YOU NEVER CALL OTHER TOOLS. You use your native capabilities as an LLM only. This includes using your general knowledge and your in-built reasoning. This tool can be used to summarize the outputs of other tools, make general language model queries or to answer questions. This should be used only as a last resort when no other tool satisfies a step in a task, however if there are no other tools that can be used to complete a step or for steps that don't require a tool call, this SHOULD be used. MAKE SURE the task_data includes ALL INPUT VARIABLES IN THE CONTEXT. DO NOT use this tool if you require input from user. Map WebsiteMaps websites using graph-based traversal that can explore hundreds of paths in parallel with intelligent discovery to generate comprehensive site maps. Provide a URL and the tool will discover and return all accessible pages on that website. Supports depth control, domain filtering, path selection, and various mapping options for comprehensive site reconnaissance and URL discovery. PDF ReaderRead a PDF file and extract its text content using Mistral OCR SearchSearches the internet (using Tavily) to find answers to the search query provided and returns those answers, including images, links and a natural language answer. The search tool has access to general information but can not return specific information on users or information not available on the internet WeatherGet the weather for a given cityPortia Cloud GitHubFind and interact with GitHub repositories. Google CalendarCreate and modify events in Google Calendar. Google DocsFetch documents from Google Docs. Google DriveSearch for files in Google Drive. Google GmailSend and find emails via Google Gmail. Google SheetsFetch spreadsheets from Google Sheets. Microsoft OutlookSend and find emails via Microsoft Outlook. SlackSend messages and search channels and chats in a Slack workspace. ZendeskInteract with Zendesk support tickets, articles, and more.Remote MCP Apify ActorsUse 4,000+ pre-built cloud tools, known as Actors, to extract data from websites, e-commerce, social media, search engines, maps, and more. AsanaOpens the Asana Work Graph to AI assistants, enabling task and project operations through an authenticated MCP interface.. CloudflareManage your Cloudflare DNS records, Cloudflare Workers, audit logs, and more. DeepWikiProvides AI assistants with access to GitHub repository documentation and search capabilities for code understanding, architecture exploration, and technical question answering. FirecrawlIntegration with FireCrawl to provide advanced web scraping capabilities for extracting structured data from complex websites. Hugging FaceIntegrates with Hugging Face's ecosystem to search models, datasets, and papers while dynamically connecting to Gradio-based tools hosted on Spaces for extended ML capabilities. IntercomEnables AI systems to securely access Intercom's customer conversation data, user profiles, and tickets in real-time for identifying patterns, troubleshooting issues, and driving business decisions. InvideoLets agents script end-to-end video creation: writing scripts, fetching stock media, generating clips and subtitling. LinearAccess your Linear data to manage your projects and issues in a simple and secure way. MakeConnects AI systems to Make automation workflows, enabling assistants to trigger scenarios with parameters and receive structured JSON output from your existing Make account. PosthogIntegrates with PostHog to enable querying analytics, errors, running SQL insights, and managing feature flags through natural language interactions. SemgrepIntegrates with Semgrep's static analysis engine to scan code for security vulnerabilities and coding issues, enabling developers to identify and fix potential problems directly within their coding workflow. SentryExposes 16+ tools to query issues, search errors and even invoke Seer for automated fixes. ShopifyIntegrates with individual Shopify stores to enable product catalog search, cart management, and policy inquiries for complete shopping experiences from discovery to checkout. SquareProvides a bridge between Square's complete API ecosystem and conversational interfaces, enabling comprehensive e-commerce and payment processing capabilities including payments, orders, inventory, and customer management. StripeIntegrates with Stripe's API to enable payment processing, customer management, and financial operations for e-commerce and billing workflows. SupermemoryPersonal knowledge platform that helps collect, organize, and recall information from various sources with end-to-end encryption and optional self-hosting. WebflowIntegration with the Webflow Data API. WixEnables website creation and management with Wix business solutions including eCommerce, booking systems, payment processing, and CRM functionality through natural language commands. YepCodeEnables secure execution of LLM-generated scripts and processes in isolated environments with environment variable management for teams needing to run code directly from AI assistants.Local MCP AWS Cost AnalysisAnalyze AWS service costs and generate cost reports. AWS DocumentationProvides tools to access AWS documentation, search for content, and get recommendations. Basic MemoryKnowledge management system that builds a persistent semantic graph in markdown, locally. BioMCPIntegrates with biomedical databases including ClinicalTrials.gov, PubMed, and MyVariant.info to provide structured access to clinical trials, research articles, and genetic variants with intelligent data rendering and source attribution. Bright DataIntegrates with Bright Data's web scraping infrastructure to provide real-time access to public web data through specialized tools for search engine scraping, webpage extraction, and structured data retrieval from popular websites. BrowserbaseAutomate web browsers remotely on a cloud environment. ChargebeeIntegration with Chargebee products and API services to facilitate billing for subscription businesses. ChromaIntegrates with Chroma vector database to enable collection management, document operations, and vector search capabilities for knowledge bases and context-aware conversations. DBHubProvides a universal database gateway for connecting to PostgreSQL, MySQL, SQLite, and DuckDB, enabling table browsing, schema inspection, and read-only SQL queries with built-in safety checks ElevenLabsIntegrates with ElevenLabs to provide high-quality text-to-speech, voice cloning, and conversational capabilities with customizable voice profiles and audio processing features. GCP Cloud RunDeploys applications to Google Cloud Run through automated containerization, project setup, and service management with support for both local files and provided content. GitHubIntegration with GitHub Issues, Pull Requests, and more. GrafanaIntegrates with Grafana to enable searching dashboards, fetching datasource information, querying Prometheus metrics, and managing incidents through both stdio and SSE transport modes. HubSpotIntegrates with HubSpot CRM to enable secure access to contact information, company records, deal data, and task management with customizable data access through Private App scopes. HyperbrowserEnables web browsing capabilities through tools for content extraction, link following, and browser automation with customizable parameters for scraping, data collection, and web crawling tasks. JetBrains IDEInteract with JetBrains IDEs for code analysis and development tasks. MiniMaxEnables high-quality text-to-speech, voice cloning, and video generation capabilities through MiniMax's API with robust error handling and file management features. Monday.comIntegrates with monday.com API to enable direct access to boards, workflows, and data for automating tasks and managing resources without context switching. MongoDBProvides a bridge between MongoDB databases and conversational interfaces, enabling comprehensive database operations, collection management, schema inspection, and Atlas cloud service interactions with authentication and telemetry support. NetlifyIntegrates with Netlify's platform for complete site management including project operations, deployments with zip uploads, team administration, extension configuration, and documentation access across hosting, build, and collaboration workflows. NotionBridges to the Notion API for searching content, querying databases, and managing pages and comments without requiring complex API interaction code PerplexityConnector for the Perplexity API, to enable web search without leaving the MCP ecosystem. PlaywrightEnables web browser control for navigating websites, capturing page snapshots, interacting with elements, and taking screenshots through Playwright's automation capabilities. QdrantStore and retrieve vector-based memories for AI systems. Shopify DevIntegrates with Shopify Dev. Supports various tools to interact with different Shopify APIs. SupabaseConnects directly to Supabase projects for managing databases, executing SQL queries, applying migrations, and handling configurations through natural language commands. TwilioIntegrates with Twilio's API ecosystem to enable messaging, voice, conversations, and serverless functions through authenticated access with automatic AccountSid population and context filtering capabilities. XeroProvides a bridge to the Xero accounting API, enabling financial data interactions and accounting operations through OAuth2 custom connections for automated workflow management.",
      "timestamp": "2025-08-24 06:50:18"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-group",
      "title": "Zendesk - Groups: Show | Portia AI Docs",
      "content": "Zendesk - Groups: Show | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:groups:show Tool description: Returns a group. Args schema: { \"description\": \"Input schema for ZendeskShowGroupTool.\", \"properties\": { \"group_id\": { \"description\": \"The id of the group\", \"title\": \"Group Id\", \"type\": \"integer\" } }, \"required\": [ \"group_id\" ], \"title\": \"ZendeskShowGroupToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:50:21"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-users",
      "title": "Zendesk - Users: Search | Portia AI Docs",
      "content": "Zendesk - Users: Search | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:users:search Tool description: Returns an array of users who meet the search criteria. Returns a maximum of 100 users. This may include (but is not limited to) the user's name, contact information, role, permissions, locale, organization, and other information. Args schema: { \"description\": \"Input schema for ZendeskSearchUsersTool.\", \"properties\": { \"query\": { \"description\": \"The Zendesk domain syntax language for searching users. Supported property key words are name, email, role, organization, and phone. Multiple properties can be used in the same query. Any search terms containing spaces must be enclosed in double quotes. Examples: - name:\\\"John Smith\\\"\\n-email:john.smith@thecompany.com\\n-role:admin organization:The Company\", \"title\": \"Query\", \"type\": \"string\" } }, \"required\": [ \"query\" ], \"title\": \"ZendeskSearchUsersToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API containing a list of users in Zendesk matching the provided query.')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:50:24"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/planning_agents/base_planning_agent",
      "title": "portia.planning_agents.base_planning_agent | Portia AI Docs",
      "content": "portia.planning_agents.base_planning_agent | Portia AI Docs Skip to main contentOn this pagePlanningAgents module creates plans from queries. This module contains the PlanningAgent interfaces and implementations used for generating plans based on user queries. It supports the creation of plans using tools and example plans, and leverages LLMs to generate detailed step-by-step plans. It also handles errors gracefully and provides feedback in the form of error messages when the plan cannot be created. BasePlanningAgent Objects​ class BasePlanningAgent(ABC) Interface for planning. This class defines the interface for PlanningAgents that generate plans based on queries. A PlanningAgent will implement the logic to generate a plan or an error given a query, a list of tools, and optionally, some example plans. Attributes: config Config - Configuration settings for the PlanningAgent. __init__​ def __init__(config: Config) -> None Initialize the PlanningAgent with configuration. Arguments: config Config - The configuration to initialize the PlanningAgent. generate_steps_or_error​ @abstractmethoddef generate_steps_or_error( query: str, tool_list: list[Tool], end_user: EndUser, examples: list[Plan] | None = None, plan_inputs: list[PlanInput] | None = None) -> StepsOrError Generate a list of steps for the given query. This method should be implemented to generate a list of steps to accomplish the query based on the provided query and tools. Arguments: query str - The user query to generate a list of steps for. tool_list list[Tool] - A list of tools available for the plan. end_user EndUser - The end user for this plan examples list[Plan] | None - Optional list of example plans to guide the PlanningAgent. plan_inputs list[PlanInput] | None - Optional list of PlanInput objects defining the inputs required for the plan. Returns: StepsOrError - A StepsOrError instance containing either the generated steps or an error. agenerate_steps_or_error​ async def agenerate_steps_or_error( query: str, tool_list: list[Tool], end_user: EndUser, examples: list[Plan] | None = None, plan_inputs: list[PlanInput] | None = None) -> StepsOrError Generate a list of steps for the given query asynchronously. This method should be implemented to generate a list of steps to accomplish the query based on the provided query and tools. Arguments: query str - The user query to generate a list of steps for. tool_list list[Tool] - A list of tools available for the plan. end_user EndUser - The end user for this plan examples list[Plan] | None - Optional list of example plans to guide the PlanningAgent. plan_inputs list[PlanInput] | None - Optional list of PlanInput objects defining the inputs required for the plan. Returns: StepsOrError - A StepsOrError instance containing either the generated steps or an error. StepsOrError Objects​ class StepsOrError(BaseModel) A list of steps or an error. This model represents either a list of steps for a plan or an error message if the steps could not be created. Attributes: steps list[Step] - The generated steps if successful. error str | None - An error message if the steps could not be created. BasePlanningAgent ObjectsStepsOrError Objects",
      "timestamp": "2025-08-24 06:50:27"
    },
    {
      "url": "https://docs.portialabs.ai/setup-account",
      "title": "Set up your Portia account | Portia AI Docs",
      "content": "Set up your Portia account | Portia AI Docs Skip to main content Set up your Portia cloud account. This will allow you to: Store and retrieve plan runs in the Portia cloud. Access our library of cloud hosted tools. Use the Portia dashboard to: View your plan run history, unhandled clarifications, tool call logs. Manage users, orgs and Portia API keys. You first need to obtain a Portia API key. Head over to (app.portialabs.ai ↗) and navigate to the Manage API keys tab from the left hand nav. There you can generate a new API key. On org usersYou will notice a Manage orgs and users tab. You can set up multiple orgs in Portia. Users under the same org can all see each others' plan runs and tool call logs. By default, Portia will look for the API key in the PORTIA_API_KEY environment variable. You can choose to override it for a specific Portia instance instance by configuring the portia_api_key variable as well. For now let's simply set the environment variable with the key value you generated and proceed to the next section. You can use the command below but it's always preferable to set your API keys in a .env file ultimately. export PORTIA_API_KEY='your-api-key-here' Upgrading your accountYou can upgrade your account to a Pro plan to increase your Portia tool and plan run usage limits. Head over to the Billing page ↗ to upgrade or manage your current plan.",
      "timestamp": "2025-08-24 06:50:30"
    },
    {
      "url": "https://docs.portialabs.ai/generate-plan",
      "title": "Generate a plan | Portia AI Docs",
      "content": "Generate a plan | Portia AI Docs Skip to main contentOn this page Learn how to create structured, multi-agent plans using your LLM of choice and familiarise yourself with the structure of plans created using Portia. TL;DR A plan is the set of steps an LLM thinks it should take in order to respond to a user prompt. A plan is represented by the Plan class and can be generated from a user prompt using the plan method of the Portia class (SDK reference ↗). - Portia uses optimised system prompts and structured outputs to ensure adherence to a plan. - You can create your own plans manually or reload existing plans, which is especially useful for repeatable plan runs. Overview of plans in Portia​ A plan is the set of steps an LLM thinks it should take in order to respond to a user prompt. Plans are: Immutable: Once a plan is generated, it cannot be altered. This is important for auditability. Structured: We use optimised system prompts to guide the LLM along a simple design language when generating a plan. This makes the plan format predictable and easy to process for the purposes of automation. Human-readable: Our planning language is in a simple, serialisable format. It is easy to render and present to users in a human readable front-end experience. This helps your users easily stay on top of your LLM's reasoning. While Portia generates a plan in response to a user prompt and then runs it, you also have the option to create plans yourself manually↗. This is especially suitable for your users' more repeatable routines or if you are latency sensitive. Introducing a Plan​ Let's bring this one to life by looking at an example plan below, created in response to the query Search for the latest SpaceX news from the past 48 hours and if there are at least 3 articles, email Avrana (avrana@kern.ai) a summary of the top 3 developments with subject 'Latest SpaceX Updates'. plan.json{ \"steps\": [ { \"task\": \"Search for the latest SpaceX news from the past 48 hours using the search tool.\", \"inputs\": [], \"tool_id\": \"search_tool\", \"output\": \"$spacex_news_results\" }, { \"task\": \"Summarize the top 3 developments from the SpaceX news articles.\", \"inputs\": [ { \"name\": \"$spacex_news_results\", \"description\": \"The list of SpaceX news articles returned by the search tool.\" } ], \"tool_id\": \"llm_tool\", \"output\": \"$spacex_summary\", \"condition\": \"if $spacex_news_results contains at least 3 articles\" }, { \"task\": \"Email Avrana (avrana@kern.ai) a summary of the top 3 SpaceX developments with the subject 'Latest SpaceX Updates'.\", \"inputs\": [ { \"name\": \"$spacex_summary\", \"description\": \"The summary of the top 3 SpaceX developments.\" } ], \"tool_id\": \"portia:google:gmail:send_email\", \"output\": \"$email_sent\", \"condition\": \"if $spacex_news_results contains at least 3 articles\" } ]} A plan includes a series of steps defined by \"task\" A task describing the objective of that particular step. \"input\" The inputs required to achieve the step. Notice how the LLM is guided to weave the outputs of previous steps as inputs to the next ones where applicable e.g. $spacex_news_results coming out of the first step acts as an input to the second one. \"tool_id\" Any relevant tool needed for the completion of the step. Portia is able to filter for the relevant tools during the multi-shot plan generation process. As we will see later on in this tutorial you can specify the tool registries (directories) you want when handling a user prompt, including local / custom tools and ones provided by third parties. In this example we are referencing tools from Portia's cloud-hosted library, prefixed with portia:. \"output\" The step's final output. As mentioned above, every step output can be referenced in future steps. As we will see shortly, these outputs are serialised and saved in plan run state as it is being executed. \"condition\" An optional condition that's used to control the execution of the step. If the condition is not met, the step will be skipped. This condition will be evaluated by our introspection agent, with the context of the plan and plan run state. Create a plan from a user prompt​ When responding to a user's prompt with Portia, you can either chain the plan generation process to the subsequent instantiation of a plan run from it, or you can choose to decouple them. The latter option allows you for example to display the plan to the user and tweak it before running a plan. Let's look at how we generate a plan from a user prompt. Paste the code below into your project and run it: main.pyfrom dotenv import load_dotenvfrom portia import ( Portia, default_config, example_tool_registry,)load_dotenv()# Instantiate a Portia instance. Load it with the default config and with the example tools.portia = Portia(tools=example_tool_registry)# Generate the plan from the user queryplan = portia.plan('Which stock price grew faster in 2024, Amazon or Google?')# Serialise into JSON and print the outputprint(plan.model_dump_json(indent=2)) As mentioned earlier in the documentation, the Portia instance class is your main entrypoint to interact with Portia's libraries (SDK reference ↗). The plan method is available from the Portia instance class and allows you to generate a plan from the query. Running the plan method per the code above returns a Plan object (SDK reference ↗) which looks as follows: plan.json{ \"id\": \"plan-1dcd74a4-0af5-490a-a7d0-0df4fd983977\", \"plan_context\": { \"query\": \"Which stock price grew faster, Amazon or Google?\", \"tool_ids\": [\"calculator_tool\", \"weather_tool\", \"search_tool\"] }, \"steps\": [ { \"task\": \"Search for the latest stock price growth data for Amazon.\", \"inputs\": [], \"tool_id\": \"search_tool\", \"output\": \"$amazon_stock_growth\" }, { \"task\": \"Search for the latest stock price growth data for Google.\", \"inputs\": [], \"tool_id\": \"search_tool\", \"output\": \"$google_stock_growth\" }, { \"task\": \"Compare the stock price growth of Amazon and Google.\", \"inputs\": [ { \"name\": \"$amazon_stock_growth\", \"value\": null, \"description\": \"The stock price growth data for Amazon.\" }, { \"name\": \"$google_stock_growth\", \"value\": null, \"description\": \"The stock price growth data for Google.\" } ], \"tool_id\": \"llm_tool\", \"output\": \"$stock_growth_comparison\" } ]} The plan method can take the following additional parameters: tools in order to confine the plan generation to a narrower set of tools if required (for simplicity or for user-access considerations). In our example above we provided the example_tool_registry, which is a collection of three open source tools in our SDK. example_plans expects a list of Plan objects. This allows you to use existing plans as inspiration or templates, which improves repeatability for more routine plan runs. User led learning​ Example plans can be used to bias the planner towards actions, tool use and behaviours, while also improving the planners ability to generate more complex plans. Broadly, the process for doing this with portia is 3 steps below \"Like\" plans saved to Portia Cloud from the dashboard to signal that they are patterns you want to reinforce. Pull \"Liked\" plans based on semantic similarity to the user intent in a query by using our freshly minted portia.storage.get_similar_plans method (SDK reference ↗). Finally, ingest those similar plans as example plans in the Planning agent using the portia.plan method's example_plans property (SDK reference ↗). For a deep dive into this feature and a practical example, check out our ULL blog post on example plans ↗. Now that you know how to generate plans in response to a user query, let's take a look at how to run a plan in the next section. Structured Output Schema​ For some plans you might want to have a structured output at the end of a plan, for this we allow the ability to attach a structured output schema to the plan that the summarizer agent will attempt to coerce the results to. This is optional. To use, attach to the Plan object, and any Plan Runs that are created from this will attempt to use structured output for the final result, this can pull information from any point of the plan steps and is not just the final step. To attach a schema, you can do it through the PlanBuilder or the Plan interfaces, as below. plan_structured_output.pyfrom portia.plan import PlanBuilderfrom pydantic import BaseModelfrom dotenv import load_dotenvfrom portia import ( Portia, default_config, example_tool_registry,)load_dotenv()portia = Portia(tools=example_tool_registry)# Final Output schema type to coerce toclass FinalPlanOutput(BaseModel): result: float # result here is an integer output from calculator tool, but will be converted to a float via structured output# Example via plan builder, attach to the plan at top levelplan = PlanBuilder( \"Add 1 + 1\", structured_output_schema=FinalPlanOutput).step( \"Add 1 + 1\", tool_id='calculator_tool').build()# Example via plan interfaceplan2 = portia.plan(\"Add 1 + 1\", structured_output_schema=FinalPlanOutput) Run the plan as normal and the final output will be an instance of the attached schema.Overview of plans in PortiaIntroducing a PlanCreate a plan from a user promptUser led learningStructured Output Schema",
      "timestamp": "2025-08-24 06:50:33"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/gcp-cloud-run",
      "title": "GCP Cloud Run | Portia AI Docs",
      "content": "GCP Cloud Run | Portia AI Docs Skip to main contentOn this page Description​ Deploys applications to Google Cloud Run through automated containerization, project setup, and service management with support for both local files and provided content. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"cloud-run-mcp\", command=\"npx\", args=[\"-y\", \"https://github.com/GoogleCloudPlatform/cloud-run-mcp\"],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"cloud-run-mcp\", command=\"npx\", args=[\"-y\", \"https://github.com/GoogleCloudPlatform/cloud-run-mcp\"],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:50:36"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/clarification",
      "title": "portia.clarification | Portia AI Docs",
      "content": "portia.clarification | Portia AI Docs Skip to main contentOn this pageClarification Primitives. This module defines base classes and utilities for handling clarifications in the Portia system. Clarifications represent questions or actions requiring user input to resolve, with different types of clarifications for various use cases such as arguments, actions, inputs, multiple choices, and value confirmations. ClarificationCategory Objects​ class ClarificationCategory(PortiaEnum) The category of a clarification. This enum defines the different categories of clarifications that can exist, such as arguments, actions, inputs, and more. It helps to categorize clarifications for easier handling and processing. Clarification Objects​ class Clarification(BaseModel, ABC) Base Model for Clarifications. A Clarification represents a question or action that requires user input to resolve. For example it could indicate the need for OAuth authentication, missing arguments for a tool or a user choice from a list. Attributes: id ClarificationUUID - A unique identifier for this clarification. category ClarificationCategory - The category of this clarification, indicating its type. response SERIALIZABLE_TYPE_VAR | None - The user's response to this clarification, if any. step int | None - The step this clarification is associated with, if applicable. user_guidance str - Guidance provided to the user to assist with the clarification. resolved bool - Whether the clarification has been resolved by the user. ActionClarification Objects​ class ActionClarification(Clarification) Action-based clarification. Represents a clarification that involves an action, such as clicking a link. The response is set to True once the user has completed the action associated with the link. Attributes: category ClarificationCategory - The category for this clarification, 'Action'. action_url HttpUrl - The URL for the action that the user needs to complete. require_confirmation bool - Whether the user needs to confirm once the action has been completed. serialize_action_url​ @field_serializer(\"action_url\")def serialize_action_url(action_url: HttpUrl) -> str Serialize the action URL to a string. Arguments: action_url HttpUrl - The URL to be serialized. Returns: str - The serialized string representation of the URL. InputClarification Objects​ class InputClarification(Clarification) Input-based clarification. Represents a clarification where the user needs to provide a value for a specific argument. This type of clarification is used when the user is prompted to enter a value. Attributes: category ClarificationCategory - The category for this clarification, 'Input'. MultipleChoiceClarification Objects​ class MultipleChoiceClarification(Clarification) Multiple choice-based clarification. Represents a clarification where the user needs to select an option for a specific argument. The available options are provided, and the user must select one. Attributes: category ClarificationCategory - The category for this clarification 'Multiple Choice'. options list[Serializable] - The available options for the user to choose from. Methods: validate_response - Ensures that the user's response is one of the available options. validate_response​ @model_validator(mode=\"after\")def validate_response() -> Self Ensure the provided response is an option. This method checks that the response provided by the user is one of the options. If not, it raises an error. Returns: Self - The validated instance. Raises: ValueError - If the response is not one of the available options. ValueConfirmationClarification Objects​ class ValueConfirmationClarification(Clarification) Value confirmation clarification. Represents a clarification where the user is presented with a value and must confirm or deny it. The clarification should be created with the response field already set, and the user indicates acceptance by setting the resolved flag to True. Attributes: category ClarificationCategory - The category for this clarification, 'Value Confirmation'. UserVerificationClarification Objects​ class UserVerificationClarification(Clarification) User verification clarification. Represents a clarification where the user some information that they must verify. Attributes: category ClarificationCategory - The category for this clarification, 'User Verification'. validate_response​ @field_validator(\"response\")@classmethoddef validate_response(cls, v: Any) -> Any Validate that response is a boolean value or None. Arguments: v - The value to validate. Returns: Any - The validated value. Raises: ValueError - If the response is not a boolean. user_confirmed​ @propertydef user_confirmed() -> bool Whether the user has confirmed the verification. Returns the response attribute as a boolean value. CustomClarification Objects​ class CustomClarification(Clarification) Custom clarifications. Allows the user to extend clarifications with arbitrary data. The user is responsible for handling this clarification type. Attributes: category ClarificationCategory - The category for this clarification, 'Custom'. ClarificationType​ A list of clarifications of any type.ClarificationCategory ObjectsClarification ObjectsActionClarification ObjectsInputClarification ObjectsMultipleChoiceClarification ObjectsValueConfirmationClarification ObjectsUserVerificationClarification ObjectsCustomClarification Objects",
      "timestamp": "2025-08-24 06:50:39"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/mongodb",
      "title": "MongoDB | Portia AI Docs",
      "content": "MongoDB | Portia AI Docs Skip to main contentOn this page Description​ Provides a bridge between MongoDB databases and conversational interfaces, enabling comprehensive database operations, collection management, schema inspection, and Atlas cloud service interactions with authentication and telemetry support. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"mongodb\", command=\"npx\", args=[\"-y\", \"mongodb-mcp-server\", \"--connectionString\", \"<connection_string>\"],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"mongodb\", command=\"npx\", args=[\"-y\", \"mongodb-mcp-server\", \"--connectionString\", \"<connection_string>\"],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:50:42"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/basic-memory",
      "title": "Basic Memory | Portia AI Docs",
      "content": "Basic Memory | Portia AI Docs Skip to main contentOn this page Description​ Knowledge management system that builds a persistent semantic graph in markdown, locally. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"basic-memory\", command=\"uvx\", args=[ \"basic-memory\", \"mcp\", ],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"basic-memory\", command=\"uvx\", args=[ \"basic-memory\", \"mcp\", ],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:50:45"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/shopify",
      "title": "Shopify | Portia AI Docs",
      "content": "Shopify | Portia AI Docs Skip to main contentOn this page Description​ Integrates with individual Shopify stores to enable product catalog search, cart management, and policy inquiries for complete shopping experiences from discovery to checkout. Authorisation​ This server does not require any extra authentication to use, other than the MCP server URL. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:50:48"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/local_file_writer_tool",
      "title": "portia.open_source_tools.local_file_writer_tool | Portia AI Docs",
      "content": "portia.open_source_tools.local_file_writer_tool | Portia AI Docs Skip to main contentOn this pageLocal file writer tool. FileWriterToolSchema Objects​ class FileWriterToolSchema(BaseModel) Schema defining the inputs for the FileWriterTool. FileWriterTool Objects​ class FileWriterTool(Tool[str]) Writes content to a file. run​ def run(_: ToolRunContext, filename: str, content: str) -> str Run the FileWriterTool.FileWriterToolSchema ObjectsFileWriterTool Objects",
      "timestamp": "2025-08-24 06:50:51"
    },
    {
      "url": "https://docs.portialabs.ai/understand-clarifications",
      "title": "Understand clarifications | Portia AI Docs",
      "content": "Understand clarifications | Portia AI Docs Skip to main contentOn this page Define clarifications to bring structured input into a plan run. Understand the different types of clarifications and how to use them. TL;DR An agent can raise a clarification during a plan run to pause it and solicit human input. This pauses the plan run, serialises and saves its state at the step where clarification was raised. We represent a clarification with the Clarification class (SDK reference ↗). This includes useful information such as guidance to be surfaced to the user when soliciting their input. Because it is a structured object, you can easily serve it to an end user using a front end of your choosing when it is encountered. The user response is captured in the Clarification object itself, which is part of the PlanRun state. This means the plan run can be resumed, and the step at which the clarification was required can now be completed. Intro to clarifications​ Portia introduces the concept of clarifications. An agent can raise a clarification during a plan run to pause it and solicit human input. This is important because: LLM-driven tasks that are multi-step can be brittle and unreliable e.g. if an input is missing the LLM may hallucinate it. Instead we allow you to pause Portia-managed plan run and raise a clarification to the user so they can resolve the missing input for the LLM. During plan run, there may be tasks where your organisation's policies require explicit approvals from specific people e.g. allowing bank transfers over a certain amount. Clarifications allow you to define these conditions so the agent running a particular step knows when to pause the plan run and solicit input in line with your policies. More advanced use cases of clarifications also include hand off to a different part of your system based on certain conditions having been met. The structured nature of clarifications make this handoff easy to manage. When Portia encounters a clarification and pauses a plan run, it serialises and saves the latest plan run state. Once the clarification is resolved, the obtained human input captured during clarification handling is added to the plan run state and the agent can resume step execution. Types of clarifications​ Clarifications are represented by the Clarification class (SDK reference ↗). Because it is a structured object, you can easily serve it to an end user using a front end of your choosing when it is encountered e.g. a chatbot or app like Slack, email etc. We offer five categories of clarifications at the moment. You can see the properties and behaviours specific to each type in the tabs below. The common properties across all clarifications are: uuid: Unique ID for this clarification category: The type of clarification response: User's response to the clarification step: Plan run step where this clarification was raised user_guidance: Guidance provided to the user to explain the nature of the clarification resolved: Boolean of the clarification state Action clarificationsInput clarificationsMultiple choice clarificationsValue confirmation clarificationsCustom clarificationsAction clarifications are useful when a user action is needed to complete a step e.g. clicking on an action_url to complete an authentication flow or to make a payment. You will need to have a way to receive a callback from such a flow in order to confirm whether the clarification was resolved successfully.action_clarification.json{ \"uuid\": \"clar-425c8ce9-8fc9-43af-b99e-64903043c5df\", \"plan_run_id\": \"prun-89c6bd4f-29d2-4aad-bf59-8ba3229fd258\", \"category\": “Action”, \"response\": “success”, \"step\": 1, \"user_guidance\": \"Click here to authenticate\", \"resolved\": true, \"action_url\": “https://accounts.google.com/o/oauth2/…”,}Input clarifications are used when a tool call is missing one argument and the user needs to provide it e.g. a send_email tool needs to be invoked but no email is resolvable from the user query. The argument attribute points to the tool argument this clarification resolves.input_clarification.json{ \"uuid\": \"clar-425c8ce9-8fc9-43af-b99e-64903043c5df\", \"plan_run_id\": \"prun-89c6bd4f-29d2-4aad-bf59-8ba3229fd258\", \"category\": “Input”, \"response\": “avrana@kern.ai”, \"step\": 2, \"user_guidance\": \"Please provide me with Avrana's email address\", \"resolved\": true, \"argument\": \"$avrana_email\",}Multiple choice clarifications are raised when a tool argument is restricted to a list of values but the agent attempting to invoke the tool is given an argument that falls outside that list. The clarification can be used to serve the acceptable list of values for the user to choose from via the options attribute.multiple_choice_clarification.json{ \"uuid\": \"clar-425c8ce9-8fc9-43af-b99e-64903043c5df\", \"plan_run_id\": \"prun-89c6bd4f-29d2-4aad-bf59-8ba3229fd258\", \"category\": “Multiple Choice”, \"response\": “ron_swanson@pawnee.com, \"step\": 2, \"user_guidance\": \"Please select a recipient.\", \"resolved\": true, \"argument\": \"$recipient\", \"options\": [ \"ron_swanson@pawnee.com\", \"ron_burgundy@kvwnchannel4.com\", \"ron@gone_wrong.com\" ]}Value confirmation clarifications are raised to get the user to confirm or deny if they want to proceed with a particular value. This is particularly useful for 'human in the loop' tasks where you want to get the user to confirm the value before proceeding.value_confirmation_clarification.json{ \"uuid\": \"clar-425c8ce9-8fc9-43af-b99e-64903043c5df\", \"plan_run_id\": \"prun-89c6bd4f-29d2-4aad-bf59-8ba3229fd258\", \"category\": “Value Confirmation”, \"step\": 2, \"user_guidance\": \"This will email all contacts in your database. Are you sure you want to proceed?\", \"resolved\": true, \"argument\": \"$email_all_contacts\"}Custom clarifications enable you to attach arbitrary information to a clarification.custom_clarification.json{ \"uuid\": \"clar-425c8ce9-8fc9-43af-b99e-64903043c5df\", \"plan_run_id\": \"prun-89c6bd4f-29d2-4aad-bf59-8ba3229fd258\", \"category\": “Custom”, \"step\": 2, \"user_guidance\": \"Which product did you want to buy?\", \"resolved\": true, \"data\": { \"product_id\": \"prod-1234567890\" }} Clarification triggers​ Clarifications are raised in one of three scenarios: LLM-triggered: During plan run, an agent attempting to complete a step notices that an input is missing, resulting in an Input clarification. Tool-triggered: A clarification is explicitly raised in the python class definition of the tool in specific conditions e.g. if a requisite OAuth token is missing to complete the underlying API call or if a tool argument is invalid, resulting in Action or a Multiple Choice clarification respectively. Starting or resuming a plan run: Before a plan run is started or resumed, the Portia runner checks the readiness of all tools mentioned in the plan. Clarifications are raised if any of the tools are not ready to be used. Portia tools use this mechanism to request user Authorization - see more details here ↗. Handle clarifications with your Portia instance​ Make a weather.txt file for this sectionWe're going to see how Portia handles multiple choices with clarifications. In this example we will import our open source tool FileReaderTool and ask it to open a non-existent local file weather.txt. This should trigger the tool to search for the file across the rest of the project directory and return all matches. Make sure to sprinkle a few copies of a weather.txt file around in the project directory. Note: Our weather.txt file contains \"The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.\" When the conditions requiring a clarification are met, the relevant tool call returns a Clarification object, the plan run is paused and the plan run state becomes NEED CLARIFICATION. Portia has now passed control of the plan run to you, the developer, along with the Clarification object in order for you to resolve with human or machine input. At this stage we need to make some changes in the main.py file to handle clarifications. main.pyfrom portia import ( InMemoryToolRegistry, MultipleChoiceClarification, Portia, PlanRunState, default_config,)from portia.open_source_tools.local_file_reader_tool import FileReaderToolfrom portia.open_source_tools.local_file_writer_tool import FileWriterTool# Load open source tools into a tool registry. More on tool registries later in the docs!my_tool_registry = InMemoryToolRegistry.from_local_tools([FileReaderTool(), FileWriterTool()])# Instantiate a Portia instance. Load it with the default config and with the tools aboveportia = Portia(tools=my_tool_registry)# Execute the plan from the user queryplan_run = portia.run('Read the contents of the file \"weather.txt\"')# Check if the plan run was paused due to raised clarificationswhile plan_run.state == PlanRunState.NEED_CLARIFICATION: # If clarifications are needed, resolve them before resuming the plan run for clarification in plan_run.get_outstanding_clarifications(): # For each clarification, prompt the user for input print(f\"{clarification.user_guidance}\") user_input = input(\"Please enter a value:\\n\" + ((\"\\n\".join(clarification.options) + \"\\n\") if isinstance(clarification, MultipleChoiceClarification) else \"\")) # Resolve the clarification with the user input plan_run = portia.resolve_clarification(clarification, user_input, plan_run) # Once clarifications are resolved, resume the plan run plan_run = portia.resume(plan_run)# Serialise into JSON and print the outputprint(plan_run.model_dump_json(indent=2)) The keen eye may have noticed that we introduced the InMemoryToolRegistry class. Fear not, we will discuss tool registries in a later section. For now let's focus on the clarification handling sections highlighted in the code. Remember to make sure you don't have a weather.txt file in the same folder as your python file AND make a few copies of a weather.txt file sprinkled around in other folders of the project directory. This will ensure that the prompt triggers the multiple choice clarifications on the filename argument of the FileReaderTool. The tool call will return a Clarification object per changes made in the previous section and pause the plan_run. The changes you need to make to our main.py in order to enable this behaviour are as follows: Check if the state of the PlanRun object returned by the run method is PlanRunState.NEED_CLARIFICATION. This means the plan run paused before completion due to a clarification. Use the get_outstanding_clarifications method of the PlanRun object to access all clarifications where resolved is false. For each Clarification, surface the user_guidance to the relevant user and collect their input. Use the portia.resolve_clarification method to capture the user input in the response attribute of the relevant clarification. Because clarifications are part of the plan run state itself, this means that the plan run now captures the latest human input gathered and can be resumed with the new information. Once this is done you can resume the plan run using the resume method. In fact resume can take a PlanRun in any state as a parameter and will kick off that plan run from that current state. In this particular example, it resumes the plan run from the step where the clarifications were encountered. For the example query above Read the contents of the file \"weather.txt\"., where the user resolves the clarification by entering one of the options offered by the clarification (in this particular case demo_runs/weather.txt in our project directory momo_sdk_tests), you should see the following plan run state and notice: The multiple choice clarification where the user_guidance was generated by Portia based on your clarification definition in the FileReaderTool class, The response in the second plan run snapshot reflecting the user input, and the change in resolved to true as a result The plan run state will appear to NEED_CLARIFICATION if you look at the logs at the point when the clarification is raised. It then progresses to COMPLETE once you respond to the clarification and the plan run is able to resume: run_state.json{ \"id\": \"prun-54d157fe-4b99-4dbb-a917-8fd8852df63d\", \"plan_id\": \"plan-b87de5ac-41d9-4722-8baa-8015327511db\", \"current_step_index\": 0, \"state\": \"COMPLETE\", \"outputs\": { \"clarifications\": [ { \"id\": \"clar-216c13a1-8342-41ca-99e5-59394cbc7008\", \"category\": \"Multiple Choice\", \"response\": \"../momo_sdk_tests/demo_runs/weather.txt\", \"step\": 0, \"user_guidance\": \"Found weather.txt in these location(s). Pick one to continue:\\n['../momo_sdk_tests/demo_runs/weather.txt', '../momo_sdk_tests/my_custom_tools/__pycache__/weather.txt']\", \"resolved\": true, \"argument_name\": \"filename\", \"options\": [ \"../momo_sdk_tests/demo_runs/weather.txt\", \"../momo_sdk_tests/my_custom_tools/__pycache__/weather.txt\" ] } ], \"step_outputs\": { \"$file_contents\": { \"value\": \"The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.\", \"summary\": null } }, \"final_output\": { \"value\": \"The current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C.\", \"summary\": null } }} Handle clarifications with a ClarificationHandler​ Through the above example, we explicitly handle the clarifications in order to demonstrate the full clarification handling flow. However, Portia also offers a ClarificationHandler class that can be used to simplify the handling of clarifications. In order to use this, simply create your own class that inherits from ClarificationHandler and implement the methods for handling the types of clarifications you expect to handle. Each method takes an on_resolution and on_error parameter - these can be called either synchronously or asynchronously when the clarification handling is finished. This allows handling clarifications in many different ways - for example, they could be handled by the user in a UI, or they could be handled in an email or slack message. Once you've created your clarifiication handler, it can be passed in as an execution hook when creating the Portia instance: from portia import Clarification, ClarificationHandler, Config, ExecutionHooks, InputClarification, Portiafrom typing import Callableclass CLIClarificationHandler(ClarificationHandler): \"\"\"Handles clarifications by obtaining user input from the CLI.\"\"\" def handle_input_clarification( self, clarification: InputClarification, on_resolution: Callable[[Clarification, object], None], on_error: Callable[[Clarification, object], None], # noqa: ARG002 ) -> None: \"\"\"Handle a user input clarifications by asking the user for input from the CLI.\"\"\" user_input = input(f\"{clarification.user_guidance}\\nPlease enter a value:\\n\") on_resolution(clarification, user_input)portia = Portia(execution_hooks=ExecutionHooks(clarification_handler=CLIClarificationHandler())) Portia also offers some default clarification handling behaviours that can be used out of the box. For example, you don't actually need to implement your own CLI clarification handler (as done above) because our default CLI execution hooks, CLIExecutionHooks, provide a clarification handler that allows the user to handle clarifications via the CLI. from portia import Config, Portiafrom portia.cli import CLIExecutionHooksportia = Portia(execution_hooks=CLIExecutionHooks())Intro to clarificationsTypes of clarificationsClarification triggersHandle clarifications with your Portia instanceHandle clarifications with a ClarificationHandler",
      "timestamp": "2025-08-24 06:50:54"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/wix",
      "title": "Wix | Portia AI Docs",
      "content": "Wix | Portia AI Docs Skip to main contentOn this page Description​ Enables website creation and management with Wix business solutions including eCommerce, booking systems, payment processing, and CRM functionality through natural language commands. Authorisation​ This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail here (↗). Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to authorise with the server via OAuth when you enable it. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:50:57"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-post",
      "title": "Zendesk - Posts: Show | Portia AI Docs",
      "content": "Zendesk - Posts: Show | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:help_center:show_post Tool description: Gets information about a given post. A post is community content that is created by a user and is not the same as an article. Args schema: { \"description\": \"Input schema for ZendeskShowPostTool.\", \"properties\": { \"post_id\": { \"description\": \"The unique ID of the post\", \"title\": \"Post Id\", \"type\": \"integer\" } }, \"required\": [ \"post_id\" ], \"title\": \"ZendeskShowPostToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:51:00"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-articles-by-section",
      "title": "Zendesk - Sections: List Articles | Portia AI Docs",
      "content": "Zendesk - Sections: List Articles | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:help_center:list_articles_by_section Tool description: Lists all articles in a given section of the Zendesk Help Center. Sections group related articles together. Args schema: { \"description\": \"Input schema for ZendeskListArticlesBySectionToolSchema.\", \"properties\": { \"section_id\": { \"description\": \"The unique ID of the section\", \"title\": \"Section Id\", \"type\": \"integer\" } }, \"required\": [ \"section_id\" ], \"title\": \"ZendeskListArticlesBySectionToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:51:03"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-ticket-metrics",
      "title": "Zendesk - Tickets: Show Metrics | Portia AI Docs",
      "content": "Zendesk - Tickets: Show Metrics | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:tickets:show_metrics Tool description: Returns metrics for a specific ticket, including first response time, full resolution time, number of reopens, and other performance metrics. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Args schema: { \"description\": \"Input schema for ZendeskShowTicketMetricsTool.\", \"properties\": { \"ticket_id\": { \"description\": \"The ID of the ticket to retrieve metrics for\", \"title\": \"Ticket Id\", \"type\": \"string\" } }, \"required\": [ \"ticket_id\" ], \"title\": \"ZendeskShowTicketMetricsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload containing ticket metrics including resolution times, reply times, number of reopens, and other performance data.')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:51:06"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/semgrep",
      "title": "Semgrep | Portia AI Docs",
      "content": "Semgrep | Portia AI Docs Skip to main contentOn this page Description​ Integrates with Semgrep's static analysis engine to scan code for security vulnerabilities and coding issues, enabling developers to identify and fix potential problems directly within their coding workflow. Authorisation​ This server does not require any extra authentication to use, other than the MCP server URL. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:51:09"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/make",
      "title": "Make | Portia AI Docs",
      "content": "Make | Portia AI Docs Skip to main contentOn this page Description​ Connects AI systems to Make automation workflows, enabling assistants to trigger scenarios with parameters and receive structured JSON output from your existing Make account. Authorisation​ This server does not require any extra authentication to use, other than the MCP server URL. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:51:12"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/errors",
      "title": "portia.errors | Portia AI Docs",
      "content": "portia.errors | Portia AI Docs Skip to main contentOn this pageCentral definition of error classes. This module defines custom exception classes used throughout the application. These exceptions help identify specific error conditions, particularly related to configuration, planning, runs, tools, and storage. They provide more context and clarity than generic exceptions. Classes in this file include: ConfigNotFoundError: Raised when a required configuration value is not found. InvalidConfigError: Raised when a configuration value is invalid. PlanError: A base class for exceptions in the query planning_agent module. PlanNotFoundError: Raised when a plan is not found. PlanRunNotFoundError: Raised when a PlanRun is not found. ToolNotFoundError: Raised when a tool is not found. DuplicateToolError: Raised when a tool is registered with the same name. InvalidToolDescriptionError: Raised when a tool description is invalid. ToolRetryError: Raised when a tool fails after retries. ToolFailedError: Raised when a tool fails with a hard error. InvalidConfigError0: Raised when a plan run is in an invalid state. InvalidConfigError1: Raised when the agent produces invalid output. InvalidConfigError2: Raised when a tool encounters an unrecoverable error. InvalidConfigError3: Raised when a tool encounters an error that can be retried. InvalidConfigError4: Raised when an issue occurs with storage. PortiaBaseError Objects​ class PortiaBaseError(Exception) Base class for all our errors. SkipExecutionError Objects​ class SkipExecutionError(PortiaBaseError) Raised when a Portia execution should be stopped or a step should be skipped. __init__​ def __init__(reason: str, should_return: bool = False) -> None Set custom error message. Arguments: reason str - The reason for skipping the step. should_return bool - Whether to return the plan run and stop execution entirely, or just skip the step. ConfigNotFoundError Objects​ class ConfigNotFoundError(PortiaBaseError) Raised when a required configuration value is not found. Arguments: value str - The name of the configuration value that is missing. __init__​ def __init__(value: str) -> None Set custom error message. InvalidConfigError Objects​ class InvalidConfigError(PortiaBaseError) Raised when a configuration value is invalid. Arguments: value str - The name of the invalid configuration value. issue str - A description of the issue with the configuration value. __init__​ def __init__(value: str, issue: str) -> None Set custom error message. PlanError Objects​ class PlanError(PortiaBaseError) Base class for exceptions in the query planning_agent module. This exception indicates an error that occurred during the planning phase. Arguments: error_string str - A description of the error encountered during planning. __init__​ def __init__(error_string: str) -> None Set custom error message. PlanNotFoundError Objects​ class PlanNotFoundError(PortiaBaseError) Raised when a plan with a specific ID is not found. Arguments: plan_id PlanUUID - The ID of the plan that was not found. __init__​ def __init__(plan_id: PlanUUID) -> None Set custom error message. PlanRunNotFoundError Objects​ class PlanRunNotFoundError(PortiaBaseError) Raised when a PlanRun with a specific ID is not found. Arguments: plan_run_id UUID | str | None - The ID or name of the PlanRun that was not found. __init__​ def __init__(plan_run_id: PlanRunUUID | str | None) -> None Set custom error message. ToolNotFoundError Objects​ class ToolNotFoundError(PortiaBaseError) Raised when a tool with a specific ID is not found. Arguments: tool_id str - The ID of the tool that was not found. __init__​ def __init__(tool_id: str) -> None Set custom error message. DuplicateToolError Objects​ class DuplicateToolError(PortiaBaseError) Raised when a tool is registered with the same name. Arguments: tool_id str - The ID of the tool that already exists. __init__​ def __init__(tool_id: str) -> None Set custom error message. InvalidToolDescriptionError Objects​ class InvalidToolDescriptionError(PortiaBaseError) Raised when a tool description is invalid. Arguments: tool_id str - The ID of the tool with an invalid description. __init__​ def __init__(tool_id: str) -> None Set custom error message. ToolRetryError Objects​ class ToolRetryError(PortiaBaseError) Raised when a tool fails after retrying. Arguments: tool_id str - The ID of the tool that failed. error_string str - A description of the error that occurred. __init__​ def __init__(tool_id: str, error_string: str) -> None Set custom error message. ToolFailedError Objects​ class ToolFailedError(PortiaBaseError) Raised when a tool fails with a hard error. Arguments: tool_id str - The ID of the tool that failed. error_string str - A description of the error that occurred. __init__​ def __init__(tool_id: str, error_string: str) -> None Set custom error message. InvalidPlanRunStateError Objects​ class InvalidPlanRunStateError(PortiaBaseError) Raised when a plan run is in an invalid state. InvalidAgentError Objects​ class InvalidAgentError(PortiaBaseError) Raised when an agent is in an invalid state. __init__​ def __init__(state: str) -> None Set custom error message. InvalidAgentOutputError Objects​ class InvalidAgentOutputError(PortiaBaseError) Raised when the agent produces invalid output. Arguments: content str - The invalid content returned by the agent. __init__​ def __init__(content: str) -> None Set custom error message. ToolHardError Objects​ class ToolHardError(PortiaBaseError) Raised when a tool encounters an error it cannot retry. Arguments: cause Exception | str - The underlying exception or error message. __init__​ def __init__(cause: Exception | str) -> None Set custom error message. ToolSoftError Objects​ class ToolSoftError(PortiaBaseError) Raised when a tool encounters an error that can be retried. Arguments: cause Exception | str - The underlying exception or error message. __init__​ def __init__(cause: Exception | str) -> None Set custom error message. StorageError Objects​ class StorageError(PortiaBaseError) Raised when there's an issue with storage. Arguments: cause Exception | str - The underlying exception or error message. __init__​ def __init__(cause: Exception | str) -> None Set custom error message.PortiaBaseError ObjectsSkipExecutionError ObjectsConfigNotFoundError ObjectsInvalidConfigError ObjectsPlanError ObjectsPlanNotFoundError ObjectsPlanRunNotFoundError ObjectsToolNotFoundError ObjectsDuplicateToolError ObjectsInvalidToolDescriptionError ObjectsToolRetryError ObjectsToolFailedError ObjectsInvalidPlanRunStateError ObjectsInvalidAgentError ObjectsInvalidAgentOutputError ObjectsToolHardError ObjectsToolSoftError ObjectsStorageError Objects",
      "timestamp": "2025-08-24 06:51:15"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-sheets/",
      "title": "Google Sheets Tools | Portia AI Docs",
      "content": "Google Sheets Tools | Portia AI Docs Skip to main content Sheets: Get SpreadsheetGets the content of a spreadsheet from Google Sheets by ID. The GoogleDriveSearchTool should be used to search for a spreadsheet by name if an ID is not known.",
      "timestamp": "2025-08-24 06:51:18"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/biomcp",
      "title": "BioMCP | Portia AI Docs",
      "content": "BioMCP | Portia AI Docs Skip to main contentOn this page Description​ Integrates with biomedical databases including ClinicalTrials.gov, PubMed, and MyVariant.info to provide structured access to clinical trials, research articles, and genetic variants with intelligent data rendering and source attribution. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"biomcp\", command=\"uv\", args=[\"run\", \"--with\", \"biomcp-python\", \"biomcp\", \"run\"],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"biomcp\", command=\"uv\", args=[\"run\", \"--with\", \"biomcp-python\", \"biomcp\", \"run\"],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:51:21"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/search",
      "title": "Open Source - Search | Portia AI Docs",
      "content": "Open Source - Search | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: search_tool Tool description: Searches the internet (using Tavily) to find answers to the search query provided and returns those answers, including images, links and a natural language answer. The search tool has access to general information but can not return specific information on users or information not available on the internet Usage notes: This tool uses the Tavily API. You can sign up to obtain a Tavily API key (↗) and set it in the environment variable TAVILY_API_KEY. Args schema: { \"description\": \"Input for SearchTool.\", \"properties\": { \"search_query\": { \"description\": \"The query to search for. For example, 'what is the capital of France?' or 'who won the US election in 2020?'\", \"title\": \"Search Query\", \"type\": \"string\" } }, \"required\": [ \"search_query\" ], \"title\": \"SearchToolSchema\", \"type\": \"object\"} Output schema: ('str', 'str: output of the search results')UsageTool details",
      "timestamp": "2025-08-24 06:51:24"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/list-users",
      "title": "Slack - Users: List | Portia AI Docs",
      "content": "Slack - Users: List | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Slack tools with Portia AI​ You will need to create your own Slack App to use with Portia AI. This is so you can control the name and appearance of slack bot activity initiated via the Portia AI framework. Once your slack app is created you can configure your client ID and secret in the Portia dashboard. Install a Slack app​ Head over to api.slack.com/apps ↗ Create an app from scratch and select the Slack workplace you would like to use it in. Note down the client ID and secret on the Basic Information page. We will need this in a couple of steps from now! In the OAuth & Permissions tab further down in the left hand nav, add as Redirect URL the following URL https://api.portialabs.ai/api/v0/oauth/slack (don't forget to hit that Save URLs button!). Under Bot Token Scopes, be sure to add the scopes channels:history -- View messages and other content in public channels that your Slack app has been added to. channels:read -- View basic information about public channels in a workspace. chat:write -- Send messages as @{your slack app name}. users:read -- View people in a workspace. Under User Token Scopes, be sure to add the scope search:read to support searching workplace content. Now scroll up to the top of the OAuth & Permissions page and hit the Install to {your workplace name} button. Once that is done, open your Slack app and hit 'Add apps` and be sure to select your new app. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the client ID and secret of your Slack app as collected in step 3 of the Slack installation process above. You are now ready to call Slack tools on our cloud! Tool details​ Tool ID: portia:slack:bot:list_user_ids Tool description: List all users in the slack workspace. Returns user meta information: Name, ID, and EmailThis tool should be used when you need to make api calls to other slack apis that requirea user ID. Args schema: { \"description\": \"Input for ListSlackUserIDsTool.\", \"properties\": {}, \"title\": \"ListSlackUserIDsToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: User meta information: Name, ID, and Email')UsageConfigure your Slack tools with Portia AIInstall a Slack appConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:51:27"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/conditional_evaluation_agent",
      "title": "portia.execution_agents.conditional_evaluation_agent | Portia AI Docs",
      "content": "portia.execution_agents.conditional_evaluation_agent | Portia AI Docs Skip to main contentOn this pageConditional evaluation agent for PlanV2. BooleanResponse Objects​ class BooleanResponse(BaseModel) Boolean response for conditional evaluation. ConditionalEvaluationAgent Objects​ class ConditionalEvaluationAgent() Conditional evaluation agent for PlanV2. __init__​ def __init__(config: Config) -> None Initialize the conditional evaluation agent. execute​ @traceable(name=\"Conditional Evaluation Agent - Execute\")async def execute(conditional: str, arguments: dict[str, Any]) -> bool Execute the conditional evaluation agent.BooleanResponse ObjectsConditionalEvaluationAgent Objects",
      "timestamp": "2025-08-24 06:51:30"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/telemetry/views",
      "title": "portia.telemetry.views | Portia AI Docs",
      "content": "portia.telemetry.views | Portia AI Docs Skip to main contentOn this pagePortia telemetry views. BaseTelemetryEvent Objects​ @dataclassclass BaseTelemetryEvent(ABC) Base class for all telemetry events. This abstract class defines the interface that all telemetry events must implement. It provides a common structure for event name and properties. name​ @property@abstractmethoddef name() -> str Get the name of the telemetry event. Returns: str - The name of the telemetry event. properties​ @propertydef properties() -> dict[str, Any] Get the properties of the telemetry event. Returns: dict[str, Any]: A dictionary containing all properties of the event, excluding the 'name' property. PortiaFunctionCallTelemetryEvent Objects​ @dataclassclass PortiaFunctionCallTelemetryEvent(BaseTelemetryEvent) Telemetry event for tracking Portia function calls. Attributes: function_name - The name of the function being called. function_call_details - Additional details about the function call. name​ type: ignore reportIncompatibleMethodOverride ToolCallTelemetryEvent Objects​ @dataclassclass ToolCallTelemetryEvent(BaseTelemetryEvent) Telemetry event for tracking tool calls. Attributes: tool_id - The identifier of the tool being called, if any. name​ type: ignore reportIncompatibleMethodOverrideBaseTelemetryEvent ObjectsPortiaFunctionCallTelemetryEvent ObjectsToolCallTelemetryEvent Objects",
      "timestamp": "2025-08-24 06:51:33"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/netlify",
      "title": "Netlify | Portia AI Docs",
      "content": "Netlify | Portia AI Docs Skip to main contentOn this page Description​ Integrates with Netlify's platform for complete site management including project operations, deployments with zip uploads, team administration, extension configuration, and documentation access across hosting, build, and collaboration workflows. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"netlify\", command=\"npx\", args=[\"-y\", \"@netlify/mcp\"], env={ \"NETLIFY_PERSONAL_ACCESS_TOKEN\": \"<api_key>\", },) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"netlify\", command=\"npx\", args=[\"-y\", \"@netlify/mcp\"], env={ \"NETLIFY_PERSONAL_ACCESS_TOKEN\": \"<api_key>\", },) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:51:36"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github",
      "title": "GitHub Tools | Portia AI Docs",
      "content": "GitHub Tools | Portia AI Docs Skip to main content Issue: ListList issues in a GitHub repository. Repository: ListLists all public repositories for a GitHub organization. Repository: SearchSearches all public repositories for a specific term. Repository: StarStars a GitHub repository.",
      "timestamp": "2025-08-24 06:51:39"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-search-email",
      "title": "Google Gmail - Gmail: Search | Portia AI Docs",
      "content": "Google Gmail - Gmail: Search | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:gmail:search_email Tool description: Searches for emails and drafts in the user's inbox and returns emails content that match the query. Args schema: { \"description\": \"Input for SearchEmailTool.\", \"properties\": { \"query\": { \"description\": \"The query to search for emails. This supports Gmail search syntax (e.g. 'from:jane@acme.com', 'subject:meeting', 'after:YYYY/MM/DD' or 'before:YYYY/MM/DD') or a combination of them.\", \"title\": \"Query\", \"type\": \"string\" } }, \"required\": [ \"query\" ], \"title\": \"SearchEmailToolSchema\", \"type\": \"object\"} Output schema: ('list[dict[str, str]]', 'list[dict[str, str]]: List of emails with the following keys: from, to, subject, date, body and id of the email.')UsageTool details",
      "timestamp": "2025-08-24 06:51:42"
    },
    {
      "url": "https://docs.portialabs.ai/getting-started-tour",
      "title": "A tour of our SDK | Portia AI Docs",
      "content": "A tour of our SDK | Portia AI Docs Skip to main contentOn this page Portia AI enables developers to build powerful, production-ready agents that can interact with real-world APIs, manage context intelligently, and even automate web browsers. This tutorial provides a whistlestop tour of the SDK to get you started. It provides four examples, each building on top of the previous to show how to develop increasingly capable AI agents with just a few lines of code. Our examples repository ↗ on GitHub also provides some advanced agent examples that can be a useful reference. Before you start​ Make sure you have the SDK environment set up: Copy .env.example to .env and fill in the necessary configuration values for the script you want to run. Each Python script documents the configuration required to run it at the top of the file. Run any example using: uv run <script_name>.py This will: Obtain an appropriate version of Python if necessary. Create a virtual environment for your Python dependencies. Install all required dependencies. Run your script! With that out of the way, let's look at running the first sample script! 1. GitHub OAuth integration​ File: 1_github_oauth.py ↗ This is the most straightforward example of using Portia to connect to third-party APIs with OAuth. It demonstrates how an agent can perform actions on behalf of a user, such as starring a GitHub repository or checking availability on their Google Calendar. Key concepts​ OAuth authentication for third-party services. Use of Portia with multiple tools. Simple command execution. Configuring Portia with a .env file​ Before we get started with the Portia-specific code, let's talk about configuration. In all of our examples, we use the popular python-dotenv ↗ library. This library will read a .env file from your current directory, and copy the variables defined in the file into the Python program's environment. Portia automatically reads certain environment variables, such as PORTIA_API_KEY, which allows it to connect to the Portia cloud service. Portia cloud provides useful extra services, such as the ability to: See all the plans created or run against your account. Store credentials for different services, like the GitHub API. Approve certain good plans, making future planning more reliable for your use-cases. Portia will also automatically look for a variable called OPENAI_API_KEY. If it's available, Portia will configure OpenAI as your underlying default LLM, used for planning and other tasks that work with human language. If OPENAI_API_KEY is not available, Portia will look for the following keys in order, and use the first one that is defined: ANTHROPIC_API_KEY MISTRAL_API_KEY GOOGLE_API_KEY AZURE_OPENAI_API_KEY Instead of implicitly loading configuration from your environment (and a .env file), it's often better to explicitly configure Portia. This can be done when obtaining a Config instance, for example: config = Config.from_default(llm_provider=LLMProvider.MISTRALAI) will override any other API keys configured in the environment. Code walkthrough​ Let's step through the first code example. We'll go slower through this first file, so you can understand all the details, and in later examples I'll just cover what's changed. from portia import ( Config, Portia, PortiaToolRegistry, StorageClass,)from portia.cli import CLIExecutionHooks Core Portia functionality is stored in the portia package. Other, more specific APIs are in sub-packages. As you can see here, command-line functionality is stored in portia.cli. ClassWhat does it do?ConfigThis object will load configuration from the environment, and allow you to configure Portia explicitly in code.PortiaThis is the primary class in the Portia SDK, and allows you to plan what an agent will do, and execute that plan with the assistance of any tools that Portia is configured with.PortiaToolRegistryThis is the default set of tools that allows Portia to interact with APIs such as GitHub and Google. The list of tools provided in the PortiaTool Registry is growing all the time. You can find a complete list in the Portia Tool Catalogue ↗StorageClassThis is an enum, allowing you to configure where Portia's state is stored. If you use StorageClass.CLOUD, Portia will store plans and plan runs on Portia's servers, allowing various extended functionality. If you would rather store your state locally, use StorageClass.MEMORY or StorageClass.DISK With that out of the way, let's define a task! This file contains two hard-coded tasks: # A relatively simple task:task0 = \"Star the github repo for portiaAI/portia-sdk-python\"# A more complex task:task1 = \"\"\"Check my availability in Google Calendar for tomorrow between 10am and 12pm.If I have any free times between 10am and 12pm, please schedule a 30-minute meeting withbob (bob@portialabs.ai) with title 'Encode Hackathon', and description 'hack it'.If I don't have any free times, please output the next time after 12pm when I am free.\"\"\" You'll notice, just from the length of the strings, that one task is significantly more complex than the other. For now I'll just focus on task0, which automatically gives us a star on GitHub ↗. The next step is to put all of the classes that we imported to work, and to compose a Portia instance. The following code combines configuration, the list of tools in the Portia Catalogue, and adds in the CLIExecutionHooks, which adds control-flow for Portia to interrupt the run when required, and interact with the user on the command-line. # Instantiate a Portia runner.# Load it with the default config from the environment, and with Portia cloud tools.# Use the CLIExecutionHooks to allow the user to provide input to the agents via the CLI when neededmy_config = Config.from_default(storage_class=StorageClass.CLOUD)portia = Portia( config=my_config, tools=PortiaToolRegistry(my_config), execution_hooks=CLIExecutionHooks(),) Finally, the Portia class is used to run the task! portia.run returns a PlanRun object that contains the outputs of the agent run, including those at each step in the plan. This is very useful for debugging what the agent did, as well as obtaining any output from plan_run.outputs. plan_run = portia.run(task0) In this example: The agent is initialized with the default tools ↗ that are provided with Portia. This includes tools for connecting to the GitHub API and Google Calendar. The run method receives a high-level instruction. Portia handles breaking down the instruction, authenticating where needed and calling any necessary tools. Running the example​ If you haven't done it already, now is a good time to copy the .env.example file and to add your configuration for PORTIA_API_KEY (you can grab this from the the Portia dashboard ↗ if you don't already have one), and provide a key for your favourite LLM. This code has been designed to run with uv. Providing you have uv installed, you can run this example with: uv run 1_github_oauth.py If the user hasn't authorized GitHub yet, Portia will request authentication before proceeding. This is a major feature of Portia! Behind the scenes, this ability for a tool to pause execution of the agent, and to ask the user for input, is super-powerful. We call this process a \"clarification.\" If you're planning to write your own tools to take advantage of this feature, do check out the documentation for clarifications ↗. Before moving on​ Before moving on, why not swap the task variable provided to plan.run()? Trying out the more complex example can show you how powerful autonomous agents can be! 2. Tools, end users, and LLMs​ File: 2_tools_end_users_llms.py ↗ Key concepts​ Introducing more diverse tools. Supporting named end users. Separation of planning and execution. Code walkthrough​ Here's the task that will be execute by default: # Needs Tavily API keytask2 = ( \"Research the price of gold in the last 30 days, \" \"and send bob@portialabs.ai a report about it.\") In order to execute this task, three tools will be required. One tool will be needed to research the price of gold. In this example, the planning agent should choose the Tavily tool ↗. Tavily is a research API designed for agents. A tool to send an email. The planning agent should choose a Google Mail tool for this. An LLM (used as a tool!) to generate the email content that will be sent. Let's skip to near the end 🙂! The following code configures a Portia instance: # Insert other imports detailed abovefrom portia import open_source_tool_registryportia = Portia( config=my_config, tools=PortiaToolRegistry(my_config) + open_source_tool_registry, execution_hooks=CLIExecutionHooks(),) This is very similar to the previous example. The first thing to notice in this example is that two tool registries are being provided, the PortiaToolRegistry (which needs to be instantiated with configuration), and open_source_tool_registry which contains some extra open-source tools that are released as part of the Portia SDK. As seen above, you can combine multiple registries by adding them together, in the same way as you might combine two Python lists. (Sometimes tool registries are simply a list of Portia Tool objects.) Finally, let's look at the code that executes the task. It's slightly different from before: plan = portia.plan(task2)print(plan.pretty_print())plan_run = portia.run_plan(plan, end_user=\"its me, mario\") Note that this time, instead of calling portia.run to plan and execute in a single step, the code calls portia.plan, and then the plan (after being printed) is executed with run_plan. Separating out these steps is useful in the case when you would like to validate the plan before it's run, or even refine the plan before executing. Note, also, the end_user parameter that is passed to run_plan. You can also provide this variable to Portia's run method, if you are planning and executing in a single step. The end_user parameter, as a string, identifies the end-user driving the agent's actions. It should be a string that uniquely identifies a particular user, and will be used within the Portia cloud to look up any stored credentials. This means that if you called run_plan(end_user=\"end_user_123\"), and the user authenticated against the Google API, future runs of the agent will be authenticated and executed as that user. When providing an identifier like this, you should use a value that you can map back to a user session on your own system. (Don't use \"it's me, mario\"!) Here: A user is explicitly declared. The agent is equipped with tools that allow it to search the web and send emails. The instruction combines multiple actions: fetch data, generate a message, and send it. This example shows how Portia agents can become personalized assistants that combine tool outputs into LLM-generated messages. 3. Model Context Protocol (MCP)​ File: 3_mcp.py ↗ Key concepts​ Setting up an MCP tool registry. Configuring Portia to use an MCP tool registry. Viewing the final output of a run. Code walkthrough​ The third example introduces the Model Context Protocol (MCP) ↗. At the time of writing, MCP is all-the-rage among the cool kids! This is a protocol that allows agents to interact with remote tool registries. Many companies are now providing MCP services alongside their more traditional APIs. In some cases, including the example below, the MCP server is a local process that is run directly by the Python code. Portia supports MCP through the MCPToolRegistry class, which you'll see below. Here's the task that the example code will execute: task = \"Read the portialabs.ai website and tell me what they do\" In order to complete this task, a tool will be needed to fetch a web page. Fortunately, there's an MCP tool to do just that! The mcp-server-fetch ↗ tool is an MCP server that can be run as a local Python process. If you were executing it directly from the shell, you could download and run it by calling # Don't actually run this:uvx mcp-server-fetch UVX is provided as part of UV ↗ and will automatically download and run an executable Python package. It's also super-fast! We configured an MCPToolRegistry that will run this server with the following code: from portia import McpToolRegistryregistry = McpToolRegistry.from_stdio_connection( server_name=\"fetch\", command=\"uvx\", args=[\"mcp-server-fetch\"],) This will execute the underlying shell command, and return a ToolRegistry object that will allow Portia to call it. portia = Portia( config=my_config, tools=registry, execution_hooks=CLIExecutionHooks(),) If you were running this task as part of a larger application, your Python code would require access to the end-result of the agent's research. This can be found in the PlanRun.outputs.final_output attribute, as shown in the last line of code: print(portia.run(task).outputs.final_output) 4. Browser automation​ File: 4_browser_use.py ↗ Key concepts​ Use of local browser automation Use of Browserbase (remote browser-as-a-service) Extraction of real-world data from websites Code walkthrough​ This final example introduces browser-based automation, showing how Portia can automate interactions in real browsers – especially useful when no API is available. This is a particularly powerful feature when used with websites that require authentication. Portia is capable of opening a local browser session to allow the user to authenticate. After successful authentication, the new browser session details are sent to Browserbase, where they can then be used remotely to drive the browser, still authenticated as the local user. It's important to note that at no point are user credentials shared with Portia! As with the other examples, let start by looking at the task we wish the agent to complete: task = ( \"Find my connections called 'Bob' on LinkedIn (https://www.linkedin.com)\") This task doesn't just require the ability to fetch a web page, like the previous example did. Instead, it needs the user to log into LinkedIn, so that the agent can drive the browser as the logged-in user. from portia.open_source_tools.browser_tool import BrowserTool, BrowserInfrastructureOption# Change `infrastructure_option` to `BrowserInfrastructureOption.REMOTE` to use Browserbase# instead of local Chrome.browser_tool = BrowserTool( infrastructure_option=BrowserInfrastructureOption.LOCAL) The code above defines a local browser tool. If (as here), infrastructure_option, is set to BrowserInfrastructureOption.LOCAL, then the tool will run Chrome locally, with no remote browser component. If the argument is set to BrowserInfrastructureOption.REMOTE then it will use the remote Browserbase ↗ service. In production you'd want to use the Browserbase tool, but that does require a paid account. So for running this example locally, we recommend that you run using the local browser tool. portia = Portia( config=my_config, tools=[browser_tool],)plan_run = portia.run(task) Running this example​ When running this example, it's important to fully shut down any version of Chrome you have running. The local browser tool needs to start up Chrome with various debugging flags enabled, as these allow the LLM to drive the browser. Run the tool with: uv run 4_browser_use.py After the planning stage, you should see a browser start up. It should navigate to the LinkedIn log in page, and then pause, allowing you to log into your LinkedIn account. Once you have logged in, return to the command-line and follow the instructions to continue. The agent should then control the browser, identifying the search box at the top of the screen, and then using it to locate all your connections called \"Bob\". (If you don't have any connections called Bob, maybe change the task so that it looks up a name you know is in your LinkedIn connection list.) In this example: The agent is capable of using either local or remote browser automation. It allows the user to log into LinkedIn, navigates the interface, and extracts relevant connections. This highlights Portia's flexibility when building agents that must operate outside the bounds of standard APIs. Before moving on​ Check out the following video, showing this feature in action, with an even more complex and powerful use-case. Summary table​ Example FileFocusFeatures Introduced1_github_oauth.pyOAuth API useOAuth, basic agent commands2_tools_end_users_llms.pyMulti-tool agentEnd users, multi-step reasoning3_mcp.pyRunning MCP ToolsMCP format, structured execution4_browser_use.pyWeb automationBrowser automation, local & remote modes These examples form a practical foundation for building agents with Portia. Look out for tutorials that take these concepts even further, with some sample web applications, integrating with popular frameworks. We have more tutorials on our blog ↗, or check out our GitHub repository ↗.Before you start1. GitHub OAuth integrationKey conceptsConfiguring Portia with a .env fileCode walkthroughRunning the exampleBefore moving on2. Tools, end users, and LLMsKey conceptsCode walkthrough3. Model Context Protocol (MCP)Key conceptsCode walkthrough4. Browser automationKey conceptsCode walkthroughRunning this exampleBefore moving onSummary table",
      "timestamp": "2025-08-24 06:51:46"
    },
    {
      "url": "https://docs.portialabs.ai/run-portia-tools",
      "title": "Run Portia tools with authentication | Portia AI Docs",
      "content": "Run Portia tools with authentication | Portia AI Docs Skip to main contentOn this page Use clarifications to leverage Portia tools' native authentication support. TL;DR All Portia tools come with built-in authentication, typically using Portia OAuth clients for each relevant resource server. At the start of a plan run containing Portia tools, Portia raises ActionClarifications to request user authorization for the subset of tools that require it. Portia offers a cloud-hosted library of tools to save you development time. You can find the ever-growing list of Portia tools in the next section (Portia tool catalogue ↗). All Portia tools come with plug and play authentication. Let's delve into how to handle the user authentication flow. Handling auth with Clarification​ We established in the preceding section that clarifications are raised when an agent needs input to progress. This concept lends itself perfectly to tool authentication. Let's break it down: All Portia tools come with built-in authentication, typically using Portia OAuth clients for each relevant resource server. Portia provisions the required token with the relevant scope when a tool call needs to be made. Tokens provisioned by Portia have a user-configurable retention period (see more here ↗). The tokens are scoped to the end_user that was passed when running the plan or a default end_user if none was provided. You will need to reuse this end_user_id across plan runs to leverage token reusability (Manage multiple end users ↗). When a plan is run, before we start executing the steps, we first check the readiness of all tools contained in the steps of the plan. For Portia tools supporting OAuth, readiness includes validating that we have an access token stored for the end_user_id provided. If no OAuth token is found, an ActionClarification is raised with an OAuth link as the action URL. This OAuth link uses the relevant Portia authentication client and a Portia redirect URL. Portia's OAuth server listens for the authentication result and resolves the concerned clarification, allowing the plan run to resume again. infoNote that there may be multiple tools that require permissions from the same OAuth client. In this case, Portia will combine together the required scopes, reducing the number of ActionClarifications that need to be resolved. Optionally, you can configure a custom URL where users will be redirected after successful authentication. To do so, follow these steps: Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the custom URL in 'Org Settings'. Ensure that the URL begins with either https:// or http://. Bringing the concepts together​ Now let's bring this to life by reproducing the experience that you can see on the website's playground (↗). We want to be able to handle a prompt like Find the github repository of Mastodon and give it a star for me, so let's take a look at the code below. Portia API key requiredWe're assuming you already have a Portia API key from the dashboard and set it in your environment variables. If not please refer to the previous section and do that first (Set up your account ↗). main.pyfrom dotenv import load_dotenvfrom portia import ( ActionClarification, InputClarification, MultipleChoiceClarification, PlanRunState, Portia, PortiaToolRegistry, default_config,)load_dotenv()# Instantiate a Portia instance. Load it with the default config and with Portia cloud tools aboveportia = Portia(tools=PortiaToolRegistry(default_config()))# Generate the plan from the user query and print itplan = portia.plan('Find the github repository of PortiaAI and give it a star for me')print(f\"{plan.model_dump_json(indent=2)}\")# Run the planplan_run = portia.run_plan(plan)while plan_run.state == PlanRunState.NEED_CLARIFICATION: # If clarifications are needed, resolve them before resuming the plan run for clarification in plan_run.get_outstanding_clarifications(): # Usual handling of Input and Multiple Choice clarifications if isinstance(clarification, (InputClarification, MultipleChoiceClarification)): print(f\"{clarification.user_guidance}\") user_input = input(\"Please enter a value:\\n\" + ((\"\\n\".join(clarification.options) + \"\\n\") if \"options\" in clarification else \"\")) plan_run = portia.resolve_clarification(clarification, user_input, plan_run) # Handling of Action clarifications if isinstance(clarification, ActionClarification): print(f\"{clarification.user_guidance} -- Please click on the link below to proceed.\") print(clarification.action_url) plan_run = portia.wait_for_ready(plan_run) # Once clarifications are resolved, resume the plan run plan_run = portia.resume(plan_run)# Serialise into JSON and print the outputprint(f\"{plan_run.model_dump_json(indent=2)}\") Pay attention to the following points: We're importing all of Portia's cloud tool library using the PortiaToolRegistry import. Portia will (rightly!) identify that executing on this query necessitates both the SearchGitHubReposTool and the StarGitHubRepoTool in particular. Like all Portia cloud tools, our Github tools are built with plug and play authentication support. Before any steps are executed, Portia will raise an Action Clarification with a Github OAuth link as the action URL. We're now introducing the portia.wait_for_ready() method to handle clarifications of type ActionClarification. This method should be used when the resolution to a clarification relies on a third party system and your Portia instance needs to listen for a change in its state. In our example, Portia's OAuth server listens for the authentication result and resolves the concerned clarification, allowing the plan run to resume again. Your plan run will pause and you should see the link in the logs like so ... OAuth required -- Please click on the link below to proceed.https://github.com/login/oauth/authorize/?redirect_uri=https%3A%2F%2Fapi.portialabs.ai%2Fapi%2Fv0%2Foauth%2Fgithub%2F&client_id=Ov23liXuuhY9MOePgG8Q&scope=public_repo+starring&state=APP_NAME%3Dgithub%253A%253Agithub%26PLAN_RUN_ID%3Daa6019e1-0bde-4d76-935d-b1a64707c64e%26ORG_ID%3Dbfc2c945-4c8a-4a02-847a-1672942e8fc9%26CLARIFICATION_ID%3D9e6b8842-dc39-40be-a298-900383dd5e9e%26SCOPES%3Dpublic_repo%2Bstarring&response_type=code In your logs you should be able to see the tools, as well as a plan and final plan run state similar to the output below. Note again how the planner weaved tools from both the cloud and the example registry. Generated planPlan run in final stateplan-71fbe578-0c3f-4266-b5d7-933e8bb10ef2.json{ \"id\": \"plan-71fbe578-0c3f-4266-b5d7-933e8bb10ef2\", \"plan_context\": { \"query\": \"Find the github repository of PortiaAI and give it a star for me\", \"tool_ids\": [ \"portia::github::search_repos\", \"portia::github::star_repo\", \"portia::slack::send_message\", \"portia::zendesk::list_groups_for_user\", ... ] }, \"steps\": [ { \"task\": \"Search for the GitHub repository of PortiaAI\", \"inputs\": [], \"tool_id\": \"portia:github::search_repos\", \"output\": \"$portiaai_repository\" }, { \"task\": \"Star the GitHub repository of PortiaAI\", \"inputs\": [ { \"name\": \"$portiaai_repository\", \"description\": \"The GitHub repository of PortiaAI\" } ], \"tool_id\": \"portia:github::star_repo\", \"output\": \"$star_result\" } ]}prun-36945fae-1dcc-4b05-9bc4-4b862748e031.json{ \"id\": \"prun-36945fae-1dcc-4b05-9bc4-4b862748e031\", \"plan_id\": \"plan-71fbe578-0c3f-4266-b5d7-933e8bb10ef2\", \"current_step_index\": 1, \"state\": \"COMPLETE\", \"outputs\": { \"clarifications\": [ { \"uuid\": \"clar-f873b9be-10ee-4184-a717-3a7559416499\", \"category\": “Multiple Choice”, \"response\": “portiaAI/portia-sdk-python\", \"step\": 2, \"user_guidance\": \"Please select a repository.\", \"handled\": true, \"argument\": \"$portiaai_repository\", \"options\": \"[\\\"portiaAI/portia-sdk-python\\\", \\\"portiaAI/docs\\\", \\\"portiaAI/portia-agent-examples\\\"]\", } ], \"step_outputs\": { \"$portiaai_repository\": { \"value\": \"[\\\"portiaAI/portia-sdk-python\\\", \\\"portiaAI/docs\\\", \\\"portiaAI/portia-agent-examples\\\"]\", \"summary\": null }, \"$star_result\": { \"value\": \"Successfully starred the repository 'portiaAI/portia-sdk-python'.\", \"summary\": null } }, \"final_output\": { \"value\": \"Successfully starred the repository 'portiaAI/portia-sdk-python'.\", \"summary\": null } }} infoNow that you're familiar with running Portia tools, why not try your hand at the intro example in our examples repo (↗). In the example ee use the Google Calendar tools to schedule a meeting and handle the authentication process to execute those tool calls.Handling auth with ClarificationBringing the concepts together",
      "timestamp": "2025-08-24 06:51:49"
    },
    {
      "url": "https://docs.portialabs.ai/evals",
      "title": "📈 Evals | Portia AI Docs",
      "content": "📈 Evals | Portia AI Docs Skip to main content📄️ Overview and basic usageEvals are static, ground truth datasets designed to be run multiple times against your agents to assess their performance. These datasets are comprised of multiple test cases which are pairs of inputs (query or plan) and outputs (plan or plan run).📄️ Custom evaluatorsEvaluators are responsible for the calculation of metrics. To help you get started quickly, Steel Thread provides a multitude of built-in evaluators you can configure from the dashboard and then pass to your EvalRun via the DefaultEvaluator class. This explained in the previous section on basic usage.📄️ Tool stubbingWhen running evals, your agent may call tools like weatherlookup, search, or sendemail. If those tools hit live systems, you'll get non-deterministic results — which can make evaluation noisy and inconsistent. There's also of course undesirable real-world effects (e.g. emails sent) and cost to these tool calls when you're simply trying to run evals!📄️ Visualise Eval resultsResults from Evals are pushed to the Portia UI for visualization. This allows you to quickly see trends over time and to drill into why metrics may have changed. Clicking into a dataset will show you a summary of the current metrics for that dataset. Metrics are plotted by run.",
      "timestamp": "2025-08-24 06:51:52"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github/star-repo",
      "title": "GitHub - Repository: Star | Portia AI Docs",
      "content": "GitHub - Repository: Star | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:github::star_repo Tool description: Stars a GitHub repository. Args schema: { \"description\": \"Schema for the StarGitHubRepoTool input.\", \"properties\": { \"repo\": { \"description\": \"The repository to star in the form organization/repository.For example: PortiaAI/portia-sdk-python\", \"title\": \"Repo\", \"type\": \"string\" } }, \"required\": [ \"repo\" ], \"title\": \"StarGitHubRepoSchema\", \"type\": \"object\"} Output schema: ('str', 'A string indicating successful starring')UsageTool details",
      "timestamp": "2025-08-24 06:51:55"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/asana",
      "title": "Asana | Portia AI Docs",
      "content": "Asana | Portia AI Docs Skip to main contentOn this page Description​ Opens the Asana Work Graph to AI assistants, enabling task and project operations through an authenticated MCP interface.. Authorisation​ This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail here (↗). Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to authorise with the server via OAuth when you enable it. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:51:58"
    },
    {
      "url": "https://docs.portialabs.ai/evals-tool-stubbing",
      "title": "Tool stubbing | Portia AI Docs",
      "content": "Tool stubbing | Portia AI Docs Skip to main contentOn this page When running evals, your agent may call tools like weather_lookup, search, or send_email. If those tools hit live systems, you'll get non-deterministic results — which can make evaluation noisy and inconsistent. There's also of course undesirable real-world effects (e.g. emails sent) and cost to these tool calls when you're simply trying to run evals! To solve this, Steel Thread supports stubbing tools. This makes your tests: Deterministic — the same input always produces the same output Isolated — no external API calls or flaky systems Repeatable — easy to track regressions across changes When to stub​ Use tool stubs when: You're writing evals The tool response affects the plan or output You want consistent scoring across iterations How Tool stubbing works​ Steel Thread provides a ToolStubRegistry — a drop-in replacement for Portia’s default registry. You can wrap your existing tools and selectively override individual tools by ID. Tool stubs are simple Python functions and the ToolStubContext contains all the original tool's context to help you generate realistic stubs. Below is an example where we use use a tool stub for the open source weather_tool available in the Portia SDK. from portia import Portia, Config, DefaultToolRegistryfrom steelthread.steelthread import SteelThread, EvalConfigfrom steelthread.portia.tools import ToolStubRegistry, ToolStubContextfrom dotenv import load_dotenvload_dotenv(override=True)# Define stub behaviordef weather_stub_response( ctx: ToolStubContext,) -> str: \"\"\"Stub for weather tool to return deterministic weather.\"\"\" city = ctx.kwargs.get(\"city\", \"\").lower() if city == \"sydney\": return \"33.28\" if city == \"london\": return \"2.00\" return f\"Unknown city: {city}\"config = Config.from_default()# Run evals with stubs portia = Portia( config, tools=ToolStubRegistry( DefaultToolRegistry(config), stubs={ \"weather_tool\": weather_stub_response, }, ),)SteelThread().run_evals( portia, EvalConfig( eval_dataset_name=\"your-dataset-name-here\", config=config, iterations=5 ),) With the stubbed tool in place, your evals will be clean, fast, and reproducible. The rest of your tools still work as normal with only the stubbed one being overridden. Best Practices for tool stubbing Stub only the tools that matter for evaluation Use consistent return types (e.g. same as real tool) Use tool_call_index if you want per-run variance Combine stubbing with assertions to detect misuse (e.g. tool called too many times) When to stubHow Tool stubbing works",
      "timestamp": "2025-08-24 06:52:01"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/supabase",
      "title": "Supabase | Portia AI Docs",
      "content": "Supabase | Portia AI Docs Skip to main contentOn this page Description​ Connects directly to Supabase projects for managing databases, executing SQL queries, applying migrations, and handling configurations through natural language commands. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"supabase\", command=\"npx\", args=[ \"-y\", \"@supabase/mcp-server-supabase@latest\", \"--read-only\", \"--project-ref=<project_ref>\", ], env={\"SUPABASE_ACCESS_TOKEN\": \"<personal_access_token>\"},) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"supabase\", command=\"npx\", args=[ \"-y\", \"@supabase/mcp-server-supabase@latest\", \"--read-only\", \"--project-ref=<project_ref>\", ], env={\"SUPABASE_ACCESS_TOKEN\": \"<personal_access_token>\"},) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:52:04"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/apify",
      "title": "Apify Actors | Portia AI Docs",
      "content": "Apify Actors | Portia AI Docs Skip to main contentOn this page Description​ Use 4,000+ pre-built cloud tools, known as Actors, to extract data from websites, e-commerce, social media, search engines, maps, and more. Authorisation​ To use this MCP server, you need API credentials in your environment. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to provide your API key when you enable the server. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:52:07"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/config",
      "title": "portia.config | Portia AI Docs",
      "content": "portia.config | Portia AI Docs Skip to main contentOn this pageConfiguration module for the SDK. This module defines the configuration classes and enumerations used in the SDK, including settings for storage, API keys, LLM providers, logging, and agent options. It also provides validation for configuration values and loading mechanisms for default settings. StorageClass Objects​ class StorageClass(Enum) Enum representing locations plans and runs are stored. Attributes: MEMORY - Stored in memory. DISK - Stored on disk. CLOUD - Stored in the cloud. Model Objects​ class Model(NamedTuple) Provider and model name tuple. DEPRECATED Use new model configuration options on Config class instead. Attributes: provider - The provider of the model. model_name - The name of the model in the provider's API. LLMModel Objects​ class LLMModel(Enum) Enum for supported LLM models. DEPRECATED Use new model configuration options on Config class instead. Models are grouped by provider, with the following providers: OpenAI Anthropic MistralAI Google Generative AI Azure OpenAI Attributes: GPT_4_O - GPT-4 model by OpenAI. GPT_4_O_MINI - Mini GPT-4 model by OpenAI. GPT_3_5_TURBO - GPT-3.5 Turbo model by OpenAI. CLAUDE_3_5_SONNET - Claude 3.5 Sonnet model by Anthropic. CLAUDE_3_5_HAIKU - Claude 3.5 Haiku model by Anthropic. CLAUDE_3_OPUS - Claude 3.0 Opus model by Anthropic. CLAUDE_3_7_SONNET - Claude 3.7 Sonnet model by Anthropic. MISTRAL_LARGE - Mistral Large Latest model by MistralAI. GEMINI_2_0_FLASH - Gemini 2.0 Flash model by Google Generative AI. GEMINI_2_0_FLASH_LITE - Gemini 2.0 Flash Lite model by Google Generative AI. GPT_4_O_MINI0 - Gemini 1.5 Flash model by Google Generative AI. GPT_4_O_MINI1 - GPT-4 model by Azure OpenAI. GPT_4_O_MINI2 - Mini GPT-4 model by Azure OpenAI. GPT_4_O_MINI3 - O3 Mini model by Azure OpenAI. Can be instantiated from a string with the following format: provider/model_name [e.g. LLMModel(\"openai/gpt-4o\")] model_name [e.g. LLMModel(\"gpt-4o\")] In the cases where the model name is not unique across providers, the earlier values in the enum definition will take precedence. _missing_​ @classmethoddef _missing_(cls, value: object) -> LLMModel Get the LLM model from the model name. api_name​ @propertydef api_name() -> str Override the default value to return the model name. provider​ def provider() -> LLMProvider Get the associated provider for the model. Returns: LLMProvider - The provider associated with the model. to_model_string​ def to_model_string() -> str Get the model string for the model. Returns: str - The model string. _AllModelsSupportedWithDeprecation Objects​ class _AllModelsSupportedWithDeprecation(Container) A type that returns True for any contains check. __contains__​ def __contains__(item: object) -> bool Check if the item is in the container. ExecutionAgentType Objects​ class ExecutionAgentType(Enum) Enum for types of agents used for executing a step. Attributes: ONE_SHOT - The one-shot agent. DEFAULT - The default agent. PlanningAgentType Objects​ class PlanningAgentType(Enum) Enum for planning agents used for planning queries. Attributes: DEFAULT - The default planning agent. LogLevel Objects​ class LogLevel(Enum) Enum for available log levels. Attributes: DEBUG - Debug log level. INFO - Info log level. WARNING - Warning log level. ERROR - Error log level. CRITICAL - Critical log level. parse_str_to_enum​ def parse_str_to_enum(value: str | E, enum_type: type[E]) -> E Parse a string to an enum or return the enum as is. Arguments: value str | E - The value to parse. enum_type type[E] - The enum type to parse the value into. Raises: InvalidConfigError - If the value cannot be parsed into the enum. Returns: E - The corresponding enum value. GenerativeModelsConfig Objects​ class GenerativeModelsConfig(BaseModel) Configuration for a Generative Models. These models do not all need to be specified manually. If an LLM provider is configured, Portia will use default models that are selected for the particular use-case. Attributes: default_model - The default generative model to use. This model is used as the fallback model if no other model is specified. It is also used by default in the Portia SDK tool that require an LLM. planning_model - The model to use for the PlanningAgent. Reasoning models are a good choice here, as they are able to reason about the problem and the possible solutions. If not specified, the default_model will be used. execution_model - The model to use for the ExecutionAgent. This model is used for the distilling context from the plan run into tool calls. If not specified, the default_model will be used. introspection_model - The model to use for the IntrospectionAgent. This model is used to introspect the problem and the plan. If not specified, the default_model will be used. summarizer_model - The model to use for the SummarizerAgent. This model is used to summarize output from the plan run. If not specified, the default_model will be used. parse_models​ @model_validator(mode=\"before\")@classmethoddef parse_models(cls, data: dict[str, Any]) -> dict[str, Any] Convert legacy LLMModel values to str with deprecation warning. Config Objects​ class Config(BaseModel) General configuration for the SDK. This class holds the configuration for the SDK, including API keys, LLM settings, logging options, and storage settings. It also provides validation for configuration consistency and offers methods for loading configuration from files or default values. Attributes: portia_api_endpoint - The endpoint for the Portia API. portia_api_key - The API key for Portia. openai_api_key - The API key for OpenAI. anthropic_api_key - The API key for Anthropic. mistralai_api_key - The API key for MistralAI. google_api_key - The API key for Google Generative AI. aws_access_key_id - The AWS access key ID. aws_secret_access_key - The AWS secret access key. aws_default_region - The AWS default region. aws_credentials_profile_name - The AWS credentials profile name. portia_api_key0 - The API key for Azure OpenAI. portia_api_key1 - The endpoint for Azure OpenAI. portia_api_key2 - The LLM provider. If set, Portia uses this to select the best models for each agent. Can be None if custom models are provided. portia_api_key3 - A configuration for the LLM models for Portia to use. portia_api_key4 - The storage class used (e.g., MEMORY, DISK, CLOUD). portia_api_key5 - The directory for storage, if applicable. portia_api_key6 - The default log level (e.g., DEBUG, INFO). portia_api_key7 - The default destination for logs (e.g., sys.stdout). portia_api_key8 - Whether to serialize logs in JSON format. portia_api_key9 - The planning agent type. openai_api_key0 - The execution agent type. openai_api_key1 - A dictionary of feature flags for the SDK. openai_api_key2 - Whether to enable clarifications for the execution agent. parse_feature_flags​ @model_validator(mode=\"after\")def parse_feature_flags() -> Self Add feature flags if not provided. setup_cache​ @model_validator(mode=\"after\")def setup_cache() -> Self Set up LLM cache if Redis URL is provided. parse_storage_class​ @field_validator(\"storage_class\", mode=\"before\")@classmethoddef parse_storage_class(cls, value: str | StorageClass) -> StorageClass Parse storage class to enum if string provided. parse_default_log_level​ @field_validator(\"default_log_level\", mode=\"before\")@classmethoddef parse_default_log_level(cls, value: str | LogLevel) -> LogLevel Parse default_log_level to enum if string provided. parse_execution_agent_type​ @field_validator(\"execution_agent_type\", mode=\"before\")@classmethoddef parse_execution_agent_type( cls, value: str | ExecutionAgentType) -> ExecutionAgentType Parse execution_agent_type to enum if string provided. parse_planning_agent_type​ @field_validator(\"planning_agent_type\", mode=\"before\")@classmethoddef parse_planning_agent_type( cls, value: str | PlanningAgentType) -> PlanningAgentType Parse planning_agent_type to enum if string provided. exceeds_output_threshold​ def exceeds_output_threshold(value: str | list[str | dict]) -> bool Determine whether the provided output value exceeds the large output threshold. get_agent_default_model​ def get_agent_default_model( agent_key: str, llm_provider: LLMProvider | None = None) -> GenerativeModel | str | None Get the default model for the given agent key. fill_default_models​ @model_validator(mode=\"after\")def fill_default_models() -> Self Fill in default models for the LLM provider if not provided. check_config​ @model_validator(mode=\"after\")def check_config() -> Self Validate Config is consistent. from_default​ @classmethoddef from_default(cls, **kwargs) -> Config Create a Config instance with default values, allowing overrides. Returns: Config - The default config has_api_key​ def has_api_key(name: str) -> bool Check if the given API Key is available. must_get_api_key​ def must_get_api_key(name: str) -> SecretStr Retrieve the required API key for the configured provider. Raises: ConfigNotFoundError - If no API key is found for the provider. Returns: SecretStr - The required API key. must_get​ def must_get(name: str, expected_type: type[T]) -> T Retrieve any value from the config, ensuring its of the correct type. Arguments: name str - The name of the config record. expected_type type[T] - The expected type of the value. Raises: ConfigNotFoundError - If no API key is found for the provider. InvalidConfigError - If the config isn't valid Returns: T - The config value get_default_model​ def get_default_model() -> GenerativeModel Get or build the default model from the config. The default model will always be present. It is a general purpose model that is used for the SDK's LLM-based Tools, such as the ImageUnderstandingTool and the LLMTool. Additionally, unless specified all other specific agent models will default to this model. get_planning_model​ def get_planning_model() -> GenerativeModel Get or build the planning model from the config. See the GenerativeModelsConfig class for more information get_execution_model​ def get_execution_model() -> GenerativeModel Get or build the execution model from the config. See the GenerativeModelsConfig class for more information get_introspection_model​ def get_introspection_model() -> GenerativeModel Get or build the introspection model from the config. See the GenerativeModelsConfig class for more information get_summarizer_model​ def get_summarizer_model() -> GenerativeModel Get or build the summarizer model from the config. See the GenerativeModelsConfig class for more information get_generative_model​ def get_generative_model( model: str | GenerativeModel | None) -> GenerativeModel | None Get a GenerativeModel instance. Arguments: model str | GenerativeModel | None - The model to get, either specified as a string in the form of \"provider/model_name\", or as a GenerativeModel instance. Also accepts None, in which case None is returned. Returns: GenerativeModel | None: The model instance or None. llm_provider_default_from_api_keys​ def llm_provider_default_from_api_keys(**kwargs) -> LLMProvider | None Get the default LLM provider from the API keys. Returns: LLMProvider - The default LLM provider. None - If no API key is found. default_config​ def default_config(**kwargs) -> Config Return default config with values that can be overridden. Returns: Config - The default config StorageClass ObjectsModel ObjectsLLMModel Objects_AllModelsSupportedWithDeprecation ObjectsExecutionAgentType ObjectsPlanningAgentType ObjectsLogLevel ObjectsGenerativeModelsConfig ObjectsConfig Objects",
      "timestamp": "2025-08-24 06:52:10"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github/",
      "title": "GitHub Tools | Portia AI Docs",
      "content": "GitHub Tools | Portia AI Docs Skip to main content Issue: ListList issues in a GitHub repository. Repository: ListLists all public repositories for a GitHub organization. Repository: SearchSearches all public repositories for a specific term. Repository: StarStars a GitHub repository.",
      "timestamp": "2025-08-24 06:52:13"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/crawl",
      "title": "Open Source - Crawl | Portia AI Docs",
      "content": "Open Source - Crawl | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: crawl_tool Tool description: Crawls websites using graph-based website traversal tool that can explore hundreds of paths in parallel with built-in extraction and intelligent discovery. Provide a starting URL and optional instructions for what to find, and the tool will navigate and extract relevant content from multiple pages. Supports depth control, domain filtering, and path selection for comprehensive site exploration. Usage notes: This tool uses the Tavily API. You can sign up to obtain a Tavily API key (↗) and set it in the environment variable TAVILY_API_KEY. Args schema: { \"description\": \"Input for CrawlTool.\", \"properties\": { \"url\": { \"description\": \"The root URL to begin the crawl (e.g., 'https://docs.tavily.com')\", \"title\": \"Url\", \"type\": \"string\" }, \"instructions\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Natural language instructions for the crawler (e.g., 'Find all pages on the Python SDK')\", \"title\": \"Instructions\" }, \"max_depth\": { \"default\": 1, \"description\": \"Max depth of the crawl. Defines how far from the base URL the crawler can explore\", \"maximum\": 5, \"minimum\": 1, \"title\": \"Max Depth\", \"type\": \"integer\" }, \"max_breadth\": { \"default\": 20, \"description\": \"Max number of links to follow per level of the tree (i.e., per page)\", \"maximum\": 100, \"minimum\": 1, \"title\": \"Max Breadth\", \"type\": \"integer\" }, \"limit\": { \"default\": 50, \"description\": \"Total number of links the crawler will process before stopping\", \"maximum\": 500, \"minimum\": 1, \"title\": \"Limit\", \"type\": \"integer\" }, \"select_paths\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Regex patterns to select only URLs with specific path patterns (e.g., ['/docs/.*', '/api/v1.*'])\", \"title\": \"Select Paths\" }, \"select_domains\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Regex patterns to select crawling to specific domains or subdomains (e.g., ['^docs\\\\.example\\\\.com$'])\", \"title\": \"Select Domains\" }, \"exclude_paths\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Regex patterns to exclude URLs with specific path patterns (e.g., ['/private/.*', '/admin/.*'])\", \"title\": \"Exclude Paths\" }, \"exclude_domains\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Regex patterns to exclude specific domains or subdomains from crawling (e.g., ['^private\\\\.example\\\\.com$'])\", \"title\": \"Exclude Domains\" }, \"allow_external\": { \"default\": false, \"description\": \"Whether to allow following links that go to external domains\", \"title\": \"Allow External\", \"type\": \"boolean\" } }, \"required\": [ \"url\" ], \"title\": \"CrawlToolSchema\", \"type\": \"object\"} Output schema: ('str', 'str: crawled content and discovered pages')UsageTool details",
      "timestamp": "2025-08-24 06:52:16"
    },
    {
      "url": "https://docs.portialabs.ai/agent-memory",
      "title": "Using agent memory | Portia AI Docs",
      "content": "Using agent memory | Portia AI Docs Skip to main contentOn this page With Portia, agents can leverage memory by default. This allows them to work efficiently when large pieces of data are produced / processed during plans, avoiding latency, cost and performance issues caused when language model context windows fill up. When a step of a plan produces a large output, for example if a large document is read or downloaded, agents in Portia will automatically store this output in agent memory. In their plan run state, they also maintain a reference to this output. Then, if the large output is needed by future steps when running the plan, the value will be pulled in from agent memory as needed. Agent memories are scoped to a particular run of a plan and persist when a plan is paused to handle a clarification and later resumed. If you are running with Portia cloud storage, you can view the values your agents have stored in agent memory by navigating to the Agent Memory page ↗. Configuring agent memory​ Agent memory uses the storage class that you have configured for your Portia client. This means you can store memories locally, in the Portia cloud or on disk. For more details on the available storage classes, see our storage options section ↗. You can also configure the size threshold at which step outputs are written to agent memory using the large_output_threshold_tokens config value: portia = Portia(Config.from_default(large_output_threshold_tokens=10000)) Step outputs longer than this threshold are automatically written to agent memory. This threshold is expressed in tokens, which is a unit of text processed by a language model. They can be thought of as being roughly equivalent to words, but with some words taking several tokens. For more details, see this explainer on language model tokens ↗.Configuring agent memory",
      "timestamp": "2025-08-24 06:52:19"
    },
    {
      "url": "https://docs.portialabs.ai/streams-custom-evaluators",
      "title": "Custom Stream evaluators | Portia AI Docs",
      "content": "Custom Stream evaluators | Portia AI Docs Skip to main content Evaluators are responsible for the calculation of metrics. To help you get started quickly, Steel Thread provides a built-in LLMJudgeEvaluator for stream based evaluation using LLM-as-Judge. This explained in the previous section on basic usage. You can add your own custom Stream evaluators, be it LLM-as-Judge or deterministic ones. StreamEvaluator can implement two methods: from steelthread.streams import PlanStreamItem, PlanRunStreamItem, StreamMetric,class MyStreamEvaluator(StreamEvaluator): def process_plan(self, stream_item: PlanStreamItem) -> list[StreamMetric] | StreamMetric: ... def process_plan_run(self, stream_item: PlanRunStreamItem) -> list[StreamMetric] | StreamMetric | None: ... Below are two examples of custom evaluators, both using LLM-as-Judge or deterministic LLM-as-judgeDeterministicYou can use an LLM to score plan runs automatically. When you subclass StreamEvaluator, you first initialise your LLMScorer and then define how you want to process plans / plan runs with this evaluator.from portia import Configfrom steelthread.steelthread import SteelThreadfrom steelthread.streams import ( StreamConfig, PlanRunStreamItem, StreamEvaluator, StreamMetric)from steelthread.utils.llm import LLMScorer, MetricOnlyclass LLMVerbosityJudge(StreamEvaluator): def __init__(self, config): self.scorer = LLMScorer(config) def process_plan_run(self, stream_item: PlanRunStreamItem): # The stream_item object holds the underlying plan / plan run being evaluated. task_data = stream_item.plan_run.model_dump_json() # The description is used to inform the LLM on how to score the metric. metrics = self.scorer.score( task_data=[task_data], metrics_to_score=[ MetricOnly( name=\"verbosity\", description=\"Scores 0 if the answer is too verbose. 0 otherwise.\"), ], ) return [ StreamMetric.from_stream_item( stream_item=stream_item, score=m.score, name=m.name, description=m.description, explanation=m.explanation, ) for m in metrics ]# Setup config + Steel Threadconfig = Config.from_default()# To use your evaluator, pass it to the runnerSteelThread().process_stream( StreamConfig( eval_dataset_name=\"your-stream-name-here\", config=config, evaluators=[LLMVerbosityJudge(config)], ),)You can score plan runs using your own code by subclassing StreamEvaluator and writing your own implementation of process_plan or process_plan_run.from portia import Configfrom steelthread.steelthread import ( SteelThread,)from steelthread.streams import ( StreamConfig, PlanRunStreamItem, StreamEvaluator, StreamMetric)from dotenv import load_dotenvload_dotenv(override=True)class JudgeDread(StreamEvaluator): def process_plan_run(self, stream_item: PlanRunStreamItem): # The stream_item object holds the underlying plan / plan run being evaluated. # In this example we're just returning a static score and explanation. return StreamMetric.from_stream_item( stream_item=stream_item, name=\"dread_score\", score=1, description=\"Dreadful stuff\", explanation=\"The dread was palpable\", )# Setup config + Steel Threadconfig = Config.from_default()# Process streamSteelThread().process_stream( StreamConfig( stream_name=\"your-stream-name-here\", config=config, evaluators=[JudgeDread(config)]))",
      "timestamp": "2025-08-24 06:52:22"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-groups",
      "title": "Zendesk - Groups: Search | Portia AI Docs",
      "content": "Zendesk - Groups: Search | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:groups:search Tool description: Search for groups in Zendesk. It can be a natural language query or use the syntax of the Zendesk API. Args schema: { \"description\": \"Input schema for ZendeskSearchGroupsTool.\", \"properties\": { \"query\": { \"description\": \"The query to search for to find groups. It can be a natural language query term or use the syntax of the Zendesk API. Groups support the following keyword fields in Zendesk syntax: `name`, `created`. e.g. 'name:Support' or 'support'.\", \"title\": \"Query\", \"type\": \"string\" } }, \"required\": [ \"query\" ], \"title\": \"ZendeskSearchGroupsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:52:25"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/hyperbrowser",
      "title": "Hyperbrowser | Portia AI Docs",
      "content": "Hyperbrowser | Portia AI Docs Skip to main contentOn this page Description​ Enables web browsing capabilities through tools for content extraction, link following, and browser automation with customizable parameters for scraping, data collection, and web crawling tasks. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"hyperbrowser\", command=\"npx\", args=[ \"-y\", \"hyperbrowser-mcp\", ], env={\"HYPERBROWSER_API_KEY\": \"<api_key>\"},) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"hyperbrowser\", command=\"npx\", args=[ \"-y\", \"hyperbrowser-mcp\", ], env={\"HYPERBROWSER_API_KEY\": \"<api_key>\"},) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:52:28"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/article-search",
      "title": "Zendesk - Articles: Search | Portia AI Docs",
      "content": "Zendesk - Articles: Search | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:help_center:search_articles Tool description: Returns up to 25 articles relevant to the search query, which must be provided. Args schema: { \"description\": \"Input schema for ZendeskArticleSearchTool.\", \"properties\": { \"query\": { \"description\": \"The search text to be matched or a search string. Examples: \\\"carrot potato\\\", \\\"'carrot potato'\\\".\", \"title\": \"Query\", \"type\": \"string\" }, \"category\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Limit the search to this category id.\", \"title\": \"Category\" }, \"section\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Limit the search to this section id.\", \"title\": \"Section\" }, \"label_names\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"A comma-separated list of label names.\", \"title\": \"Label Names\" }, \"locale\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Search for articles in the specified locale (e.g. en-us). \", \"title\": \"Locale\" }, \"multibrand\": { \"anyOf\": [ { \"type\": \"boolean\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Enable search across all brands if true. Defaults to false if omitted.\", \"title\": \"Multibrand\" }, \"brand_id\": { \"anyOf\": [ { \"type\": \"integer\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Search for articles in the specified brand.\", \"title\": \"Brand Id\" }, \"created_before\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Limit the search to articles created before a given date (format YYYY-MM-DD).\", \"title\": \"Created Before\" }, \"created_after\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Limit the search to articles created after a given date (format YYYY-MM-DD).\", \"title\": \"Created After\" }, \"created_at\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Limit the search to articles created on a given date (format YYYY-MM-DD).\", \"title\": \"Created At\" }, \"updated_before\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Limit the search to articles updated before a given date (format YYYY-MM-DD). \", \"title\": \"Updated Before\" }, \"updated_after\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Limit the search to articles updated after a given date (format YYYY-MM-DD). \", \"title\": \"Updated After\" }, \"updated_at\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Limit the search to articles updated on a given date (format YYYY-MM-DD). \", \"title\": \"Updated At\" }, \"sort_by\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"One of created_at or updated_at. Defaults to sorting by relevance\", \"title\": \"Sort By\" }, \"sort_order\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"One of asc or desc. Defaults to desc\", \"title\": \"Sort Order\" } }, \"required\": [ \"query\" ], \"title\": \"ZendeskArticleSearchToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:52:31"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-sheets/sheets-get-spreadsheet",
      "title": "Google Sheets - Sheets: Get Spreadsheet | Portia AI Docs",
      "content": "Google Sheets - Sheets: Get Spreadsheet | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:sheets:get_spreadsheet Tool description: Gets the content of a spreadsheet from Google Sheets by ID. The GoogleDriveSearchTool should be used to search for a spreadsheet by name if an ID is not known. Args schema: { \"description\": \"Schema for the Google Sheets Get Spreadsheet tool.\", \"properties\": { \"spreadsheet_id\": { \"description\": \"The ID of the spreadsheet to get.\", \"title\": \"Spreadsheet Id\", \"type\": \"string\" } }, \"required\": [ \"spreadsheet_id\" ], \"title\": \"GoogleSheetsGetSpreadsheetToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict[str, list[dict[str, str]]]: Content of the spreadsheet.This is a structured response with a hierarchy including sheet names and its content in dict format.')UsageTool details",
      "timestamp": "2025-08-24 06:52:34"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/planning_agents/default_planning_agent",
      "title": "portia.planning_agents.default_planning_agent | Portia AI Docs",
      "content": "portia.planning_agents.default_planning_agent | Portia AI Docs Skip to main contentOn this pageDefaultPlanningAgent is a single best effort attempt at planning based on the given query + tools. DefaultPlanningAgent Objects​ class DefaultPlanningAgent(BasePlanningAgent) DefaultPlanningAgent class. __init__​ def __init__(config: Config, planning_prompt: str | None = None, retries: int = 3) -> None Init with the config. generate_steps_or_error​ def generate_steps_or_error( query: str, tool_list: list[Tool], end_user: EndUser, examples: list[Plan] | None = None, plan_inputs: list[PlanInput] | None = None) -> StepsOrError Generate a plan or error using an LLM from a query and a list of tools. agenerate_steps_or_error​ async def agenerate_steps_or_error( query: str, tool_list: list[Tool], end_user: EndUser, examples: list[Plan] | None = None, plan_inputs: list[PlanInput] | None = None) -> StepsOrError Generate a plan or error using an LLM from a query and a list of tools.DefaultPlanningAgent Objects",
      "timestamp": "2025-08-24 06:52:37"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/default_execution_agent",
      "title": "portia.execution_agents.default_execution_agent | Portia AI Docs",
      "content": "portia.execution_agents.default_execution_agent | Portia AI Docs Skip to main contentOn this pageThe Default execution agent for hardest problems. This agent uses multiple models (verifier, parser etc) to achieve the highest accuracy in completing tasks. ExecutionState Objects​ class ExecutionState(MessagesState) State for the execution agent. ToolArgument Objects​ class ToolArgument(BaseModel) Represents an argument for a tool as extracted from the goal and context. Attributes: name str - The name of the argument, as requested by the tool. explanation str - Explanation of the source for the value of the argument. value Any | None - The value of the argument, as provided in the goal or context. valid bool - Whether the value is a valid type and/or format for the given argument. ToolInputs Objects​ class ToolInputs(BaseModel) Represents the inputs for a tool. Attributes: args list[ToolArgument] - Arguments for the tool. VerifiedToolArgument Objects​ class VerifiedToolArgument(BaseModel) Represents an argument for a tool after being verified by an agent. Attributes: name str - The name of the argument, as requested by the tool. value Any | None - The value of the argument, as provided in the goal or context. made_up bool - Whether the value was made up or not. Should be false if the value was provided by the user. VerifiedToolInputs Objects​ class VerifiedToolInputs(BaseModel) Represents the inputs for a tool after being verified by an agent. Attributes: args list[VerifiedToolArgument] - Arguments for the tool. ParserModel Objects​ class ParserModel() Model to parse the arguments for a tool. Arguments: model Model - The language model used for argument parsing. context str - The context for argument generation. agent DefaultExecutionAgent - The agent using the parser model. Attributes: arg_parser_prompt ChatPromptTemplate - The prompt template for argument parsing. model Model - The language model used. context str - The context for argument generation. agent DefaultExecutionAgent - The agent using the parser model. previous_errors list[str] - A list of previous errors encountered during parsing. retries int - The number of retries attempted for parsing. __init__​ def __init__(model: GenerativeModel, agent: DefaultExecutionAgent, tool_context: ToolRunContext) -> None Initialize the model. Arguments: model Model - The language model used for argument parsing. agent DefaultExecutionAgent - The agent using the parser model. tool_context ToolRunContext - The context for the tool. invoke​ def invoke(state: ExecutionState) -> dict[str, Any] Invoke the model with the given message state. Arguments: state ExecutionState - The current state of the conversation. Returns: dict[str, Any]: The response after invoking the model. Raises: InvalidRunStateError - If the agent's tool is not available. VerifierModel Objects​ class VerifierModel() A model to verify the arguments for a tool. This model ensures that the arguments passed to a tool are valid, determining whether they are \"made up\" or not based on the context and specific rules. The verification process uses an LLM to analyze the context and tool arguments and returns a structured validation output. Attributes: arg_verifier_prompt ChatPromptTemplate - The prompt template used for arg verification. model Model - The model used to invoke the verification process. agent DefaultExecutionAgent - The agent responsible for handling the verification process. __init__​ def __init__(model: GenerativeModel, agent: DefaultExecutionAgent, tool_context: ToolRunContext) -> None Initialize the model. Arguments: model Model - The model used for argument verification. context str - The context for argument generation. agent DefaultExecutionAgent - The agent using the verifier model. tool_context ToolRunContext - The context for the tool. invoke​ def invoke(state: ExecutionState) -> dict[str, Any] Invoke the model with the given message state. Arguments: state ExecutionState - The current state of the conversation. Returns: dict[str, Any]: The response after invoking the model. Raises: InvalidRunStateError - If the agent's tool is not available. ToolCallingModel Objects​ class ToolCallingModel() Model to call the tool with the verified arguments. __init__​ def __init__(model: GenerativeModel, tools: list[StructuredTool], agent: DefaultExecutionAgent) -> None Initialize the model. Arguments: model GenerativeModel - The language model used for argument parsing. agent DefaultExecutionAgent - The agent using the parser model. tools list[StructuredTool] - The tools to pass to the model. invoke​ def invoke(state: ExecutionState) -> dict[str, Any] Invoke the model with the given message state. Arguments: state ExecutionState - The current state of the conversation. Returns: dict[str, Any]: The response after invoking the model. Raises: InvalidRunStateError - If the agent's tool is not available. DefaultExecutionAgent Objects​ class DefaultExecutionAgent(BaseExecutionAgent) Agent responsible for achieving a task by using verification. This agent does the following things: It uses an LLM to make sure that we have the right arguments for the tool, with explanations of the values and where they come from. It uses an LLM to make sure that the arguments are correct, and that they are labeled as provided, inferred or assumed. If any of the arguments are assumed, it will request a clarification. If the arguments are correct, it will call the tool and return the result to the user. If the tool fails, it will try again at least 3 times. Also, if the agent is being called a second time, it will just jump to step 4. Possible improvements: This approach (as well as the other agents) could be improved for arguments that are lists __init__​ def __init__(plan: Plan, plan_run: PlanRun, config: Config, agent_memory: AgentMemory, end_user: EndUser, tool: Tool | None = None, execution_hooks: ExecutionHooks | None = None) -> None Initialize the agent. Arguments: plan Plan - The plan containing the steps. plan_run PlanRun - The run that defines the task execution process. config Config - The configuration settings for the agent. agent_memory AgentMemory - The agent memory to be used for the task. end_user EndUser - The end user for this execution tool Tool | None - The tool to be used for the task (optional). execution_hooks ExecutionHooks | None - The execution hooks for the agent. clarifications_or_continue​ def clarifications_or_continue( state: ExecutionState) -> Literal[AgentNode.TOOL_AGENT, END] Determine if we should continue with the tool call or request clarifications instead. Arguments: state ExecutionState - The current state of the conversation. Returns: Literal[AgentNode.TOOL_AGENT, END]: The next node we should route to. get_last_resolved_clarification​ def get_last_resolved_clarification(arg_name: str) -> Clarification | None Return the last argument clarification that matches the given arg_name. Arguments: arg_name str - The name of the argument to match clarifications for Returns: Clarification | None: The matched clarification execute_sync​ def execute_sync() -> Output Run the core execution logic of the task. This method will invoke the tool with arguments that are parsed and verified first. Returns: Output - The result of the agent's execution, containing the tool call result. ExecutionState ObjectsToolArgument ObjectsToolInputs ObjectsVerifiedToolArgument ObjectsVerifiedToolInputs ObjectsParserModel ObjectsVerifierModel ObjectsToolCallingModel ObjectsDefaultExecutionAgent Objects",
      "timestamp": "2025-08-24 06:52:40"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/stripe",
      "title": "Stripe | Portia AI Docs",
      "content": "Stripe | Portia AI Docs Skip to main contentOn this page Description​ Integrates with Stripe's API to enable payment processing, customer management, and financial operations for e-commerce and billing workflows. Authorisation​ To use this MCP server, you need API credentials in your environment. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to provide your API key when you enable the server. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:52:43"
    },
    {
      "url": "https://docs.portialabs.ai/add-custom-tools",
      "title": "Add custom tools | Portia AI Docs",
      "content": "Add custom tools | Portia AI Docs Skip to main contentOn this page Let's build two custom tools that allow an LLM to write / read content to / from a local file. We'll start building the tool using the @tool decorator, which provides a simple and straightforward way to create custom tools from Python functions. Using the @tool decorator​ The @tool decorator converts your functions into Portia tools. Let's create our custom tools in a separate folder called custom_tools at the root of the project directory: file_reader_tool.pyfile_writer_tool.pycustom_tools/file_reader_tool.pyfrom pathlib import Pathimport pandas as pdimport jsonfrom typing import Annotatedfrom portia import tool@tooldef file_reader_tool( filename: Annotated[str, \"The location where the file should be read from\"]) -> str | dict: \"\"\"Finds and reads content from a local file on Disk.\"\"\" file_path = Path(filename) suffix = file_path.suffix.lower() if file_path.is_file(): if suffix == '.csv': return pd.read_csv(file_path).to_string() elif suffix == '.json': with file_path.open('r', encoding='utf-8') as json_file: data = json.load(json_file) return data elif suffix in ['.xls', '.xlsx']: return pd.read_excel(file_path).to_string() elif suffix in ['.txt', '.log']: return file_path.read_text(encoding=\"utf-8\")custom_tools/file_writer_tool.pyfrom pathlib import Pathfrom typing import Annotatedfrom portia import tool@tooldef file_writer_tool( filename: Annotated[str, \"The location where the file should be saved\"], content: Annotated[str, \"The content to write to the file\"]) -> str: \"\"\"Writes content to a file.\"\"\" filepath = Path(filename) if filepath.is_file(): with open(filepath, \"w\") as file: file.write(content) else: with open(filepath, \"x\") as file: file.write(content) return f\"Content written to {filename}\" The file reader tool expects a filename argument, which includes the file path and specifies the file to be read, and then returns the contents of the file as an output. The file writer tool expects the content to be written alongside the filename tool and then returns a string summarising the successful action. If a file already exists at the specified location its content will be overwritten. In general, a custom tool can return any type that can be safely serialised to a string, though we suggest basic data types (e.g. str, int, float, bool), collections of these types (e.g. list, set, dict) or Pydantic models as they are easier to work with. On the local file toolsIf those tools look familiar it's because we actually offer them in our open source repo ready-made. We just wanted to walk you through building your own local version from scratch (Open source tools in our SDK repo ↗). We will save adding clarifications to the next section though. Manage tool registries​ Let's group our custom tools into a registry so we can import it into code afterwards. Let's create a registry.py file in the custom_tools directory and declare our registry as follow: custom_tools/registry.py\"\"\"Registry containing my custom tools.\"\"\"from portia import ToolRegistrymy_tool_registry = ToolRegistry([ file_reader_tool(), file_writer_tool(),]) Here we are loading our freshly minted local tools into a tool registry called my_tool_registry represented by the ToolRegistry class. This takes a list of instantiated tool functions as a parameter. Bringing it together in an example​ Now let's bring it all together. We can combine any number of tool registries into a single one with the + operator. This can just as well be done to combine local and Portia tools together in one fell swoop! For this example, we will combine our custom tool(s) from the my_tool_registry we created above with the example_tool_registry using complete_tool_registry = example_tool_registry + my_tool_registry. Note: Make a demo_runs directory at this point. We will be using repeatedly. API keys requiredWe will use a simple GET endpoint from OpenWeatherMap in this section. Please sign up to obtain an API key from them (↗) and set it in the environment variable OPENWEATHERMAP_API_KEY.We're assuming you already have a Tavily key provisioned from the previous sections in this doc. If not, then head over to their website and do so (↗). We will set it in the environment variable TAVILY_API_KEY. custom_tools/main.pyfrom dotenv import load_dotenvfrom portia import ( Portia, example_tool_registry, Config, LogLevel,)load_dotenv()# Load example and custom tool registries into a single onecomplete_tool_registry = example_tool_registry + my_tool_registry# Instantiate Portia with the tools aboveportia = Portia( Config.from_default(default_log_level=LogLevel.DEBUG), tools=complete_tool_registry,)# Execute the plan from the user queryplan_run = portia.run('Get the weather in the town with the longest name in Welsh' + ' and write it to demo_runs/weather.txt.')# Serialise into JSON and print the outputprint(plan_run.model_dump_json(indent=2)) This should result in a plan and subsequent plan run automatically weaving in the WeatherTool and SearchTool from the example_tool_registry as well as our hot-off-the-press file_writer_tool from our custom_tool_registry. You should expect the weather information in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch to be printed in a weather.txt file inside a demo_runs folder as specified. If you're in the mood, now is a good time to practise your Welsh pronunciation. demo_runs/weather.txtThe current weather in Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch is broken clouds with a temperature of 6.76°C. Class-based approach (Alternative)​ For more complex scenarios requiring advanced customisation, you can also use the class-based approach. This provides more control over tool configuration and is equivalent to the decorator approach shown above: file_reader_tool.py (class-based)file_writer_tool.py (class-based)custom_tools/file_reader_tool.pyfrom pathlib import Pathimport pandas as pdimport jsonfrom pydantic import BaseModel, Fieldfrom portia.tool import Tool, ToolRunContextclass FileReaderToolSchema(BaseModel): \"\"\"Schema defining the inputs for the FileReaderTool.\"\"\" filename: str = Field(..., description=\"The location where the file should be read from\", )class FileReaderTool(Tool[str]): \"\"\"Finds and reads content from a local file on Disk.\"\"\" id: str = \"file_reader_tool\" name: str = \"File reader tool\" description: str = \"Finds and reads content from a local file on Disk\" args_schema: type[BaseModel] = FileReaderToolSchema output_schema: tuple[str, str] = (\"str\", \"A string dump or JSON of the file content\") def run(self, _: ToolRunContext, filename: str) -> str | dict[str,any]: \"\"\"Run the FileReaderTool.\"\"\" file_path = Path(filename) suffix = file_path.suffix.lower() if file_path.is_file(): if suffix == '.csv': return pd.read_csv(file_path).to_string() elif suffix == '.json': with file_path.open('r', encoding='utf-8') as json_file: data = json.load(json_file) return data elif suffix in ['.xls', '.xlsx']: return pd.read_excel(file_path).to_string() elif suffix in ['.txt', '.log']: return file_path.read_text(encoding=\"utf-8\")my_custom_tools/file_writer_tool.pyfrom pathlib import Pathfrom pydantic import BaseModel, Fieldfrom portia.tool import Tool, ToolRunContextclass FileWriterToolSchema(BaseModel): \"\"\"Schema defining the inputs for the FileWriterTool.\"\"\" filename: str = Field(..., description=\"The location where the file should be saved\", ) content: str = Field(..., description=\"The content to write to the file\", )class FileWriterTool(Tool): \"\"\"Writes content to a file.\"\"\" id: str = \"file_writer_tool\" name: str = \"File writer tool\" description: str = \"Writes content to a file locally\" args_schema: type[BaseModel] = FileWriterToolSchema output_schema: tuple[str, str] = (\"str\", \"A string indicating where the content was written to\") def run(self, _: ToolRunContext, filename: str, content: str) -> str: \"\"\"Run the FileWriterTool.\"\"\" filepath = Path(filename) if filepath.is_file(): with open(filepath, \"w\") as file: file.write(content) else: with open(filepath, \"x\") as file: file.write(content) return f\"Content written to {filename}\" When using the class-based approach you would be registering the tools the exact same way as the decorator approach: my_custom_tools/registry.py (class-based)\"\"\"Registry containing my custom tools.\"\"\"from portia import InMemoryToolRegistryfrom my_custom_tools.file_reader_tool import FileReaderToolfrom my_custom_tools.file_writer_tool import FileWriterToolcustom_tool_registry = InMemoryToolRegistry.from_local_tools( [ FileReaderTool(), FileWriterTool(), ],) The @tool decorator approach is recommended for most use cases due to its simplicity and ease of use, while the class-based approach provides more flexibility for advanced scenarios.Using the @tool decoratorManage tool registriesBringing it together in an exampleClass-based approach (Alternative)",
      "timestamp": "2025-08-24 06:52:46"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/xero",
      "title": "Xero | Portia AI Docs",
      "content": "Xero | Portia AI Docs Skip to main contentOn this page Description​ Provides a bridge to the Xero accounting API, enabling financial data interactions and accounting operations through OAuth2 custom connections for automated workflow management. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"xero\", command=\"npx\", args=[\"-y\", \"@xeroapi/xero-mcp-server@latest\"], env={ \"XERO_CLIENT_ID\": \"your-client-id\", \"XERO_CLIENT_SECRET\": \"your-client-secret\", },) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"xero\", command=\"npx\", args=[\"-y\", \"@xeroapi/xero-mcp-server@latest\"], env={ \"XERO_CLIENT_ID\": \"your-client-id\", \"XERO_CLIENT_SECRET\": \"your-client-secret\", },) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:52:49"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/model",
      "title": "portia.model | Portia AI Docs",
      "content": "portia.model | Portia AI Docs Skip to main contentOn this pageLLM provider model classes for Portia Agents. Message Objects​ class Message(BaseModel) Portia LLM message class. from_langchain​ @classmethoddef from_langchain(cls, message: BaseMessage) -> Message Create a Message from a LangChain message. Arguments: message BaseMessage - The LangChain message to convert. Returns: Message - The converted message. to_langchain​ def to_langchain() -> BaseMessage Convert to LangChain BaseMessage sub-type. Returns: BaseMessage - The converted message, subclass of LangChain's BaseMessage. LLMProvider Objects​ class LLMProvider(Enum) Enum for supported LLM providers. Attributes: OPENAI - OpenAI provider. ANTHROPIC - Anthropic provider. MISTRALAI - MistralAI provider. GOOGLE - Google Generative AI provider. AZURE_OPENAI - Azure OpenAI provider. GOOGLE_GENERATIVE_AI​ noqa: PIE796 - Alias for GOOGLE member GenerativeModel Objects​ class GenerativeModel(ABC) Base class for all generative model clients. __init__​ def __init__(model_name: str) -> None Initialize the model. Arguments: model_name - The name of the model. get_response​ @abstractmethoddef get_response(messages: list[Message]) -> Message Given a list of messages, call the model and return its response as a new message. Arguments: messages list[Message] - The list of messages to send to the model. Returns: Message - The response from the model. get_structured_response​ @abstractmethoddef get_structured_response(messages: list[Message], schema: type[BaseModelT]) -> BaseModelT Get a structured response from the model, given a Pydantic model. Arguments: messages list[Message] - The list of messages to send to the model. schema type[BaseModelT] - The Pydantic model to use for the response. Returns: BaseModelT - The structured response from the model. aget_response​ @abstractmethodasync def aget_response(messages: list[Message]) -> Message Given a list of messages, call the model and return its response as a new message async. Arguments: messages list[Message] - The list of messages to send to the model. aget_structured_response​ @abstractmethodasync def aget_structured_response(messages: list[Message], schema: type[BaseModelT]) -> BaseModelT Get a structured response from the model, given a Pydantic model asynchronously. Arguments: messages list[Message] - The list of messages to send to the model. schema type[BaseModelT] - The Pydantic model to use for the response. get_context_window_size​ def get_context_window_size() -> int Get the context window size of the model. Falls back to 100k tokens if the model is not found. __str__​ def __str__() -> str Get the string representation of the model. __repr__​ def __repr__() -> str Get the string representation of the model. to_langchain​ @abstractmethoddef to_langchain() -> BaseChatModel Get the LangChain client. LangChainGenerativeModel Objects​ class LangChainGenerativeModel(GenerativeModel) Base class for LangChain-based models. __init__​ def __init__(client: BaseChatModel, model_name: str) -> None Initialize with LangChain client. Arguments: client - LangChain chat model instance model_name - The name of the model to_langchain​ def to_langchain() -> BaseChatModel Get the LangChain client. get_response​ def get_response(messages: list[Message]) -> Message Get response using LangChain model. get_structured_response​ def get_structured_response(messages: list[Message], schema: type[BaseModelT], **kwargs: Any) -> BaseModelT Get structured response using LangChain model. Arguments: messages list[Message] - The list of messages to send to the model. schema type[BaseModelT] - The Pydantic model to use for the response. **kwargs - Additional keyword arguments to pass to the with_structured_output method. Returns: BaseModelT - The structured response from the model. aget_response​ async def aget_response(messages: list[Message]) -> Message Get response using LangChain model asynchronously. Arguments: messages list[Message] - The list of messages to send to the model. aget_structured_response​ async def aget_structured_response(messages: list[Message], schema: type[BaseModelT], **kwargs: Any) -> BaseModelT Get structured response using LangChain model asynchronously. Arguments: messages list[Message] - The list of messages to send to the model. schema type[BaseModelT] - The Pydantic model to use for the response. **kwargs - Additional keyword arguments to pass to the with_structured_output method. set_cache​ @classmethoddef set_cache(cls, cache: BaseCache) -> None Set the cache for the model. OpenAIGenerativeModel Objects​ class OpenAIGenerativeModel(LangChainGenerativeModel) OpenAI model implementation. __init__​ def __init__(*, model_name: str, api_key: SecretStr, seed: int = 343, max_retries: int = 3, temperature: float = 0, **kwargs: Any) -> None Initialize with OpenAI client. Arguments: model_name - OpenAI model to use api_key - API key for OpenAI seed - Random seed for model generation max_retries - Maximum number of retries temperature - Temperature parameter **kwargs - Additional keyword arguments to pass to ChatOpenAI get_structured_response​ def get_structured_response(messages: list[Message], schema: type[BaseModelT], **kwargs: Any) -> BaseModelT Call the model in structured output mode targeting the given Pydantic model. Arguments: messages list[Message] - The list of messages to send to the model. schema type[BaseModelT] - The Pydantic model to use for the response. **kwargs - Additional keyword arguments to pass to the model. Returns: BaseModelT - The structured response from the model. get_structured_response_instructor​ def get_structured_response_instructor(messages: list[Message], schema: type[BaseModelT]) -> BaseModelT Get structured response using instructor. aget_structured_response​ async def aget_structured_response(messages: list[Message], schema: type[BaseModelT], **kwargs: Any) -> BaseModelT Call the model in structured output mode targeting the given Pydantic model. Arguments: messages list[Message] - The list of messages to send to the model. schema type[BaseModelT] - The Pydantic model to use for the response. **kwargs - Additional keyword arguments to pass to the model. Returns: BaseModelT - The structured response from the model. aget_structured_response_instructor​ async def aget_structured_response_instructor( messages: list[Message], schema: type[BaseModelT]) -> BaseModelT Get structured response using instructor asynchronously. OpenRouterGenerativeModel Objects​ class OpenRouterGenerativeModel(OpenAIGenerativeModel) OpenRouter model implementation. __init__​ def __init__(*, model_name: str, api_key: SecretStr, seed: int = 343, max_retries: int = 3, temperature: float = 0, **kwargs: Any) -> None Initialize with OpenRouter client. Arguments: model_name - OpenRouter model to use api_key - API key for OpenRouter seed - Random seed for model generation max_retries - Maximum number of retries temperature - Temperature parameter **kwargs - Additional keyword arguments to pass to ChatOpenAI AzureOpenAIGenerativeModel Objects​ class AzureOpenAIGenerativeModel(LangChainGenerativeModel) Azure OpenAI model implementation. __init__​ def __init__(*, model_name: str, api_key: SecretStr, azure_endpoint: str, api_version: str = \"2025-01-01-preview\", seed: int = 343, max_retries: int = 3, temperature: float = 0, **kwargs: Any) -> None Initialize with Azure OpenAI client. Arguments: model_name - OpenAI model to use azure_endpoint - Azure OpenAI endpoint api_version - Azure API version seed - Random seed for model generation api_key - API key for Azure OpenAI max_retries - Maximum number of retries temperature - Temperature parameter (defaults to 1 for O_3_MINI, 0 otherwise) **kwargs - Additional keyword arguments to pass to AzureChatOpenAI get_structured_response​ def get_structured_response(messages: list[Message], schema: type[BaseModelT], **kwargs: Any) -> BaseModelT Call the model in structured output mode targeting the given Pydantic model. Arguments: messages list[Message] - The list of messages to send to the model. schema type[BaseModelT] - The Pydantic model to use for the response. **kwargs - Additional keyword arguments to pass to the model. Returns: BaseModelT - The structured response from the model. get_structured_response_instructor​ def get_structured_response_instructor(messages: list[Message], schema: type[BaseModelT]) -> BaseModelT Get structured response using instructor. aget_structured_response​ async def aget_structured_response(messages: list[Message], schema: type[BaseModelT], **kwargs: Any) -> BaseModelT Call the model in structured output mode targeting the given Pydantic model. Arguments: messages list[Message] - The list of messages to send to the model. schema type[BaseModelT] - The Pydantic model to use for the response. **kwargs - Additional keyword arguments to pass to the model. Returns: BaseModelT - The structured response from the model. AnthropicGenerativeModel Objects​ class AnthropicGenerativeModel(LangChainGenerativeModel) Anthropic model implementation. __init__​ def __init__(*, model_name: str = \"claude-3-7-sonnet-latest\", api_key: SecretStr, timeout: int = 120, max_retries: int = 3, max_tokens: int = 8096, **kwargs: Any) -> None Initialize with Anthropic client. Arguments: model_name - Name of the Anthropic model timeout - Request timeout in seconds max_retries - Maximum number of retries max_tokens - Maximum number of tokens to generate api_key - API key for Anthropic **kwargs - Additional keyword arguments to pass to ChatAnthropic get_response​ def get_response(messages: list[Message]) -> Message Get response from Anthropic model, handling list content. get_structured_response​ def get_structured_response(messages: list[Message], schema: type[BaseModelT], **kwargs: Any) -> BaseModelT Call the model in structured output mode targeting the given Pydantic model. Arguments: messages list[Message] - The list of messages to send to the model. schema type[BaseModelT] - The Pydantic model to use for the response. **kwargs - Additional keyword arguments to pass to the model. Returns: BaseModelT - The structured response from the model. get_structured_response_instructor​ def get_structured_response_instructor(messages: list[Message], schema: type[BaseModelT]) -> BaseModelT Get structured response using instructor. aget_response​ async def aget_response(messages: list[Message]) -> Message Get response from Anthropic model asynchronously, handling list content. aget_structured_response​ async def aget_structured_response(messages: list[Message], schema: type[BaseModelT], **kwargs: Any) -> BaseModelT Call the model in structured output mode targeting the given Pydantic model async. Arguments: messages list[Message] - The list of messages to send to the model. schema type[BaseModelT] - The Pydantic model to use for the response. **kwargs - Additional keyword arguments to pass to the model. Returns: BaseModelT - The structured response from the model. aget_structured_response_instructor​ async def aget_structured_response_instructor( messages: list[Message], schema: type[BaseModelT]) -> BaseModelT Get structured response using instructor asynchronously. map_message_to_instructor​ def map_message_to_instructor(message: Message) -> ChatCompletionMessageParam Map a Message to ChatCompletionMessageParam. Arguments: message Message - The message to map. Returns: ChatCompletionMessageParam - Message in the format expected by instructor. Message ObjectsLLMProvider ObjectsGenerativeModel ObjectsLangChainGenerativeModel ObjectsOpenAIGenerativeModel ObjectsOpenRouterGenerativeModel ObjectsAzureOpenAIGenerativeModel ObjectsAnthropicGenerativeModel Objects",
      "timestamp": "2025-08-24 06:52:52"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/telemetry/telemetry_service",
      "title": "portia.telemetry.telemetry_service | Portia AI Docs",
      "content": "portia.telemetry.telemetry_service | Portia AI Docs Skip to main contentOn this pageTelemetry service for capturing anonymized usage data. xdg_cache_home​ def xdg_cache_home() -> Path Get the XDG cache home directory path. Returns: Path - The path to the cache directory, either from XDG_CACHE_HOME environment variable or the default ~/.portia location. get_project_id_key​ def get_project_id_key() -> str Get the project ID key. Returns: str - The project ID key BaseProductTelemetry Objects​ class BaseProductTelemetry(ABC) Base interface for capturing anonymized telemetry data. This class handles the collection and transmission of anonymized usage data to PostHog. Telemetry can be disabled by setting the environment variable ANONYMIZED_TELEMETRY=False. capture​ @abstractmethoddef capture(event: BaseTelemetryEvent) -> None Capture and send a telemetry event. Arguments: event BaseTelemetryEvent - The telemetry event to capture ProductTelemetry Objects​ @singletonclass ProductTelemetry(BaseProductTelemetry) Service for capturing anonymized telemetry data. This class handles the collection and transmission of anonymized usage data to PostHog. Telemetry can be disabled by setting the environment variable ANONYMIZED_TELEMETRY=False. Attributes: USER_ID_PATH str - Path where the user ID is stored PROJECT_API_KEY str - PostHog project API key HOST str - PostHog server host URL UNKNOWN_USER_ID str - Default user ID when user identification fails __init__​ def __init__() -> None Initialize the telemetry service. Sets up the PostHog client if telemetry is enabled and configures logging. capture​ def capture(event: BaseTelemetryEvent) -> None Capture and send a telemetry event. Arguments: event BaseTelemetryEvent - The telemetry event to capture user_id​ @propertydef user_id() -> str Get the current user ID, generating a new one if it doesn't exist. Returns: str - The user ID, either from cache or newly generated BaseProductTelemetry ObjectsProductTelemetry Objects",
      "timestamp": "2025-08-24 06:52:55"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-draft-email",
      "title": "Google Gmail - Gmail: Draft | Portia AI Docs",
      "content": "Google Gmail - Gmail: Draft | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:gmail:draft_email Tool description: Drafts an email for the recipients indicated. Should not be used with the send email tool. Instead to send a draft email use the portia:google:gmail:send_draft_email. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Args schema: { \"description\": \"Input for DraftEmailTool.\", \"properties\": { \"recipients\": { \"description\": \"The recipients that the email should be drafted for (should be a list of email addresses)\", \"items\": { \"type\": \"string\" }, \"title\": \"Recipients\", \"type\": \"array\" }, \"email_title\": { \"description\": \"The title of the email draft\", \"title\": \"Email Title\", \"type\": \"string\" }, \"email_body\": { \"description\": \"The body of the email draft\", \"title\": \"Email Body\", \"type\": \"string\" } }, \"required\": [ \"recipients\", \"email_title\", \"email_body\" ], \"title\": \"DraftEmailToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Output of the email drafted')UsageTool details",
      "timestamp": "2025-08-24 06:52:58"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-drive/drive-search",
      "title": "Google Drive - Drive: Search | Portia AI Docs",
      "content": "Google Drive - Drive: Search | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:drive:search Tool description: Search for files and folders in Google Drive. Google Drive stores proprietary files like Google Docs, Sheets, and Slides. It also stores regular files like PDFs, images, and videos or even files from other apps like Microsoft docx, xlsx, pptx, etc. Use this tool to search for files using a search query. This tool should be used to resolve name / file descriptions into concrete file IDs for other Google tools to use when needed. Args schema: { \"description\": \"Schema for the Google Drive search tool.\", \"properties\": { \"query\": { \"description\": \"The query to search for. ALWAYS EXCLUDE words like 'doc', 'sheet', 'spreadsheet', 'file' from the end query string. For example if the query is 'cash flow forecast spreadsheet', the query string should be 'cash flow forecast'\", \"title\": \"Query\", \"type\": \"string\" }, \"mime_type\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The MIME type of the files to search for. Use this if you want to search for files with a specific type of file or file extension. For example, 'application/pdf' or 'pdf'. Uses RFC 6838 standard for MIME types.\", \"title\": \"Mime Type\" } }, \"required\": [ \"query\" ], \"title\": \"GoogleDriveSearchToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Dictionary containing the results of the Google Drive search. Each file result includes metadata like name, id, mimeType and more.')UsageTool details",
      "timestamp": "2025-08-24 06:53:01"
    },
    {
      "url": "https://docs.portialabs.ai/mcp-servers",
      "title": "Integrating an MCP server with the SDK | Portia AI Docs",
      "content": "Integrating an MCP server with the SDK | Portia AI Docs Skip to main content The Model Context Protocol (MCP) makes it very easy to integrate third-party tools into your Portia AI project. To find out more you can visit the official MCP docs ↗. Remote MCP serversThis section covers integration an MCP server with the SDK. The easiest way to connect a remote MCP server with managed authentication is through the Cloud tool registry (see documentation here). When using the cloud tool registry, authentication is handled for you, but if you're connecting directly into the SDK then you'll need to handle authentication yourself. We provide developers with the ability to set up their own MCP server connections (local or remote) directly into our SDK. When integrating an SDK server directly with the SDK, we offer the three methods currently available for interacting with MCP servers: STDIO (Standard input/output): The server runs as a subprocess of your main python process. Below we interact with that process via an npx command and a docker command provided with the correct arguments. Streamable HTTP: Communication is over HTTP, you can run the server locally or deploy a server remotely. Per below, you just need to specify the current server name and URL. SSE (Server-Sent Events): A legacy method of communication over HTTP, since replaced by Streamable HTTP. To find out more about these options, see the official MCP docs (↗). The server_name argument is used by Portia to identify where tools have come from, you can set this to whatever makes most sense for the MCP server you are integrating. If you re-use old Plan objects later on, make sure to use the same server_name with the MCP server. STDIOStreamable HTTPSSEmcp_stdio_example.pyimport osfrom portia import ( DefaultToolRegistry, Portia, McpToolRegistry, Config,)config = Config.from_default()tool_registry = ( # Integrates the Stripe MCP server from # https://github.com/stripe/agent-toolkit/tree/main/modelcontextprotocol McpToolRegistry.from_stdio_connection( server_name=\"stripe\", command=\"npx\", args=[ \"-y\", \"@stripe/mcp\", \"--tools=all\", f\"--api-key={os.getenv('STRIPE_API_KEY')}\", ], ) # Integrates Github MCP server using docker + McpToolRegistry.from_stdio_connection( server_name=\"github\", command=\"docker\", args=[ \"run\", \"-i\", \"--rm\", \"-e\", \"GITHUB_PERSONAL_ACCESS_TOKEN\", \"ghcr.io/github/github-mcp-server\" ], env={ \"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<YOUR TOKEN>\" } ) + DefaultToolRegistry(config))portia = Portia(config=config, tools=tool_registry)mcp_streamable_http_example.pyfrom portia import ( DefaultToolRegistry, Portia, McpToolRegistry, Config,)config = Config.from_default()tool_registry = ( # Assumes server is running on port 8000 McpToolRegistry.from_streamable_http_connection( server_name=\"mcp_streamable_http_example_server\", url=\"http://mcp.example.com/http\", ) + DefaultToolRegistry(config))portia = Portia(config=config, tools=tool_registry)mcp_sse_example.pyfrom portia import ( DefaultToolRegistry, Portia, McpToolRegistry, Config,)config = Config.from_default()tool_registry = ( # Assumes server is running on port 8000 McpToolRegistry.from_sse_connection( server_name=\"mcp_sse_example_server\", url=\"http://localhost:8000\", ) + DefaultToolRegistry(config))portia = Portia(config=config, tools=tool_registry) Pre-requisitesTo run the stdio example, make sure npx and docker are available in your environment. Many MCP servers are currently provided to run in this way, usually either run with the npx, docker or uvx command. When you provide a McpToolRegistry, Portia will pull in the tool definitions from the MCP server, making them available to the Planner and Execution Agents during a plan run. To see an example of this implementation, head over to our agent-examples repo where we built an agent to manage customer refunds (↗). There are many open source MCP servers already available: check out the list of servers on the official MCP github repository (↗).",
      "timestamp": "2025-08-24 06:53:04"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/image-understanding",
      "title": "Open Source - Image Understanding | Portia AI Docs",
      "content": "Open Source - Image Understanding | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: image_understanding_tool Tool description: Tool for understanding images from a URL. Capable of tasks like object detection, OCR, scene recognition, and image-based Q&A. This tool uses its native capabilities to analyze images and provide insights. Args schema: { \"description\": \"Input for Image Understanding Tool.\", \"properties\": { \"task\": { \"description\": \"The task to be completed by the Image tool.\", \"title\": \"Task\", \"type\": \"string\" }, \"image_url\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Image URL for processing.\", \"title\": \"Image Url\" }, \"image_file\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Image file for processing.\", \"title\": \"Image File\" } }, \"required\": [ \"task\" ], \"title\": \"ImageUnderstandingToolSchema\", \"type\": \"object\"} Output schema: ('str', \"The Image understanding tool's response to the user query about the provided image.\")UsageTool details",
      "timestamp": "2025-08-24 06:53:07"
    },
    {
      "url": "https://docs.portialabs.ai/steel-thread-intro",
      "title": "Introducing Steel Thread | Portia AI Docs",
      "content": "Introducing Steel Thread | Portia AI Docs Skip to main contentOn this page Steel Thread is a lightweight, extensible framework for evaluating LLM agents — designed to help teams measure quality, catch regressions, and improve performance with minimal friction. Steel Thread is built around two core abstractions: Streams are dynamic datasets built from sampling real plans and plan runs in production allowing you to monitor live agent behaviour. Evals are static data sets designed to be run multiple times to allow you to analyze the impact of changes to your agents before deploying them. Note that Steel Thread is built to work specifically with Portia cloud and therefore requires a Portia API key. Why we built Steel Thread​ Evaluating agents isn’t hard because the models are bad — it’s hard because: The output space is non-deterministic. The tool usage is complex and multi-step. The definition of \"correct\" can be subjective. And most of all: curating test data is painful ☠️. We found that most eval frameworks fall down not on logic or metrics — but on data. They assume someone else is maintaining eval datasets that are 1) clean, 2) up-to-date with how their agents are behaving in production. Instead of asking teams to build new datasets from scratch, Steel Thread plugs directly into the data you already generate in Portia Cloud: Plans Plan Runs Tool Calls User IDs Metadata and outputs Now, every agent execution can become an eval — either retrospectively or in real time. What does it do?​ Steel Thread helps you figure out whether your agents are getting better or worse across runs. It does this by providing: 🌊 Streams​ Run against your live or recent production runs. More commonly referred to as 'online evals', they are useful for: Monitoring quality in production usage. Tracking performance across time or model changes. Detecting silent failures. 📈 Evals​ Run against curated static datasets. More commonly referred to as 'offline evals', they are useful for: Iterating on prompts. Testing new chains of tool calls. Benchmarking models. Catching regressions on common use cases before deployment. 🎯 Custom metrics​ Use both determistic evaluators or LLMs-as-judge ones to compute: Accuracy Completeness Clarity Efficiency Latency Tool usage ...or domain-specific checks Built for Portia​ Steel Thread is deeply integrated with the Portia SDK and cloud. It works natively with: Plan and PlanRun IDs Tool call metadata End user context Agent outputs (e.g. final outputs, intermediate values) APIs and UI features in Portia Cloud This means you don’t need to create new test harnesses or annotate synthetic datasets — you can evaluate what's already happening. Just point Steel Thread at your Portia instance, and start measuring.Why we built Steel ThreadWhat does it do?🌊 Streams📈 Evals🎯 Custom metricsBuilt for Portia",
      "timestamp": "2025-08-24 06:53:10"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/weather",
      "title": "Open Source - Weather | Portia AI Docs",
      "content": "Open Source - Weather | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: weather_tool Tool description: Get the weather for a given city Usage notes: This tool uses a simple GET endpoint from OpenWeatherMap. Please sign up to obtain an API key from them (↗) and set it in the environment variable OPENWEATHERMAP_API_KEY. Args schema: { \"description\": \"Input for WeatherTool.\", \"properties\": { \"city\": { \"description\": \"The city to get the weather for\", \"title\": \"City\", \"type\": \"string\" } }, \"required\": [ \"city\" ], \"title\": \"WeatherToolSchema\", \"type\": \"object\"} Output schema: ('str', 'String output of the weather with temp and city')UsageTool details",
      "timestamp": "2025-08-24 06:53:13"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-groups-for-user",
      "title": "Zendesk - Groups: List for User | Portia AI Docs",
      "content": "Zendesk - Groups: List for User | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:groups:list_groups_for_user Tool description: Returns a list of groups that a user (Agent or Admin) is a member of. Returns a maximum of 100 records. Args schema: { \"description\": \"Input schema for ZendeskListGroupsTool.\", \"properties\": { \"user_id\": { \"description\": \"The id of the user\", \"title\": \"User Id\", \"type\": \"integer\" } }, \"required\": [ \"user_id\" ], \"title\": \"ZendeskListGroupsForUserToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:53:16"
    },
    {
      "url": "https://docs.portialabs.ai/browser-tools",
      "title": "Using browser tools | Portia AI Docs",
      "content": "Using browser tools | Portia AI Docs Skip to main contentOn this page Browser tools (SDK ↗) can deploy an agent to browse the internet and retrieve data or enact actions on your behalf. Portia will use Browser tools when it recognises there is a web-based task to be performed. We use the Browser Use (↗) library to offer a multi-modal web agent that will visually and textually analyse a website in order to navigate it and carry out a task. Our browser tool can be used in two modes: Remote mode: Runs on a remote chromium instance using Browserbase (↗) as the underlying infrastructure. Browserbase offers infrastructure for headless browsers remotely. We spin up remote sessions for your end-users which persist through clarifications. Local mode (DEFAULT): Runs on a chrome instance on your own computer. Requires Chrome to be started fresh by the agent to work. The underlying library for navigating the page is provided by Browser Use (↗). It uses a number of LLM calls to navigate the page and complete the action. Setting up the browser based tools​ Browserbase setupLocal setupTo use browserbase infrastructure, you need to install the required tools-browser-browserbase dependency group:pip install \"portia-sdk-python[tools-browser-browserbase]\"# Alternatively, install our 'all' dependency group to get everythingpip install \"portia-sdk-python[all]\"You must also ensure that you have set the BROWSERBASE_API_KEY and BROWSERBASE_PROJECT_ID in your .env file (or equivalent). These can be obtained by creating an account on Browserbase (↗). The current behaviour requires a paid version of Browserbase to use.With local setup, the browser tool uses chrome on the machine it is running on. This means that it is not possible to support end-users but is a good way to test or to write agents for your own purposes. To use the browser tool in local mode, you need to install the required tools-browser-local dependency group:pip install \"portia-sdk-python[tools-browser-local]\"# Alternatively, install our 'all' dependency group to get everythingpip install \"portia-sdk-python[all]\"You must then specify the BrowserInfrastructureOption when creating the tool, i.e:from portia.open_source_tools.browser_tool import BrowserInfrastructureOption, BrowserToolbrowser_tool = BrowserTool(infrastructure_option=BrowserInfrastructureOption.LOCAL)You can specify the executable for the Chrome instance, by setting PORTIA_BROWSER_LOCAL_CHROME_EXEC='path/to/chrome/exec'. If not specified, the default location on most operating systems will be used. For the agent to work, all other Chrome instances must be closed before the task starts. Using browser based tools in Portia​ The BrowserTool is located in our open source tools folder SDK ↗. Additionally, there are 2 ways to use the tool: BrowserTool(): This is a general browser tool and it will be used when a URL is provided as part of the query. BrowserTool examplefrom portia import Config, Portiafrom portia.open_source_tools.browser_tool import BrowserTooltask = \"Find my connections called 'Bob' on LinkedIn (https://www.linkedin.com)\"# Needs BrowserBase API key and project_idportia = Portia(config=Config.from_default(), tools=[BrowserTool()]) BrowserToolForUrl(url): To restrict the browser tool to a specific URL. This is particularly useful to ensure that the planner is restricted to the domains that you want it to be support. BrowserToolForUrl examplefrom portia import Config, Portiafrom portia.open_source_tools.browser_tool import BrowserToolForUrltask = \"Find my connections called 'Bob' on LinkedIn\"# Needs BrowserBase API key and project_idportia = Portia(config=Config.from_default(), tools=[BrowserToolForUrl(\"https://www.linkedin.com\")]) A simple E2E example​ Full examplefrom dotenv import load_dotenvfrom portia import ( ActionClarification, Config, PlanRunState, Portia,)from portia.open_source_tools.browser_tool import BrowserToolload_dotenv(override=True)task = \"Get the top news headline from the BBC news website (https://www.bbc.co.uk/news)\"portia = Portia(Config.from_default(), tools=[BrowserTool()])plan_run = portia.run(task)while plan_run.state == PlanRunState.NEED_CLARIFICATION: # If clarifications are needed, resolve them before resuming the workflow print(\"\\nPlease resolve the following clarifications to continue\") for clarification in plan_run.get_outstanding_clarifications(): # Handling of Action clarifications if isinstance(clarification, ActionClarification): print(f\"{clarification.user_guidance} -- Please click on the link below to proceed.\") print(clarification.action_url) input(\"Press Enter to continue...\") # Once clarifications are resolved, resume the workflow plan_run = portia.resume(plan_run) Authentication with browser based tools​ Recap: Portia AuthenticationPortia uses Clarifications to handle human-in-the-loop authentication (full explanation here ↗). In our OAuth based tools, the user clicks on a link, authenticates and their token is used when the agents resumes. In the browser tool case, whenever a browser tool encounters a page that requires authentication, it will raise a clarification request to the user, just like API-based Portia tools. The user will need to provide the necessary credentials or authentication information into the website to proceed. The cookies for that authentication are then used for the rest of the plan run. Authentication with BrowserbaseLocal Browser AuthenticationIn the case of Browserbase Authentication, the end-user will be provided with a URL starting with browserbase.com/devtools-fullscreen/.... When the end-user visits this page, they will see the authentication screen to enter their credentials (and any required 2FA or similar checks). This requires a paid version of Browserbase to work. In addition, Browserbase sessions have a timeout (default is 1hr with a max of 6hr) and the clarification must be handled by the user within this time.Once the end-user has performed the authentication, they should then indicate to your application that they have completed the flow, and you should call portia.resume(plan_run) to resume the agent. Note if you are using the CLIClarificationHandler, this will not work in this way and you will need to override it to ensure this behaviour.The authentication credentials will be saved against the end user and can be reused until they expire. When the credentials expire, a new clarification will be raised to reset the authentication. If you want to disable persistent authentication across agent runs, you should clear the bb_context_id attribute.When running via a Local browser, i.e via your own computer, the clarification URL will be a regular URL that you can click on to authenticate. When to use API vs browser based tools​ Browser based tools are very flexible in terms of what they do, however they do not have the same tight permissioning as OAuth tools and require more LLM calls so we recommend balancing between the two and using browser tools only when APIs are not available. Known issues and caveats​ Popups and authentication​ When using Browserbase as the underlying browser infrastructure, if authentication requires a popup, it will not show to the user and they will not be able to log-in. We are investigating solutions for this at the moment. Local chrome failing to connect​ If you see an issue whereby Chrome opens, but then immediately closes and restarts, the issue is likely because it can't find the user data directory and the debug server is not starting. You can fix this by specifying the env variable PORTIA_BROWSER_LOCAL_EXTRA_CHROMIUM_ARGS=\"--user-data-dir='path/to/dir'\" and there's more information about this on the browser-use issue link ↗. LLM moderation​ We have occasionally observed that LLMs might get moderated on tasks that look like authentication requests to websites. These issues are typically transient but you may want to adjust the task or plan to avoid direct requests for the agent to login to a website.Setting up the browser based toolsUsing browser based tools in PortiaA simple E2E exampleAuthentication with browser based toolsWhen to use API vs browser based toolsKnown issues and caveatsPopups and authenticationLocal chrome failing to connectLLM moderation",
      "timestamp": "2025-08-24 06:53:19"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-send-draft-email",
      "title": "Microsoft Outlook - Outlook: Send Draft | Portia AI Docs",
      "content": "Microsoft Outlook - Outlook: Send Draft | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Selecting Microsoft Tools​ Microsoft tools are included in Portia's cloud registry but are not included in the default DefaultToolRegistry class. This is due to tool clashes with the Google tools (i.e. the agent wouldn't know whether to check Gmail or Outlook for email tasks). In order to use Microsoft tools rather than Google tools, simply filter out the Google tools from the Portia cloud registry rather than using the default registry: from portia import PortiaToolRegistry, default_configregistry = PortiaToolRegistry(default_config()).filter_tools(lambda tool: not tool.id.startswith(\"portia:google:\"))registry = PortiaToolRegistry(default_config()).filter_tools( lambda tool: not tool.id.startswith(\"portia:google:\")) Tool details​ Tool ID: portia:microsoft:outlook:send_draft_email Tool description: Sends a previously drafted email with the email title, body and recipients indicated in the draft. Requires a draft id which is obtained from the DraftEmailTool. Only use this tool if you actually want to send an email, not if the user just wants to draft an email. Args schema: { \"description\": \"Input for SendDraftEmailTool.\", \"properties\": { \"draft_id\": { \"description\": \"The id of the draft email as returned by the DraftEmailTool tool\", \"title\": \"Draft Id\", \"type\": \"string\" } }, \"required\": [ \"draft_id\" ], \"title\": \"SendDraftEmailToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Output of the email sent')UsageSelecting Microsoft ToolsTool details",
      "timestamp": "2025-08-24 06:53:22"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/create-ticket",
      "title": "Zendesk - Tickets: Create | Portia AI Docs",
      "content": "Zendesk - Tickets: Create | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:tickets:create Tool description: Create a Zendesk Ticket. This populates the ticket with the provided subject and description. This should be followed up with calls to the ZendeskUpdateTicketTool to add or change details if needed. {SHARED_TICKET_DESCRIPTION} Args schema: { \"description\": \"Input schema for ZendeskCreateTicketTool.\", \"properties\": { \"subject\": { \"description\": \"The subject of the ticket\", \"title\": \"Subject\", \"type\": \"string\" }, \"description\": { \"description\": \"The initial comment/description of the ticket.\", \"title\": \"Description\", \"type\": \"string\" } }, \"required\": [ \"subject\", \"description\" ], \"title\": \"ZendeskCreateTicketToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Returns the created ticket data from Zendesk API matching the input schema')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:53:25"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-delete-event",
      "title": "Google Calendar - Calendar: Delete Event | Portia AI Docs",
      "content": "Google Calendar - Calendar: Delete Event | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:gcalendar:delete_event Tool description: Deletes the Google Calendar event associated with the ID. Args schema: { \"description\": \"Schema for deleting a Google Calendar event.\", \"properties\": { \"event_id\": { \"description\": \"The ID of the event to delete\", \"title\": \"Event Id\", \"type\": \"string\" } }, \"required\": [ \"event_id\" ], \"title\": \"GoogleCalendarDeleteEventSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Output of the tool')UsageTool details",
      "timestamp": "2025-08-24 06:53:28"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-drive",
      "title": "Google Drive Tools | Portia AI Docs",
      "content": "Google Drive Tools | Portia AI Docs Skip to main content Drive: SearchSearch for files and folders in Google Drive. Google Drive stores proprietary files like Google Docs, Sheets, and Slides. It also stores regular files like PDFs, images, and videos or even files from other apps like Microsoft docx, xlsx, pptx, etc. Use this tool to search for files using a search query. This tool should be used to resolve name / file descriptions into concrete file IDs for other Google tools to use when needed.",
      "timestamp": "2025-08-24 06:53:31"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-tickets",
      "title": "Zendesk - Tickets: Search | Portia AI Docs",
      "content": "Zendesk - Tickets: Search | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:tickets:search Tool description: Searches for tickets in Zendesk based on a natural language query or the Zendesk API syntax. Returns up to 1000 tickets that match the query. Args schema: { \"description\": \"Input schema for ZendeskSearchTicketsTool.\", \"properties\": { \"query\": { \"description\": \"The query to search for. It can be a natural language query or use the syntax of the Zendesk API.\", \"title\": \"Query\", \"type\": \"string\" } }, \"required\": [ \"query\" ], \"title\": \"ZendeskSearchTicketsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API for searching Zendesk tickets. This includes most core ticket information like ID, subject, description, status, priority, and type. It excludes comments.')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:53:34"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/list-conversations",
      "title": "Slack - Conversation: List | Portia AI Docs",
      "content": "Slack - Conversation: List | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Slack tools with Portia AI​ You will need to create your own Slack App to use with Portia AI. This is so you can control the name and appearance of slack bot activity initiated via the Portia AI framework. Once your slack app is created you can configure your client ID and secret in the Portia dashboard. Install a Slack app​ Head over to api.slack.com/apps ↗ Create an app from scratch and select the Slack workplace you would like to use it in. Note down the client ID and secret on the Basic Information page. We will need this in a couple of steps from now! In the OAuth & Permissions tab further down in the left hand nav, add as Redirect URL the following URL https://api.portialabs.ai/api/v0/oauth/slack (don't forget to hit that Save URLs button!). Under Bot Token Scopes, be sure to add the scopes channels:history -- View messages and other content in public channels that your Slack app has been added to. channels:read -- View basic information about public channels in a workspace. chat:write -- Send messages as @{your slack app name}. users:read -- View people in a workspace. Under User Token Scopes, be sure to add the scope search:read to support searching workplace content. Now scroll up to the top of the OAuth & Permissions page and hit the Install to {your workplace name} button. Once that is done, open your Slack app and hit 'Add apps` and be sure to select your new app. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the client ID and secret of your Slack app as collected in step 3 of the Slack installation process above. You are now ready to call Slack tools on our cloud! Tool details​ Tool ID: portia:slack:bot:list_conversation_ids Tool description: List all conversations meta information only without comments in the slack workspaceThis tool should be used when you need to make api calls to other slack apis that requirea conversation or channel id. DOES NOT RETURN MESSAGES, CONVERSATION HISTORY, OR USER IDS. Args schema: { \"description\": \"Input for ListSlackConversationIDsTool.\", \"properties\": {}, \"title\": \"ListSlackConversationIDsToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Conversation meta information: Name, ID, and Type')UsageConfigure your Slack tools with Portia AIInstall a Slack appConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:53:37"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/supermemory",
      "title": "Supermemory | Portia AI Docs",
      "content": "Supermemory | Portia AI Docs Skip to main contentOn this page Description​ Personal knowledge platform that helps collect, organize, and recall information from various sources with end-to-end encryption and optional self-hosting. Authorisation​ This server does not require any extra authentication to use, other than the MCP server URL. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:53:40"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/chroma",
      "title": "Chroma | Portia AI Docs",
      "content": "Chroma | Portia AI Docs Skip to main contentOn this page Description​ Integrates with Chroma vector database to enable collection management, document operations, and vector search capabilities for knowledge bases and context-aware conversations. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"chroma-mcp\", command=\"uvx\", args=[\"chroma-mcp\", \"--client-type\", \"persistent\", \"--data-dir\", \"/path/to/chroma/\"],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"chroma-mcp\", command=\"uvx\", args=[\"chroma-mcp\", \"--client-type\", \"persistent\", \"--data-dir\", \"/path/to/chroma/\"],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:53:43"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-requests",
      "title": "Zendesk - Requests: Search | Portia AI Docs",
      "content": "Zendesk - Requests: Search | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:requests:search Tool description: Search for requests in Zendesk. Returns a maximum of 100 requests. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Args schema: { \"description\": \"Input schema for ZendeskSearchRequestsTool.\", \"properties\": { \"query\": { \"description\": \"The syntax and matching logic for the string is detailed in the Zendesk Support search reference.\", \"title\": \"Query\", \"type\": \"string\" } }, \"required\": [ \"query\" ], \"title\": \"ZendeskSearchRequestsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:53:46"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-get-events-by-properties",
      "title": "Google Calendar - Calendar: Get Events By Properties | Portia AI Docs",
      "content": "Google Calendar - Calendar: Get Events By Properties | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:gcalendar:get_events_by_properties Tool description: Gets Google Calendar events by properties, returning the matching event details. You do not need to provide all the properties, only the ones you have provided with. Args schema: { \"description\": \"Schema for getting a Google Calendar events by properties.\", \"properties\": { \"event_title\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The title of the event to get\", \"title\": \"Event Title\" }, \"start_time\": { \"anyOf\": [ { \"format\": \"date-time\", \"type\": \"string\" }, { \"type\": \"string\" } ], \"default\": \"1970-01-01T00:00:00\", \"description\": \"The earliest time of the events to get in ISO format without timezone, e.g 2024-09-20T20:00:00\", \"title\": \"Start Time\" }, \"end_time\": { \"anyOf\": [ { \"format\": \"date-time\", \"type\": \"string\" }, { \"type\": \"string\" } ], \"default\": \"2100-01-01T00:00:00\", \"description\": \"The latest time of the events to get in ISO format without timezone, e.g 2024-09-20T20:00:00\", \"title\": \"End Time\" }, \"event_description\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"The description of the events to get\", \"title\": \"Event Description\" }, \"attendees\": { \"default\": [], \"description\": \"The attendees' of the events to get\", \"items\": { \"type\": \"string\" }, \"title\": \"Attendees\", \"type\": \"array\" }, \"max_results\": { \"default\": 10, \"description\": \"The maximum number of events to return\", \"title\": \"Max Results\", \"type\": \"integer\" } }, \"title\": \"GoogleCalendarGetEventsByPropertiesSchema\", \"type\": \"object\"} Output schema: ('list[dict]', 'A list of dictionaries containing information about matching calendar events')UsageTool details",
      "timestamp": "2025-08-24 06:53:49"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk",
      "title": "Zendesk Tools | Portia AI Docs",
      "content": "Zendesk Tools | Portia AI Docs Skip to main content Articles: Create CommentsCreate a comment on a zendesk article. Articles: ListList up to 100 Zendesk articles. An article is a piece of content that is createdby Zendesk. Use this tool to get articles without a search query. Articles: List CommentsReturns up to 100 comments made by all users on a specific article. Articles: SearchReturns up to 25 articles relevant to the search query, which must be provided. Articles: ShowShows the properties of a Zendesk article. An article is a piece of content that is created by Zendesk. Groups: List UsersReturns a list of memberships for a group. Memberships include the user ID and metadata about their membership in the group. Returns a maximum of 100 records. Groups: List for UserReturns a list of groups that a user (Agent or Admin) is a member of. Returns a maximum of 100 records. Groups: SearchSearch for groups in Zendesk. It can be a natural language query or use the syntax of the Zendesk API. Groups: ShowReturns a group. Organizations: SearchRetrieves a list of organizations in Zendesk matching the query. Organizations: ShowGets information about a specific organization in Zendesk. Posts: List CommentsLists all comments on a specific post. Posts: ShowGets information about a given post. A post is community content that is created by a user and is not the same as an article. Request Comments: ListLists comments on a Zendesk request. Returns a maximum of 100 comments. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Request Comments: ShowRetrieves information about a specific comment on a request in Zendesk. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Requests: SearchSearch for requests in Zendesk. Returns a maximum of 100 requests. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Requests: ShowRetrieves information about a specific request in Zendesk. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Sections: List ArticlesLists all articles in a given section of the Zendesk Help Center. Sections group related articles together. Sections: ShowReturns a section of the Zendesk Help Center articles. Sections group related articles together. Tickets: CountReturns an approximate count of tickets in the account. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Tickets: Count CommentsReturns an approximate count of the comments added to the ticket. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Tickets: CreateCreate a Zendesk Ticket. This populates the ticket with the provided subject and description. This should be followed up with calls to the ZendeskUpdateTicketTool to add or change details if needed. {SHARED_TICKET_DESCRIPTION} Tickets: List CommentsReturns the comments added to the ticket. Each comment may include a `content_url` for an attachment or a `recording_url` for a voice comment that points to a file that may be hosted externally. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Tickets: SearchSearches for tickets in Zendesk based on a natural language query or the Zendesk API syntax. Returns up to 1000 tickets that match the query. Tickets: ShowReturns a number of ticket properties though not the ticket comments. To get the comments, use the ZendeskListTicketCommentsTool. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Tickets: Show MetricsReturns metrics for a specific ticket, including first response time, full resolution time, number of reopens, and other performance metrics. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Tickets: UpdateUpdates an existing ticket in Zendesk with the provided details. For fields requiring group and user ID fields, use the ZendeskSearchGroupsTool and ZendeskSearchUsersTool to get the IDs. This tool can be run once with multiple details updated on the ticket or multiple times with a single detail updated on the ticket. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Users: SearchReturns an array of users who meet the search criteria. Returns a maximum of 100 users. This may include (but is not limited to) the user's name, contact information, role, permissions, locale, organization, and other information. Users: ShowReturns information about a specific user in Zendesk.",
      "timestamp": "2025-08-24 06:53:52"
    },
    {
      "url": "https://docs.portialabs.ai/execution-hooks",
      "title": "Execution hooks | Portia AI Docs",
      "content": "Execution hooks | Portia AI Docs Skip to main contentOn this page Execution hooks provide the ability for users to extend, intervene in or modify the running of agents in Portia, including allowing human control to be overlayed into the multi-agent plan run deterministically. This is done by allowing you to run custom code at specific points in the agent run. This can be very useful in a wide range of circumstances: To add human-in-the-loop verification before tool calls. For example, if you're building an agent to verify and then administer product refunds to customers, you likely want to include a human-in-the-loop check before the agent gives out the refund. To add guardrails into the system, causing the agent to exit if a bad output is given or skip steps if certain conditions are met To modify the args that tools are called with (for example to redact any leaked PII (personally identifiable information)) To stream updates of the system to a frontend to display to the user To add custom logging Available hooks​ Portia provides several hook points where you can inject custom code: Before plan run: Run only before the first step of a plan run. This can be useful for any setup steps you need to take at the start of a run. Before step: Run before each step in the plan is executed. This can be useful if you want add a guardrail before each step. After step: Run after each step completes. This can be useful for streaming updates on each step to a frontend. After last step: Run only after the final step of a plan run. This can be useful for any cleanup steps that you need to take at the end of a run. Before tool call: Run directly before any tool is called. This can be useful if you want to add a human-in-the-loop check before running a particular tool, or if you want to add any checks on tool args before a tool is called. You can also alter the tool args in this hook if required. After tool call: Executed directly after any tool call completes. This can be useful if you want to add any guardrail that check tool output. Implementing an execution hook​ To implement a custom hook, simply define the code you want to run and then pass it in as a hook when creating your Portia instance. We also provide several pre-made execution hooks that can be imported from portia.execution_hooks: from dotenv import load_dotenvfrom portia import Plan, PlanRun, Portia, Step, loggerfrom portia.execution_hooks import ExecutionHooks, clarify_on_all_tool_calls, log_step_outputsload_dotenv()def log_before_each_step(plan: Plan, plan_run: PlanRun, step: Step) -> None: # noqa: ARG001 \"\"\"Log the output of a step in the plan.\"\"\" logger().info(f\"Running step with task {step.task} using tool {step.tool_id}\")portia = Portia( execution_hooks=ExecutionHooks( # Out custom hook defined above before_step_execution=log_before_each_step, # Imported hook to raise a clarification before all tool calls before_tool_call=clarify_on_all_tool_calls, # Imported hook to log the result of all steps after_step_execution=log_step_outputs, ),) Human-in-the-loop checks​ In the 'before tool call' and 'after tool call' hooks, you can raise clarifications with the user if you require their input. As with other clarifications, these clarifications are then handled by the user through your chosen clarification handler (see the clarification docs ↗. for more details). This allows you to create powerful human-in-the-loop checks and guardrails. As an example, the below code uses a UserVerificationClarification to ensure that the user verifies all calls to the refund tool. from typing import Anyfrom portia import Clarification, ClarificationCategory, ExecutionHooks, PlanRun, Portia, Step, Tool, ToolHardErrorfrom portia.clarification import UserVerificationClarificationdef clarify_before_refunds( tool: Tool, args: dict[str, Any], plan_run: PlanRun, step: Step,) -> Clarification | None: # Only raise a clarification for the refund tool if tool.id != \"refund_tool\": return None # Find if the clarification if we already raised it previous_clarification = plan_run.get_clarification_for_step(ClarificationCategory.USER_VERIFICATION) # If we haven't raised it, or it has been resolved, raise a clarification if not previous_clarification or not previous_clarification.resolved: return UserVerificationClarification( plan_run_id=plan_run.id, user_guidance=f\"Are you happy to proceed with the call to {tool.name} with args {args}? \" \"Enter 'y' or 'yes' to proceed\", ) # If the user didn't verify the tool call, error out if str(previous_clarification.response).lower() not in [\"y\", \"yes\"]: raise ToolHardError(\"User rejected tool call to {tool.name} with args {args}\") # If the user did verify the tool call, continue to the call return Noneportia = Portia(execution_hooks=ExecutionHooks(before_tool_call=clarify_before_refunds)) This is a common use-case so you don't actually need to write this yourself - you can use our pre-made clarify_on_tool_calls hook.Available hooksImplementing an execution hookHuman-in-the-loop checks",
      "timestamp": "2025-08-24 06:53:55"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs/",
      "title": "Google Docs Tools | Portia AI Docs",
      "content": "Google Docs Tools | Portia AI Docs Skip to main content Docs: Get DocumentGet a document from Google Docs in plain text format by ID. The GoogleDriveSearchTool should be used to search for a document by name if an ID is not known. Docs: Get Structured DocumentGet a document from Google Docs in a machine readable format. Do not use unless you reallyneed a structured document.",
      "timestamp": "2025-08-24 06:53:58"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/count-tickets",
      "title": "Zendesk - Tickets: Count | Portia AI Docs",
      "content": "Zendesk - Tickets: Count | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:tickets:count Tool description: Returns an approximate count of tickets in the account. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Args schema: { \"description\": \"Input schema for ZendeskCountTicketsTool.\", \"properties\": {}, \"title\": \"ZendeskCountTicketsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API with the approximate count of tickets in the account.')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:54:01"
    },
    {
      "url": "https://docs.portialabs.ai/store-retrieve-plan-runs",
      "title": "Plan run states on Portia cloud | Portia AI Docs",
      "content": "Plan run states on Portia cloud | Portia AI Docs Skip to main contentOn this page Use our Run service to save and retrieve serialised plan run states on our cloud. Storing and retrieving plan runs on Portia cloud significantly simplifies the management of long lived and / or asynchronous plan runs. For example when a clarification is raised, the state of the plan run is automatically maintained in the Portia cloud and retrieving the plan run once the clarification is handled is a single line of code. API keys requiredWe're assuming you already have a Portia API key from the dashboard and set it in your environment variables. If not please refer to the previous section and do that first (Set up your account ↗).We will use a simple GET endpoint from OpenWeatherMap in this section. Please sign up to obtain an API key from them (↗) and set it in the environment variable OPENWEATHERMAP_API_KEY. Store plan runs in the cloud​ We have seen how to configure the location where plan runs are stored and retrieved previously (Manage config options ↗). We can simply set the storage_class property to CLOUD in the config of our Portia instance. With this config and as long as the API key has been set up appropriately as described in the previous section (Set up your account ↗), you should see plan runs executed by your Portia instance appear in the Plan runs tab of your Portia dashboard and see a change in the aggregate plan run metrics in the Home page as well. main.pyfrom dotenv import load_dotenvfrom portia import Portiafrom portia.config import Config, StorageClassfrom portia.open_source_tools.registry import example_tool_registryload_dotenv()# Load the default config and override the storage class to point to the Portia cloudmy_config = Config.from_default(storage_class=StorageClass.CLOUD)# Instantiate a Portia instance. Load it with the default config and an example tool registryportia = Portia(config=my_config, tools=example_tool_registry)# Run a plan from the user queryplan_run = portia.run('Get the temperature in London and share it with a light joke')# Serialise into JSON and print the outputprint(plan_run.model_dump_json(indent=2)) Take a moment to examine the plan run created by the code above in your dashboard. To do so you will need the plan run ID, appearing in the first attribute of the output e.g. \"id\": \"prun-f66b141b-5603-4bd9-b827-0c7a41bf5d5c\". Retrieve plan runs from the cloud​ You can retrieve both plans and run states for a stored plan run. For that you would use the get_plan_run and get_plan methods of the Storage class. You will need to specify the PortiaCloudStorage class in particular here. Go ahead and copy your plan run ID from the dashboard entry created in the previous section into the code below. main.pyfrom dotenv import load_dotenvfrom portia import Config, StorageClassfrom portia.storage import PortiaCloudStorageload_dotenv()# Load the default config and override the storage class to point to the Portia cloudmy_config = Config.from_default(storage_class=StorageClass.CLOUD)# Use the PortiaCloudStorage class to interact with cloud storagemy_store = PortiaCloudStorage(config=my_config)# Retrieve a plan and its run from the cloudplan_run = my_store.get_plan_run(\"229956fb-820d-4099-b69c-0606ca620b86\")plan = my_store.get_plan(plan_run.plan_id)# Serialise into JSON an print the objectsprint(f\"Retrieved plan run:\\n{plan_run.model_dump_json(indent=2)}\")print(f\"Retrieved plan:\\n{plan.model_dump_json(indent=2)}\") Note that you can also access the StorageClass directly from your Portia instance. If you have a Portia instance with an associated Config that uses CLOUD storage like the first example on this page, you could simply use portia.storage.get_plan_run and portia.storage.get_plan. You should expect to see the following output: Retrieved plan run:{ \"id\": \"prun-f66b141b-5603-4bd9-b827-0c7a41bf5d5c\", \"plan_id\": \"plan-1eee4bbf-361a-41be-bab7-6dd86a247f48\", \"current_step_index\": 1, \"clarifications\": [], \"state\": \"COMPLETE\", \"step_outputs\": { \"$weather_joke\": { \"value\": \"Why did the weather go to therapy? It had too many issues to cloud its mind!\" }, \"$london_temperature\": { \"value\": \"The current weather in London is overcast clouds with a temperature of 0.91°C.\" } }, \"final_output\": { \"value\": \"Why did the weather go to therapy? It had too many issues to cloud its mind!\" }}Retrieved plan:{ \"id\": \"plan-1eee4bbf-361a-41be-bab7-6dd86a247f48\", \"query\": \"Get the temperature in London and share it with a light joke\", \"steps\": [ { \"task\": \"Get the current temperature in London.\", \"inputs\": [], \"tool_id\": \"weather_tool\", \"output\": \"$london_temperature\" }, { \"task\": \"Generate a light joke about the weather.\", \"inputs\": [ { \"name\": \"$london_temperature\", \"description\": \"The current temperature in London.\" } ], \"tool_id\": \"llm_tool\", \"output\": \"$weather_joke\" } ]} If you wanted to retrieve plan runs in bulk, you can use the get_plan_runs method (plural!) from StorageClass. This returns paginated data so you will need to process that information further to cycle through all results. Remember the first page number returned is always 1 (not 0!). plan_run_list_init = my_store.get_plan_runs() # again, plural!total_pages = plan_run_list_init.total_pagesfor page in range(1, total_pages+1): print(f\"Retrieving plan runs from page {page}...\") plan_run_list = my_store.get_plan_runs(page=page) for plan_run in plan_run_list.results: print(f\"Plan run ID: {plan_run.id}\")Store plan runs in the cloudRetrieve plan runs from the cloud",
      "timestamp": "2025-08-24 06:54:04"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/playwright",
      "title": "Playwright | Portia AI Docs",
      "content": "Playwright | Portia AI Docs Skip to main contentOn this page Description​ Enables web browser control for navigating websites, capturing page snapshots, interacting with elements, and taking screenshots through Playwright's automation capabilities. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"playwright\", command=\"npx\", args=[\"@playwright/mcp@latest\"],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"playwright\", command=\"npx\", args=[\"@playwright/mcp@latest\"],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:54:07"
    },
    {
      "url": "https://docs.portialabs.ai/telemetry",
      "title": "Telemetry Overview | Portia AI Docs",
      "content": "Telemetry Overview | Portia AI Docs Skip to main contentOn this pagetipBy default, the telemetry data collected by the library is not personally identifiable information under GDPR and other privacy regulations as the data is deliberately anonymized.The anonymized data collected is described in detail below. Collecting this data helps us understand how the library is being used and to improve the user experience. It also helps us fix bugs faster and prioritize feature development. We use PostHog for telemetry collection. The data is completely anonymized and contains no personally identifiable information. We track the following events. Portia function calls​ We track the following Portia function calls: Portia.run Portia.plan Portia.run_plan Portia.resume Portia.execute_plan_run_and_handle_clarifications Portia.resolve_clarification Portia.wait_for_ready Portia.create_plan_run For each of these, we track usage of features and tool IDs, e.g for Portia.run: self.telemetry.capture(PortiaFunctionCallTelemetryEvent( function_name='portia_run', function_args={ 'tools': \",\".join([tool.id if isinstance(tool, Tool) else tool for tool in tools]) if tools else None, 'example_plans_provided': example_plans != None, # Whether examples plan were provided. 'end_user_provided': end_user != None, # Whether an end user was used. 'plan_run_inputs_provided': plan_run_inputs != None # Whether plan inputs were used. })) Portia tool calls​ We also track when a tool call happens and the name of the tool that was executed. None of the arguments to the tool are tracked. Opting out You can disable telemetry by setting the environment variable: ANONYMIZED_TELEMETRY=falsePortia function callsPortia tool calls",
      "timestamp": "2025-08-24 06:54:10"
    },
    {
      "url": "https://docs.portialabs.ai/steel-thread-quickstart",
      "title": "Install and quickstart | Portia AI Docs",
      "content": "Install and quickstart | Portia AI Docs Skip to main contentOn this page SteelThread relies on access to agent activity in Portia cloud (queries, plans, plan runs). You will need a PORTIA_API_KEY to get started. Head over to (app.portialabs.ai ↗) and navigate to the Manage API keys tab from the left hand nav. There you can generate a new API key. For a deeper diveBelow takes you through install and two end-to-end examples. If you wanted to get a deeper understanding, head over to: Streams page. Evals page. Install using your framework of choice​ pippoetryuvpip install steel-threadpoetry add steel-threaduv add steel-thread Create a dataset​ If you're new to Portia you may not have agent runs in the cloud just yet so let's start by creating those. Run the query Read the user feedback notes in local file {path}, and call out recurring themes in their feedback. Use lots of ⚠️ emojis when highlighting areas of concern. where path is a local file you can put a couple of lines of fictitious user feedback in. Here's the script to save you same time: from portia import Portiapath = \"./uxr/calorify.txt\" # TODO: change to your desired pathquery =f\"Read the user feedback notes in local file {path}, \\ and call out recurring themes in their feedback. \\ Use lots of ⚠️ emojis when highlighting areas of concern.\"Portia().run(query=query) Basic example Streams​ Below is example code to process a stream. Before running it make sure you set up your stream from the Portia dashboard's Observability tab, paying special attention to the name you gave your stream so you can pass it to the process_stream method per below. This method will use the built-in set of Stream evaluators to give you data out of the box. from portia import Configfrom steelthread.steelthread import SteelThread, StreamConfigfrom dotenv import load_dotenvload_dotenv(override=True)config = Config.from_default()# Setup SteelThread instance and process streamst = SteelThread()st.process_stream( StreamConfig( # The stream name is the name of the stream we created in the dashboard. stream_name=\"your-stream-name-here\", config=config, )) End-to-end example with Evals​ Let's push the envelope with some more advanced usage for Evals. Create an Eval dataset in the dashboard from the plan run we made in the Create a dataset section. Navigate to the \"Evaluations\" tab of the dashboard, create a new eval set from existing data and select the relevant plan run. Record the name you bestowed upon your Eval dataset as you will need to pass it to the evaluators in the code below, which you are now ready to run. This code: Uses a custom evaluator to count ⚠️ emojis in the output. We will do this by subclassing the Evaluator class. Stubs the file_reader_tool with static text. We will point our Portia client to a ToolStubRegistry to do this. Run the evals for the dataset you create to compute the emoji count metric over it. Feel free to mess around with the output from the tool stub and re-run these Evals a few times to see the progression in scoring. from portia import Portia, Config, DefaultToolRegistryfrom steelthread.steelthread import SteelThread, EvalConfigfrom steelthread.evals import Evaluator, EvalMetricfrom steelthread.portia.tools import ToolStubRegistry, ToolStubContext# Define custom evaluatorclass EmojiEvaluator(Evaluator): def eval_test_case(self, test_case,plan, plan_run, metadata): out = plan_run.outputs.final_output.get_value() or \"\" count = out.count(\"⚠️\") return EvalMetric.from_test_case( test_case=test_case, name=\"emoji_score\", score=min(count / 2, 1.0), description=\"Emoji usage\", explanation=f\"Found {count} ⚠️ emojis in the output.\", actual_value=str(count), expectation=\"2\" )# Define stub behaviordef file_reader_stub_response( ctx: ToolStubContext,) -> str: \"\"\"Stub response for file reader tool to return static file content.\"\"\" filename = ctx.kwargs.get(\"filename\", \"\").lower() return f\"Feedback from file: {filename} suggests \\ ⚠️ 'One does not simply Calorify' \\ and ⚠️ 'Calorify is not a diet' \\ and ⚠️ 'Calorify is not a weight loss program' \\ and ⚠️ 'Calorify is not a fitness program' \\ and ⚠️ 'Calorify is not a health program' \\ and ⚠️ 'Calorify is not a nutrition program' \\ and ⚠️ 'Calorify is not a meal delivery service' \\ and ⚠️ 'Calorify is not a meal kit service' \"config = Config.from_default()# Add the tool stub definition to your Portia client using a ToolStubRegistryportia = Portia( config, tools=ToolStubRegistry( DefaultToolRegistry(config), stubs={ \"file_reader_tool\": file_reader_stub_response, }, ),)# Run evals with stubs SteelThread().run_evals( portia, EvalConfig( eval_dataset_name=\"your-dataset-name-here\", #TODO: replace with your dataset name config=config, iterations=5, evaluators=[EmojiEvaluator(config)] ),)Install using your framework of choiceCreate a datasetBasic example StreamsEnd-to-end example with Evals",
      "timestamp": "2025-08-24 06:54:13"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/grafana",
      "title": "Grafana | Portia AI Docs",
      "content": "Grafana | Portia AI Docs Skip to main contentOn this page Description​ Integrates with Grafana to enable searching dashboards, fetching datasource information, querying Prometheus metrics, and managing incidents through both stdio and SSE transport modes. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"grafana\", command=\"docker\", args=[ \"run\", \"--rm\", \"-i\", \"-e\", \"GRAFANA_URL\", \"-e\", \"GRAFANA_API_KEY\", \"mcp/grafana\", \"-t\", \"stdio\", ], env={\"GRAFANA_URL\": \"<grafana_url>\", \"GRAFANA_API_KEY\": \"<api_key>\"},) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"grafana\", command=\"docker\", args=[ \"run\", \"--rm\", \"-i\", \"-e\", \"GRAFANA_URL\", \"-e\", \"GRAFANA_API_KEY\", \"mcp/grafana\", \"-t\", \"stdio\", ], env={\"GRAFANA_URL\": \"<grafana_url>\", \"GRAFANA_API_KEY\": \"<api_key>\"},) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:54:16"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/qdrant",
      "title": "Qdrant | Portia AI Docs",
      "content": "Qdrant | Portia AI Docs Skip to main contentOn this page Description​ Store and retrieve vector-based memories for AI systems. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"qdrant\", command=\"uvx\", args=[ \"mcp-server-qdrant\", ], env={ \"QDRANT_LOCAL_PATH\": \"<path_to_qdrant>\", \"COLLECTION_NAME\": \"<collection_name>\", \"EMBEDDING_MODEL\": \"<model_name>\", },) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"qdrant\", command=\"uvx\", args=[ \"mcp-server-qdrant\", ], env={ \"QDRANT_LOCAL_PATH\": \"<path_to_qdrant>\", \"COLLECTION_NAME\": \"<collection_name>\", \"EMBEDDING_MODEL\": \"<model_name>\", },) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:54:19"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/tool_wrapper",
      "title": "portia.tool_wrapper | Portia AI Docs",
      "content": "portia.tool_wrapper | Portia AI Docs Skip to main contentOn this pageTool Wrapper that intercepts run calls and records them. This module contains the ToolCallWrapper class, which wraps around an existing tool and records information about the tool's execution, such as input, output, latency, and status. The recorded data is stored in AdditionalStorage for later use. Classes: ToolCallWrapper: A wrapper that intercepts tool calls, records execution data, and stores it. ToolCallWrapper Objects​ class ToolCallWrapper(Tool) Tool Wrapper that records calls to its child tool and sends them to the AdditionalStorage. This class is a wrapper around a child tool. It captures the input and output, measures latency, and records the status of the execution. The results are then stored in the provided AdditionalStorage. Attributes: model_config ConfigDict - Pydantic configuration that allows arbitrary types. _child_tool Tool - The child tool to be wrapped and executed. _storage AdditionalStorage - Storage mechanism to save tool call records. _plan_run PlanRun - The run context for the current execution. __init__​ def __init__(child_tool: Tool, storage: AdditionalStorage, plan_run: PlanRun) -> None Initialize parent fields using child_tool's attributes. Arguments: child_tool Tool - The child tool to be wrapped. storage AdditionalStorage - The storage to save execution records. plan_run PlanRun - The PlanRun to execute. ready​ def ready(ctx: ToolRunContext) -> ReadyResponse Check if the child tool is ready and return ReadyResponse. run​ def run(ctx: ToolRunContext, *args: Any, **kwargs: Any) -> Any | Clarification Run the child tool and store the outcome. This method executes the child tool with the provided arguments, records the input, output, latency, and status of the execution, and stores the details in AdditionalStorage. Arguments: ctx ToolRunContext - The context containing user data and metadata. *args Any - Positional arguments for the child tool. **kwargs Any - Keyword arguments for the child tool. Returns: Any | Clarification: The output of the child tool or a clarification request. Raises: Exception - If an error occurs during execution, the exception is logged, and the status is set to FAILED. arun​ async def arun(ctx: ToolRunContext, *args: Any, **kwargs: Any) -> Any | Clarification Async run the child tool and store the outcome.ToolCallWrapper Objects",
      "timestamp": "2025-08-24 06:54:22"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/weather",
      "title": "portia.open_source_tools.weather | Portia AI Docs",
      "content": "portia.open_source_tools.weather | Portia AI Docs Skip to main contentOn this pageTool to get the weather from openweathermap. WeatherToolSchema Objects​ class WeatherToolSchema(BaseModel) Input for WeatherTool. WeatherTool Objects​ class WeatherTool(Tool[str]) Get the weather for a given city. run​ def run(_: ToolRunContext, city: str) -> str Run the WeatherTool. arun​ async def arun(_: ToolRunContext, city: str) -> str Run the WeatherTool asynchronously.WeatherToolSchema ObjectsWeatherTool Objects",
      "timestamp": "2025-08-24 06:54:25"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/context",
      "title": "portia.execution_agents.context | Portia AI Docs",
      "content": "portia.execution_agents.context | Portia AI Docs Skip to main contentOn this pageContext builder that generates contextual information for the PlanRun. This module defines a set of functions that build various types of context required for the run execution. It takes information about inputs, outputs, clarifications, and execution metadata to build context strings used by the agent to perform tasks. The context can be extended with additional system or user-provided data. generate_main_system_context​ def generate_main_system_context() -> list[str] Generate the main system context. Returns: list[str] - A list of strings representing the system context. StepInput Objects​ class StepInput(BaseModel) An input for a step being executed by an execution agent. generate_input_context​ def generate_input_context(step_inputs: list[StepInput], previous_outputs: dict[str, Output]) -> list[str] Generate context for the inputs and indicate which ones were used. Arguments: step_inputs list[StepInput] - The list of inputs for the current step. previous_outputs dict[str, Output] - A dictionary of previous step outputs. Returns: list[str] - A list of strings representing the input context. generate_clarification_context​ def generate_clarification_context(clarifications: ClarificationListType, step: int) -> list[str] Generate context from clarifications for the given step. Arguments: clarifications ClarificationListType - A list of clarification objects. step int - The step index for which clarifications are being generated. Returns: list[str] - A list of strings representing the clarification context. generate_context_from_run_context​ def generate_context_from_run_context(context: ToolRunContext) -> list[str] Generate context from the execution context. Arguments: context ExecutionContext - The execution context containing metadata and additional data. Returns: list[str] - A list of strings representing the execution context. build_context​ def build_context(ctx: ToolRunContext, plan_run: PlanRun, step_inputs: list[StepInput]) -> str Build the context string for the agent using inputs/outputs/clarifications/ctx. Arguments: ctx ToolRunContext - The tool run context containing agent and system metadata. plan_run PlanRun - The current run containing outputs and clarifications. step_inputs list[StepInput] - The inputs for the current step. Returns: str - A string containing all relevant context information. StepInput Objects",
      "timestamp": "2025-08-24 06:54:28"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/hubspot",
      "title": "HubSpot | Portia AI Docs",
      "content": "HubSpot | Portia AI Docs Skip to main contentOn this page Description​ Integrates with HubSpot CRM to enable secure access to contact information, company records, deal data, and task management with customizable data access through Private App scopes. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"hubspot\", command=\"npx\", args=[\"-y\", \"@hubspot/mcp-server\"], env={\"PRIVATE_APP_ACCESS_TOKEN\": \"<private_app_access_token>\"},) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"hubspot\", command=\"npx\", args=[\"-y\", \"@hubspot/mcp-server\"], env={\"PRIVATE_APP_ACCESS_TOKEN\": \"<private_app_access_token>\"},) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:54:31"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/github",
      "title": "GitHub | Portia AI Docs",
      "content": "GitHub | Portia AI Docs Skip to main contentOn this page Description​ Integration with GitHub Issues, Pull Requests, and more. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"github\", command=\"docker\", args=[ \"run\", \"-i\", \"--rm\", \"-e\", \"GITHUB_PERSONAL_ACCESS_TOKEN\", \"ghcr.io/github/github-mcp-server\", ], env={\"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<personal_access_token>\"},) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"github\", command=\"docker\", args=[ \"run\", \"-i\", \"--rm\", \"-e\", \"GITHUB_PERSONAL_ACCESS_TOKEN\", \"ghcr.io/github/github-mcp-server\", ], env={\"GITHUB_PERSONAL_ACCESS_TOKEN\": \"<personal_access_token>\"},) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:54:34"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/extract",
      "title": "Open Source - Extract | Portia AI Docs",
      "content": "Open Source - Extract | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: extract_tool Tool description: Extracts web page content from one or more specified URLs using Tavily Extract and returns the raw content, images, and metadata from those pages. The extract tool can access publicly available web pages but cannot extract content from pages that block automated access Usage notes: This tool uses the Tavily API. You can sign up to obtain a Tavily API key (↗) and set it in the environment variable TAVILY_API_KEY. Args schema: { \"description\": \"Input for ExtractTool.\", \"properties\": { \"urls\": { \"description\": \"List of URLs to extract content from\", \"items\": { \"type\": \"string\" }, \"title\": \"Urls\", \"type\": \"array\" }, \"include_images\": { \"default\": false, \"description\": \"Whether to include images in the extraction\", \"title\": \"Include Images\", \"type\": \"boolean\" }, \"include_favicon\": { \"default\": false, \"description\": \"Whether to include favicon in the extraction\", \"title\": \"Include Favicon\", \"type\": \"boolean\" }, \"extract_depth\": { \"default\": \"basic\", \"description\": \"The depth of the extraction process. Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency. Basic extraction costs 1 credit per 5 successful URL extractions, while advanced extraction costs 2 credits per 5 successful URL extractions.\", \"title\": \"Extract Depth\", \"type\": \"string\" }, \"format\": { \"default\": \"markdown\", \"description\": \"Output format: 'markdown' or 'text'\", \"title\": \"Format\", \"type\": \"string\" } }, \"required\": [ \"urls\" ], \"title\": \"ExtractToolSchema\", \"type\": \"object\"} Output schema: ('str', 'str: extracted content from URLs')UsageTool details",
      "timestamp": "2025-08-24 06:54:37"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/map_tool",
      "title": "portia.open_source_tools.map_tool | Portia AI Docs",
      "content": "portia.open_source_tools.map_tool | Portia AI Docs Skip to main contentOn this pageTool to map websites. MapToolSchema Objects​ class MapToolSchema(BaseModel) Input for MapTool. MapTool Objects​ class MapTool(Tool[str]) Maps websites using Tavily's graph-based traversal to generate comprehensive site maps. run​ def run(_: ToolRunContext, url: str, max_depth: int = 1, max_breadth: int = 20, limit: int = 50, instructions: str | None = None, **kwargs: Any) -> str Run the map tool.MapToolSchema ObjectsMapTool Objects",
      "timestamp": "2025-08-24 06:54:40"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/dbhub",
      "title": "DBHub | Portia AI Docs",
      "content": "DBHub | Portia AI Docs Skip to main contentOn this page Description​ Provides a universal database gateway for connecting to PostgreSQL, MySQL, SQLite, and DuckDB, enabling table browsing, schema inspection, and read-only SQL queries with built-in safety checks Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"dbhub-postgres-docker\", command=\"npx\", args=[ \"-y\", \"@bytebase/dbhub\", \"--transport\", \"stdio\", \"--dsn\", \"<connection_string>\", ],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"dbhub-postgres-docker\", command=\"npx\", args=[ \"-y\", \"@bytebase/dbhub\", \"--transport\", \"stdio\", \"--dsn\", \"<connection_string>\", ],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:54:43"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook",
      "title": "Microsoft Outlook Tools | Portia AI Docs",
      "content": "Microsoft Outlook Tools | Portia AI Docs Skip to main content Outlook: DraftDrafts an email for the recipients indicated. Should not be used with the send email tool. Instead to send a draft email use the send_draft_email_tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Outlook: SearchSearches for emails in the user's Outlook inbox and returns emails content that match the query. Outlook: SendSends an email to the recipients indicated. Should not be used with the draft email tool. Instead to send a draft email use the send_draft_email_tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Outlook: Send DraftSends a previously drafted email with the email title, body and recipients indicated in the draft. Requires a draft id which is obtained from the DraftEmailTool. Only use this tool if you actually want to send an email, not if the user just wants to draft an email.",
      "timestamp": "2025-08-24 06:54:46"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-send-draft-email",
      "title": "Google Gmail - Gmail: Send Draft | Portia AI Docs",
      "content": "Google Gmail - Gmail: Send Draft | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:google:gmail:send_draft_email Tool description: Sends a previously drafted email with the email title, body and recipients indicated in the draft. Requires a draft id which is obtained from the DraftEmailTool. Only use this tool if you actually want to send an email, not if the user just wants to draft an email. Args schema: { \"description\": \"Input for SendDraftEmailTool.\", \"properties\": { \"draft_id\": { \"description\": \"The id of the draft email as returned by the DraftEmailTool tool\", \"title\": \"Draft Id\", \"type\": \"string\" } }, \"required\": [ \"draft_id\" ], \"title\": \"SendDraftEmailToolSchema\", \"type\": \"object\"} Output schema: ('str', 'str: ID of the email sent')UsageTool details",
      "timestamp": "2025-08-24 06:54:49"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/notion",
      "title": "Notion | Portia AI Docs",
      "content": "Notion | Portia AI Docs Skip to main contentOn this page Description​ Bridges to the Notion API for searching content, querying databases, and managing pages and comments without requiring complex API interaction code Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"notionApi\", command=\"npx\", args=[\"-y\", \"@notionhq/notion-mcp-server\"], env={ \"OPENAPI_MCP_HEADERS\": '{\"Authorization\": \"Bearer <api_key>\", \"Notion-Version\": \"2022-06-28\" }' },) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"notionApi\", command=\"npx\", args=[\"-y\", \"@notionhq/notion-mcp-server\"], env={ \"OPENAPI_MCP_HEADERS\": '{\"Authorization\": \"Bearer <api_key>\", \"Notion-Version\": \"2022-06-28\" }' },) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:54:52"
    },
    {
      "url": "https://docs.portialabs.ai/cloud-tool-registry",
      "title": "Remote MCP and cloud tools | Portia AI Docs",
      "content": "Remote MCP and cloud tools | Portia AI Docs Skip to main contentOn this page When your agents are connected to Portia Cloud, they gain access to an extensive tool registry with powerful integrations. The registry includes by default popular services like Gmail, Google Calendar, Slack, GitHub, Zendesk, and is extensible to many more by integrating remote MCP servers. You can check out and configure the integrations you want access to in the dashboard (↗). This will update update the tools available to your DefaultToolRegistry (see here if you need a recap on how tool registries work). Authentication for these tools is handled seamlessly by Portia's authentication system ↗. This means all tools are available using just the Portia API key and you don't have to worry about implementing OAuth flows or handling tokens and API keys yourself! A snippet of our tool registry The registry contains applications, which are a collection of tools. It is fully configurable, allowing you to turn applications on and off so you can control which tools your agents have access to. The applications in the registry are a combination of remote MCP servers from official providers and tools developed by Portia. Remote MCP Servers​ The Model Context Protocol (MCP) makes it very easy to integrate third-party tools with Portia AI. To find out more about MCP you can visit the official MCP docs (↗). We support remote MCP execution within our tool registry and, where possible, our integrations use remote MCP servers from official providers, with communication over a streamable HTTP connection. This allows our tool registry to grow rapidly as providers bring out new remote MCP servers. We support authentication natively for all of these servers and are in the process of adding many other features to make working with them easier. You can extend your Portia cloud tool registry by configuring your own remote MCP server. This allows you to seamlessly integrate tools from any provider with a remote MCP server while Portia handles the authentication for you. Connect your own MCP server into our cloud tool registry Enabling authenticated remote MCP serversIt is worth noting that, when enabling MCP-based applications which use OAuth or API key authentication, you will need to authenticate with the server. This is required because MCP requires authentication in order to view available tools. The authentication credentials provided here are only used for listing tools from the server and are separate to those that the tool is executed with. We store all authentication credentials using production-grade encryption. Customizing MCP and other cloud based tools​ We offer an easy way to customize our cloud based tools, or remote MCP server tool descriptions using the ToolRegistry.with_tool_description function. You can read more about this here. Other Portia Cloud Tools​ Where there is no official remote MCP server for a provider, we have a collection of tools developed by Portia. This allows you to integrate easily with providers that are yet to release a remote MCP server. Authentication for the tools is handled fully by the Portia platform and you can use these tools in exactly the same way as you can use tools coming from remote MCP servers. Enabling and Disabling Tools​ When you enable an application, all tools in this application become available to your agent. Applications can be easily enabled and disabled in the UI by: Clicking on the 'Enable' / 'Disable' button when you hover over the application. Configuring access if required - this is only required for remote MCP servers Once this is done, the tool is configured and you'll be able to view the available tools under the application in the dashboard. Quickly enable and disable tools hovering over them It is important to choose your enabled tools carefully to avoid tool clashes. For example, if you wish to enable Microsoft Outlook, you should disable Gmail so that the agent knows which email provider to choose when you give it prompts like 'send an email'.Remote MCP ServersCustomizing MCP and other cloud based toolsOther Portia Cloud ToolsEnabling and Disabling Tools",
      "timestamp": "2025-08-24 06:54:56"
    },
    {
      "url": "https://docs.portialabs.ai/integrating-tools",
      "title": "Integrating tools | Portia AI Docs",
      "content": "Integrating tools | Portia AI Docs Skip to main contentOn this page Learn how to integrate tools that your agent can use to answer a user query. TL;DR You can specify the tools that agents can use to answer a user query by using the tools argument in your Portia instance. If you don't specify this, the Portia instance will use a default set of tools. Tool registries are useful to group frequently used tools together. They are represented by the ToolRegistry class (SDK reference ↗). Overview of tool integration​ As part of defining your Portia instance for a query, you can specify the tools that the LLM can use to answer the query. This is done by specifying the tools argument in the Portia instance definition. from portia import ( default_config, Portia,)from portia.open_source_tools.calculator_tool import CalculatorToolfrom portia.open_source_tools.search_tool import SearchToolfrom portia.open_source_tools.weather import WeatherTool# Instantiate a Portia instance. Load it with the default config and with the example tools.portia = Portia(tools=[CalculatorTool(), SearchTool(), WeatherTool()]) If you don't specify the tools argument, your Portia instance will use a default set of tools. Default toolsThe default tool set comprises: The open source tool set, with the Search tool and Weather tool only included if you have the corresponding Tavily / OpenWeatherMap API keys specified. If you have an API key for Portia Cloud, the tools from your cloud tool registry will be included. This includes the ability to integrate any remote MCP server, as well as a suite of pre-created integrations you can use straight off the bat. Further information on this tool registry, including how it can be configured, can be found on the Remote MCP and cloud tools page ↗. Tool registries​ A tool registry is a collection of tools and is represented by the ToolRegistry class (SDK reference ↗). Tool registries are useful to group frequently used tools together, e.g. you could imagine having a tool registry by function in your organisation. Portia's default tool registry can be accessed by calling DefaultToolRegistry(config=default_config()). from dotenv import load_dotenvfrom portia import ( DefaultToolRegistry, Portia, default_config,)from portia.open_source_tools.calculator_tool import CalculatorToolfrom portia.open_source_tools.search_tool import SearchToolfrom portia.open_source_tools.weather import WeatherToolload_dotenv()# Instantiate a Portia instance. Load it with the example tools and Portia's tools.portia = Portia(tools=DefaultToolRegistry(default_config())) Customizing tool descriptions​ It's often the case that you want to provide custom instructions to Portia agents about how to use a tool, for example, because the author of the MCP tool has missed some context that's important for your usecase, or because you want to personalize the tool in some way. We offer an easy way to edit tool descriptions to do this using the ToolRegistry.with_tool_description function. Consider the below example that personalizes the Linear MCP server with the default team ID: customize_tool_descriptions.pyfrom portia import Config, Portia, PortiaToolRegistryfrom portia.cli import CLIExecutionHooksmy_config = Config.from_default()portia = Portia( config=my_config, tools=PortiaToolRegistry(my_config).with_tool_description( \"portia:mcp:custom:mcp.linear.app:create_issue\", \"If a teamID is not provided, use teamID 123.\"), execution_hooks=CLIExecutionHooks(),) This customization can be used across any tool registry in Portia. Available tools​ When setting up your tool registry, there are four sources of tools you can use: our open-source tools, our Portia cloud tools, your own MCP tool registry and custom code tools. Open source tools​ Portia provides an open source tool registry that contains a selection of general-purpose utility tools. For example, it includes a Tavily tool for web search, an OpenWeatherMap tool for determining weather and a PDF reader tool, among many others. The open source tool registry can be used as follows, though for some of the tools you will need to retrieve an API key first: from portia import open_source_tool_registry, Portiaportia = Portia(tools=open_source_tool_registry) For more details, check out our open-source tool documentation ↗. Portia cloud registry​ Portia cloud provides an extensive tool registry to speed up your agent development, with authentication handled seamlessly by Portia for you. You can select any MCP server with an official remote server implementation from our Tool registry dashboard and connect it to your account. We are rapidly growing our library as providers bring out new remote MCP servers. If you'd like to add a missing or proprietary remote MCP server to your Portia cloud registry and rely on Portia to handle authentication for you, you can do that from the dashboard as well. Finally Portia cloud also includes some in-house-built tools that don't have an official MCP server implementation e.g. Google and Microsoft productivity tools. Your Portia tool registry is available through the PortiaToolRegistry class (SDK reference ↗). This gives access to all the tools you have enabled in your registry: from portia import Portia, PortiaToolRegistryportia = Portia(tools=PortiaToolRegistry()) More details can be found on our Cloud tool registry ↗ page, including how to enable / disable tools within the registry and how to connect in your own remote MCP server. Integrate your own MCP servers [SDK-only option]​ You can easily add any local or remote MCP servers directly into a Portia agent through our McpToolRegistry class. The key difference between integrating an MCP server this way and through the Portia cloud registry is that authentication needs to be handled manually when integrating directly into the Portia instance. The MCP server can be added to your Portia instance as follows, with more details available on our integrating MCP servers ↗ page. from portia import Portia, McpToolRegistrytool_registry = ( # Assumes server is running on port 8000 McpToolRegistry.from_sse_connection( server_name=\"mcp_sse_example_server\", url=\"http://localhost:8000\", ))portia = Portia(tools=tool_registry) Custom tools​ As outlined in the Introduction to tools ↗, it is easy to define your own tools in python code with Portia. In (Adding custom tools ↗), we'll walk through how to do this in more detail by creating our own tool registries with custom tools. Filtering tool registries​ You can create new tool registries from existing ones by filtering tools to your desired subset. For example, you might want to prevent one of your agents from accessing emails in Gmail. This can be done by setting up a filter to exclude the Gmail tools from the registry: from dotenv import load_dotenvfrom portia import ( Portia, PortiaToolRegistry, Tool, default_config,)load_dotenv()def exclude_gmail_filter(tool: Tool) -> bool: return not tool.id.startswith(\"portia:google:gmail:\")registry = PortiaToolRegistry(config=default_config()).filter_tools(exclude_gmail_filter)portia = Portia(tools=registry)Overview of tool integrationTool registriesCustomizing tool descriptionsAvailable toolsOpen source toolsPortia cloud registryIntegrate your own MCP servers [SDK-only option]Custom toolsFiltering tool registries",
      "timestamp": "2025-08-24 06:54:59"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/logger",
      "title": "portia.logger | Portia AI Docs",
      "content": "portia.logger | Portia AI Docs Skip to main contentOn this pageLogging functions for managing and configuring loggers. This module defines functions and classes to manage logging within the application. It provides a LoggerManager class that manages the package-level logger and allows customization. The LoggerInterface defines the general interface for loggers, and the default logger is provided by loguru. The logger function returns the active logger, and the LoggerManager can be used to configure logging behavior. Classes in this file include: LoggerInterface: A protocol defining the common logging methods (debug, info, warning, error, LoggerInterface0). LoggerManager: A class for managing the logger, allowing customization and configuration from the application's settings. This module ensures flexible and configurable logging, supporting both default and custom loggers. LoggerInterface Objects​ class LoggerInterface(Protocol) General Interface for loggers. This interface defines the common methods that any logger should implement. The methods are: debug: For logging debug-level messages. info: For logging informational messages. warning: For logging warning messages. error: For logging error messages. critical: For logging critical error messages. These methods are used throughout the application for logging messages at various levels. Formatter Objects​ class Formatter() A class used to format log records. Attributes​ max_lines : int The maximum number of lines to include in the formatted log message. Methods​ format(record) Formats a log record into a string. __init__​ def __init__() -> None Initialize the logger with default settings. Attributes: max_lines int - The maximum number of lines the logger can handle, default is 30. format​ def format(record: Any) -> str Format a log record into a string with specific formatting. Arguments: record dict - A dictionary containing log record information. Expected keys are \"message\", \"extra\", \"time\", \"level\", \"name\", \"function\", and \"line\". Returns: str - The formatted log record string. _sanitize_message_​ def _sanitize_message_(msg: str, truncate: bool = True) -> str Sanitize a message to be used in a log record. _get_function_color_​ def _get_function_color_(record: Any) -> str Get color based on function/module name. Default is white. SafeLogger Objects​ class SafeLogger(LoggerInterface) A logger that catches exceptions and logs them to the child logger. __init__​ def __init__(child_logger: LoggerInterface) -> None Initialize the SafeLogger. debug​ def debug(msg: str, *args: Any, **kwargs: Any) -> None Wrap the child logger's debug method to catch exceptions. info​ def info(msg: str, *args: Any, **kwargs: Any) -> None Wrap the child logger's info method to catch exceptions. warning​ def warning(msg: str, *args: Any, **kwargs: Any) -> None Wrap the child logger's warning method to catch exceptions. error​ def error(msg: str, *args: Any, **kwargs: Any) -> None Wrap the child logger's error method to catch exceptions. exception​ def exception(msg: str, *args: Any, **kwargs: Any) -> None Wrap the child logger's exception method to catch exceptions. critical​ def critical(msg: str, *args: Any, **kwargs: Any) -> None Wrap the child logger's critical method to catch exceptions. LoggerManager Objects​ class LoggerManager() Manages the package-level logger. The LoggerManager is responsible for initializing and managing the logger used throughout the application. It provides functionality to configure the logger, set a custom logger, and adjust logging settings based on the application's configuration. Arguments: custom_logger LoggerInterface | None - A custom logger to be used. If not provided, the default loguru logger will be used. Attributes: logger LoggerInterface - The current active logger. custom_logger bool - A flag indicating whether a custom logger is in use. Methods: logger - Returns the active logger. set_logger - Sets a custom logger. configure_from_config - Configures the logger based on the provided configuration. __init__​ def __init__(custom_logger: LoggerInterface | None = None) -> None Initialize the LoggerManager. Arguments: custom_logger LoggerInterface | None - A custom logger to use. Defaults to None. logger​ @propertydef logger() -> LoggerInterface Get the current logger. Returns: LoggerInterface - The active logger being used. set_logger​ def set_logger(custom_logger: LoggerInterface) -> None Set a custom logger. Arguments: custom_logger LoggerInterface - The custom logger to be used. configure_from_config​ def configure_from_config(config: Config) -> None Configure the global logger based on the library's configuration. This method configures the logger's log level and output sink based on the application's settings. If a custom logger is in use, it will skip the configuration and log a warning. Arguments: config Config - The configuration object containing the logging settings. logger​ def logger() -> LoggerInterface Return the active logger. Returns: LoggerInterface - The current active logger being used. LoggerInterface ObjectsFormatter ObjectsAttributesMethodsSafeLogger ObjectsLoggerManager Objects",
      "timestamp": "2025-08-24 06:55:02"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/firecrawl",
      "title": "Firecrawl | Portia AI Docs",
      "content": "Firecrawl | Portia AI Docs Skip to main contentOn this page Description​ Integration with FireCrawl to provide advanced web scraping capabilities for extracting structured data from complex websites. Authorisation​ This server does not require any extra authentication to use, other than the MCP server URL. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:55:05"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/map-website",
      "title": "Open Source - Map Website | Portia AI Docs",
      "content": "Open Source - Map Website | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: map_tool Tool description: Maps websites using graph-based traversal that can explore hundreds of paths in parallel with intelligent discovery to generate comprehensive site maps. Provide a URL and the tool will discover and return all accessible pages on that website. Supports depth control, domain filtering, path selection, and various mapping options for comprehensive site reconnaissance and URL discovery. Usage notes: This tool uses the Tavily API. You can sign up to obtain a Tavily API key (↗) and set it in the environment variable TAVILY_API_KEY. Args schema: { \"description\": \"Input for MapTool.\", \"properties\": { \"url\": { \"description\": \"The root URL to begin the mapping (e.g., 'docs.tavily.com')\", \"title\": \"Url\", \"type\": \"string\" }, \"max_depth\": { \"default\": 1, \"description\": \"Max depth of the mapping. Defines how far from the base URL the crawler can explore\", \"title\": \"Max Depth\", \"type\": \"integer\" }, \"max_breadth\": { \"default\": 20, \"description\": \"Max number of links to follow per level of the tree (i.e., per page)\", \"title\": \"Max Breadth\", \"type\": \"integer\" }, \"limit\": { \"default\": 50, \"description\": \"Total number of links the crawler will process before stopping\", \"title\": \"Limit\", \"type\": \"integer\" }, \"instructions\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Natural language instructions for the crawler (e.g., 'Python SDK')\", \"title\": \"Instructions\" }, \"select_paths\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Regex patterns to select only URLs with specific path patterns (e.g., ['/docs/.*', '/api/v1.*'])\", \"title\": \"Select Paths\" }, \"select_domains\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Regex patterns to select crawling to specific domains or subdomains (e.g., ['^docs\\\\.example\\\\.com$'])\", \"title\": \"Select Domains\" }, \"exclude_paths\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Regex patterns to exclude URLs with specific path patterns (e.g., ['/private/.*', '/admin/.*'])\", \"title\": \"Exclude Paths\" }, \"exclude_domains\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Regex patterns to exclude specific domains or subdomains from crawling (e.g., ['^private\\\\.example\\\\.com$'])\", \"title\": \"Exclude Domains\" }, \"allow_external\": { \"default\": false, \"description\": \"Whether to allow following links that go to external domains\", \"title\": \"Allow External\", \"type\": \"boolean\" }, \"categories\": { \"anyOf\": [ { \"items\": { \"type\": \"string\" }, \"type\": \"array\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Filter URLs using predefined categories like 'Documentation', 'Blog', 'API', etc.\", \"title\": \"Categories\" } }, \"required\": [ \"url\" ], \"title\": \"MapToolSchema\", \"type\": \"object\"} Output schema: ('str', 'str: list of discovered URLs on the website')UsageTool details",
      "timestamp": "2025-08-24 06:55:08"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/storage",
      "title": "portia.storage | Portia AI Docs",
      "content": "portia.storage | Portia AI Docs Skip to main contentOn this pageStorage classes for managing the saving and retrieval of plans, runs, and tool calls. This module defines a set of storage classes that provide different backends for saving, retrieving, and managing plans, runs, and tool calls. These storage classes include both in-memory and file-based storage, as well as integration with the Portia Cloud API. Each class is responsible for handling interactions with its respective storage medium, including validating responses and raising appropriate exceptions when necessary. Classes: Storage (Base Class): A base class that defines common interfaces for all storage types, ensuring consistent methods for saving and retrieving plans, runs, and tool calls. InMemoryStorage: An in-memory implementation of the Storage class for storing plans, runs, and tool calls in a temporary, volatile storage medium. FileStorage: A file-based implementation of the Storage class for storing plans, runs, and tool calls as local files in the filesystem. PortiaCloudStorage: A cloud-based implementation of the Storage class that interacts with the Portia Cloud API to save and retrieve plans, runs, and tool call records. Each storage class handles the following tasks: Sending and receiving data to its respective storage medium - memory, file system, or API. Validating responses from storage and raising errors when necessary. Handling exceptions and re-raising them as custom StorageError exceptions to provide more informative error handling. PlanStorage Objects​ class PlanStorage(ABC) Abstract base class for storing and retrieving plans. Subclasses must implement the methods to save and retrieve plans. Methods: save_plan(self, plan: Plan) -> None: Save a plan. get_plan(self, plan_id: PlanUUID) -> Plan: Get a plan by ID. plan_exists(self, plan_id: PlanUUID) -> bool: Check if a plan exists without raising an error. save_plan​ @abstractmethoddef save_plan(plan: Plan) -> None Save a plan. Arguments: plan Plan - The Plan object to save. Raises: NotImplementedError - If the method is not implemented. get_plan​ @abstractmethoddef get_plan(plan_id: PlanUUID) -> Plan Retrieve a plan by its ID. Arguments: plan_id PlanUUID - The UUID of the plan to retrieve. Returns: Plan - The Plan object associated with the provided plan_id. Raises: NotImplementedError - If the method is not implemented. get_plan_by_query​ @abstractmethoddef get_plan_by_query(query: str) -> Plan Get a plan by query. Arguments: query str - The query to get a plan for. plan_exists​ @abstractmethoddef plan_exists(plan_id: PlanUUID) -> bool Check if a plan exists without raising an error. Arguments: plan_id PlanUUID - The UUID of the plan to check. Returns: bool - True if the plan exists, False otherwise. Raises: NotImplementedError - If the method is not implemented. get_similar_plans​ def get_similar_plans(query: str, threshold: float = 0.5, limit: int = 10) -> list[Plan] Get similar plans to the query. Arguments: query str - The query to get similar plans for. threshold float - The threshold for similarity. limit int - The maximum number of plans to return. Returns: list[Plan] - The list of similar plans. Raises: NotImplementedError - If the method is not implemented. asave_plan​ async def asave_plan(plan: Plan) -> None Save a plan asynchronously using threaded execution. Arguments: plan Plan - The Plan object to save. aget_plan​ async def aget_plan(plan_id: PlanUUID) -> Plan Retrieve a plan by its ID asynchronously using threaded execution. Arguments: plan_id PlanUUID - The UUID of the plan to retrieve. Returns: Plan - The Plan object associated with the provided plan_id. aget_plan_by_query​ async def aget_plan_by_query(query: str) -> Plan Get a plan by query asynchronously using threaded execution. Arguments: query str - The query to get a plan for. aplan_exists​ async def aplan_exists(plan_id: PlanUUID) -> bool Check if a plan exists without raising an error asynchronously using threaded execution. Arguments: plan_id PlanUUID - The UUID of the plan to check. Returns: bool - True if the plan exists, False otherwise. aget_similar_plans​ async def aget_similar_plans(query: str, threshold: float = 0.5, limit: int = 10) -> list[Plan] Get similar plans to the query asynchronously using threaded execution. Arguments: query str - The query to get similar plans for. threshold float - The threshold for similarity. limit int - The maximum number of plans to return. Returns: list[Plan] - The list of similar plans. PlanRunListResponse Objects​ class PlanRunListResponse(BaseModel) Response for the get_plan_runs operation. Can support pagination. RunStorage Objects​ class RunStorage(ABC) Abstract base class for storing and retrieving runs. Subclasses must implement the methods to save and retrieve PlanRuns. Methods: save_plan_run(self, run: Run) -> None: Save a PlanRun. get_plan_run(self, plan_run_id: PlanRunUUID) -> PlanRun: Get PlanRun by ID. get_plan_runs(self, run_state: RunState | None = None, page=int | None = None) -> PlanRunListResponse: Return runs that match the given run_state save_plan_run​ @abstractmethoddef save_plan_run(plan_run: PlanRun) -> None Save a PlanRun. Arguments: plan_run PlanRun - The Run object to save. Raises: NotImplementedError - If the method is not implemented. get_plan_run​ @abstractmethoddef get_plan_run(plan_run_id: PlanRunUUID) -> PlanRun Retrieve PlanRun by its ID. Arguments: plan_run_id RunUUID - The UUID of the run to retrieve. Returns: Run - The Run object associated with the provided plan_run_id. Raises: NotImplementedError - If the method is not implemented. get_plan_runs​ @abstractmethoddef get_plan_runs(run_state: PlanRunState | None = None, page: int | None = None) -> PlanRunListResponse List runs by their state. Arguments: run_state RunState | None - Optionally filter runs by their state. page int | None - Optional pagination data Returns: list[Run] - A list of Run objects that match the given state. Raises: NotImplementedError - If the method is not implemented. asave_plan_run​ async def asave_plan_run(plan_run: PlanRun) -> None Save a PlanRun asynchronously using threaded execution. Arguments: plan_run PlanRun - The Run object to save. aget_plan_run​ async def aget_plan_run(plan_run_id: PlanRunUUID) -> PlanRun Retrieve PlanRun by its ID asynchronously using threaded execution. Arguments: plan_run_id RunUUID - The UUID of the run to retrieve. Returns: Run - The Run object associated with the provided plan_run_id. aget_plan_runs​ async def aget_plan_runs(run_state: PlanRunState | None = None, page: int | None = None) -> PlanRunListResponse List runs by their state asynchronously using threaded execution. Arguments: run_state RunState | None - Optionally filter runs by their state. page int | None - Optional pagination data Returns: list[Run] - A list of Run objects that match the given state. AdditionalStorage Objects​ class AdditionalStorage(ABC) Abstract base class for additional storage. Subclasses must implement the methods. Methods: save_tool_call(self, tool_call: ToolCallRecord) -> None: Save a tool_call. save_tool_call​ @abstractmethoddef save_tool_call(tool_call: ToolCallRecord) -> None Save a ToolCall. Arguments: tool_call ToolCallRecord - The ToolCallRecord object to save. Raises: NotImplementedError - If the method is not implemented. save_end_user​ @abstractmethoddef save_end_user(end_user: EndUser) -> EndUser Save an end user. Arguments: end_user EndUser - The EndUser object to save. Raises: NotImplementedError - If the method is not implemented. get_end_user​ @abstractmethoddef get_end_user(external_id: str) -> EndUser | None Get an end user. Arguments: external_id str - The id of the end user to get. Raises: NotImplementedError - If the method is not implemented. asave_tool_call​ async def asave_tool_call(tool_call: ToolCallRecord) -> None Save a tool_call asynchronously using threaded execution. Arguments: tool_call ToolCallRecord - The ToolCallRecord object to save. asave_end_user​ async def asave_end_user(end_user: EndUser) -> EndUser Save an end user asynchronously using threaded execution. Arguments: end_user EndUser - The EndUser object to save. aget_end_user​ async def aget_end_user(external_id: str) -> EndUser | None Get an end user asynchronously using threaded execution. Arguments: external_id str - The id of the end user to get. Storage Objects​ class Storage(PlanStorage, RunStorage, AdditionalStorage) Combined base class for Plan Run + Additional storages. AgentMemory Objects​ class AgentMemory(ABC) Abstract base class for storing items in agent memory. save_plan_run_output​ @abstractmethoddef save_plan_run_output(output_name: str, output: Output, plan_run_id: PlanRunUUID) -> Output Save an output from a plan run to agent memory. Arguments: output_name str - The name of the output within the plan output Output - The Output object to save plan_run_id PlanRunUUID - The ID of the current plan run Returns: Output - The Output object with value marked as stored in agent memory. Raises: NotImplementedError - If the method is not implemented. get_plan_run_output​ @abstractmethoddef get_plan_run_output(output_name: str, plan_run_id: PlanRunUUID) -> LocalDataValue Retrieve an Output from agent memory. Arguments: output_name str - The name of the output to retrieve plan_run_id PlanRunUUID - The ID of the plan run Returns: Output - The retrieved Output object with value filled in from agent memory. Raises: NotImplementedError - If the method is not implemented. asave_plan_run_output​ async def asave_plan_run_output(output_name: str, output: Output, plan_run_id: PlanRunUUID) -> Output Save an output from a plan run to agent memory asynchronously using threaded execution. Arguments: output_name str - The name of the output within the plan output Output - The Output object to save plan_run_id PlanRunUUID - The ID of the current plan run Returns: Output - The Output object with value marked as stored in agent memory. aget_plan_run_output​ async def aget_plan_run_output(output_name: str, plan_run_id: PlanRunUUID) -> LocalDataValue Retrieve an Output from agent memory asynchronously using threaded execution. Arguments: output_name str - The name of the output to retrieve plan_run_id PlanRunUUID - The ID of the plan run Returns: Output - The retrieved Output object with value filled in from agent memory. log_tool_call​ def log_tool_call(tool_call: ToolCallRecord) -> None Log the tool call. Arguments: tool_call ToolCallRecord - The ToolCallRecord object to log. InMemoryStorage Objects​ class InMemoryStorage(PlanStorage, RunStorage, AdditionalStorage, AgentMemory) Simple storage class that keeps plans + runs in memory. Tool Calls are logged via the LogAdditionalStorage. __init__​ def __init__() -> None Initialize Storage. save_plan​ def save_plan(plan: Plan) -> None Add plan to dict. Arguments: plan Plan - The Plan object to save. get_plan​ def get_plan(plan_id: PlanUUID) -> Plan Get plan from dict. Arguments: plan_id PlanUUID - The UUID of the plan to retrieve. Returns: Plan - The Plan object associated with the provided plan_id. Raises: PlanNotFoundError - If the plan is not found. get_plan_by_query​ def get_plan_by_query(query: str) -> Plan Get a plan by query. Arguments: query str - The query to get a plan for. plan_exists​ def plan_exists(plan_id: PlanUUID) -> bool Check if a plan exists in memory. Arguments: plan_id PlanUUID - The UUID of the plan to check. Returns: bool - True if the plan exists, False otherwise. save_plan_run​ def save_plan_run(plan_run: PlanRun) -> None Add run to dict. Arguments: plan_run PlanRun - The Run object to save. get_plan_run​ def get_plan_run(plan_run_id: PlanRunUUID) -> PlanRun Get run from dict. Arguments: plan_run_id PlanRunUUID - The UUID of the PlanRun to retrieve. Returns: PlanRun - The PlanRun object associated with the provided plan_run_id. Raises: PlanRunNotFoundError - If the PlanRun is not found. get_plan_runs​ def get_plan_runs(run_state: PlanRunState | None = None, page: int | None = None) -> PlanRunListResponse Get run from dict. Arguments: run_state RunState | None - Optionally filter runs by their state. page int | None - Optional pagination data which is not used for in memory storage. Returns: list[Run] - A list of Run objects that match the given state. save_plan_run_output​ def save_plan_run_output(output_name: str, output: Output, plan_run_id: PlanRunUUID) -> Output Save Output from a plan run to memory. Arguments: output_name str - The name of the output within the plan output Output - The Output object to save plan_run_id PlanRunUUID - The ID of the current plan run get_plan_run_output​ def get_plan_run_output(output_name: str, plan_run_id: PlanRunUUID) -> LocalDataValue Retrieve an Output from memory. Arguments: output_name str - The name of the output to retrieve plan_run_id PlanRunUUID - The ID of the plan run Returns: Output - The retrieved Output object Raises: KeyError - If the output is not found save_tool_call​ def save_tool_call(tool_call: ToolCallRecord) -> None Log the tool call. save_end_user​ def save_end_user(end_user: EndUser) -> EndUser Add end_user to dict. Arguments: end_user EndUser - The EndUser object to save. get_end_user​ def get_end_user(external_id: str) -> EndUser | None Get end_user from dict or init a new one. Arguments: external_id str - The id of the end user object to get. DiskFileStorage Objects​ class DiskFileStorage(PlanStorage, RunStorage, AdditionalStorage, AgentMemory) Disk-based implementation of the Storage interface. Stores serialized Plan and Run objects as JSON files on disk. __init__​ def __init__(storage_dir: str | None) -> None Set storage dir. Arguments: storage_dir str | None - Optional directory for storing files. save_plan​ def save_plan(plan: Plan) -> None Save a Plan object to the storage. Arguments: plan Plan - The Plan object to save. get_plan​ def get_plan(plan_id: PlanUUID) -> Plan Retrieve a Plan object by its ID. Arguments: plan_id PlanUUID - The ID of the Plan to retrieve. Returns: Plan - The retrieved Plan object. Raises: PlanNotFoundError - If the Plan is not found or validation fails. get_plan_by_query​ def get_plan_by_query(query: str) -> Plan Get a plan by query. This method will return the first plan that matches the query. This is not always the most recent plan. Arguments: query str - The query to get a plan for. plan_exists​ def plan_exists(plan_id: PlanUUID) -> bool Check if a plan exists on disk. Arguments: plan_id PlanUUID - The UUID of the plan to check. Returns: bool - True if the plan exists, False otherwise. save_plan_run​ def save_plan_run(plan_run: PlanRun) -> None Save PlanRun object to the storage. Arguments: plan_run PlanRun - The Run object to save. get_plan_run​ def get_plan_run(plan_run_id: PlanRunUUID) -> PlanRun Retrieve PlanRun object by its ID. Arguments: plan_run_id RunUUID - The ID of the Run to retrieve. Returns: Run - The retrieved Run object. Raises: RunNotFoundError - If the Run is not found or validation fails. get_plan_runs​ def get_plan_runs(run_state: PlanRunState | None = None, page: int | None = None) -> PlanRunListResponse Find all plan runs in storage that match state. Arguments: run_state RunState | None - Optionally filter runs by their state. page int | None - Optional pagination data which is not used for in memory storage. Returns: list[Run] - A list of Run objects that match the given state. save_plan_run_output​ def save_plan_run_output(output_name: str, output: Output, plan_run_id: PlanRunUUID) -> Output Save Output from a plan run to agent memory on disk. Arguments: output_name str - The name of the output within the plan output Output - The Output object to save plan_run_id PlanRunUUID - The ID of the current plan run get_plan_run_output​ def get_plan_run_output(output_name: str, plan_run_id: PlanRunUUID) -> LocalDataValue Retrieve an Output from agent memory on disk. Arguments: output_name str - The name of the output to retrieve plan_run_id PlanRunUUID - The ID of the plan run Returns: Output - The retrieved Output object Raises: FileNotFoundError - If the output file is not found ValidationError - If the deserialization fails save_tool_call​ def save_tool_call(tool_call: ToolCallRecord) -> None Log the tool call. save_end_user​ def save_end_user(end_user: EndUser) -> EndUser Write end_user to dict. Arguments: end_user EndUser - The EndUser object to save. get_end_user​ def get_end_user(external_id: str) -> EndUser | None Get end_user from dict or init a new one. Arguments: external_id str - The id of the end user object to get. PortiaCloudStorage Objects​ class PortiaCloudStorage(Storage, AgentMemory) Save plans, runs and tool calls to portia cloud. __init__​ def __init__(config: Config, cache_dir: str | None = None, max_cache_size: int = DEFAULT_MAX_CACHE_SIZE) -> None Initialize the PortiaCloudStorage instance. Arguments: config Config - The configuration containing API details for Portia Cloud. cache_dir str | None - Optional directory for local caching of outputs. max_cache_size int - The maximum number of files to cache locally. check_response​ def check_response(response: httpx.Response) -> None Validate the response from Portia API. Arguments: response httpx.Response - The response from the Portia API to check. Raises: StorageError - If the response from the Portia API indicates an error. save_plan​ def save_plan(plan: Plan) -> None Save a plan to Portia Cloud. Arguments: plan Plan - The Plan object to save to the cloud. Raises: StorageError - If the request to Portia Cloud fails. asave_plan​ async def asave_plan(plan: Plan) -> None Save a plan to Portia Cloud. Arguments: plan Plan - The Plan object to save to the cloud. Raises: StorageError - If the request to Portia Cloud fails. get_plan​ def get_plan(plan_id: PlanUUID) -> Plan Retrieve a plan from Portia Cloud. Arguments: plan_id PlanUUID - The ID of the plan to retrieve. Returns: Plan - The Plan object retrieved from Portia Cloud. Raises: StorageError - If the request to Portia Cloud fails or the plan does not exist. aget_plan​ async def aget_plan(plan_id: PlanUUID) -> Plan Retrieve a plan from Portia Cloud. Arguments: plan_id PlanUUID - The ID of the plan to retrieve. Returns: Plan - The Plan object retrieved from Portia Cloud. Raises: StorageError - If the request to Portia Cloud fails or the plan does not exist. get_plan_by_query​ def get_plan_by_query(query: str) -> Plan Get a plan by query. Arguments: query str - The query to get a plan for. aget_plan_by_query​ async def aget_plan_by_query(query: str) -> Plan Get a plan by query asynchronously using threaded execution. Arguments: query str - The query to get a plan for. plan_exists​ def plan_exists(plan_id: PlanUUID) -> bool Check if a plan exists in Portia Cloud. Arguments: plan_id PlanUUID - The UUID of the plan to check. Returns: bool - True if the plan exists, False otherwise. aplan_exists​ async def aplan_exists(plan_id: PlanUUID) -> bool Check if a plan exists in Portia Cloud. Arguments: plan_id PlanUUID - The UUID of the plan to check. Returns: bool - True if the plan exists, False otherwise. save_plan_run​ def save_plan_run(plan_run: PlanRun) -> None Save PlanRun to Portia Cloud. Arguments: plan_run PlanRun - The Run object to save to the cloud. Raises: StorageError - If the request to Portia Cloud fails. asave_plan_run​ async def asave_plan_run(plan_run: PlanRun) -> None Save PlanRun to Portia Cloud. Arguments: plan_run PlanRun - The Run object to save to the cloud. Raises: StorageError - If the request to Portia Cloud fails. get_plan_run​ def get_plan_run(plan_run_id: PlanRunUUID) -> PlanRun Retrieve PlanRun from Portia Cloud. Arguments: plan_run_id RunUUID - The ID of the run to retrieve. Returns: Run - The Run object retrieved from Portia Cloud. Raises: StorageError - If the request to Portia Cloud fails or the run does not exist. aget_plan_run​ async def aget_plan_run(plan_run_id: PlanRunUUID) -> PlanRun Retrieve PlanRun from Portia Cloud. Arguments: plan_run_id RunUUID - The ID of the run to retrieve. Returns: Run - The Run object retrieved from Portia Cloud. Raises: StorageError - If the request to Portia Cloud fails or the run does not exist. get_plan_runs​ def get_plan_runs(run_state: PlanRunState | None = None, page: int | None = None) -> PlanRunListResponse Find all runs in storage that match state. Arguments: run_state RunState | None - Optionally filter runs by their state. page int | None - Optional pagination data which is not used for in memory storage. Returns: list[Run] - A list of Run objects retrieved from Portia Cloud. Raises: StorageError - If the request to Portia Cloud fails. aget_plan_runs​ async def aget_plan_runs(run_state: PlanRunState | None = None, page: int | None = None) -> PlanRunListResponse Find all runs in storage that match state. Arguments: run_state RunState | None - Optionally filter runs by their state. page int | None - Optional pagination data which is not used for in memory storage. Returns: list[Run] - A list of Run objects retrieved from Portia Cloud. Raises: StorageError - If the request to Portia Cloud fails. save_tool_call​ def save_tool_call(tool_call: ToolCallRecord) -> None Save a tool call to Portia Cloud. This method attempts to save the tool call to Portia Cloud but will not raise exceptions if the request fails. Instead, it logs the error and continues execution. Arguments: tool_call ToolCallRecord - The ToolCallRecord object to save to the cloud. asave_tool_call​ async def asave_tool_call(tool_call: ToolCallRecord) -> None Save a tool call to Portia Cloud. This method attempts to save the tool call to Portia Cloud but will not raise exceptions if the request fails. Instead, it logs the error and continues execution. Arguments: tool_call ToolCallRecord - The ToolCallRecord object to save to the cloud. save_plan_run_output​ def save_plan_run_output(output_name: str, output: Output, plan_run_id: PlanRunUUID) -> Output Save Output from a plan run to Portia Cloud. Arguments: output_name str - The name of the output within the plan output Output - The Output object to save plan_run_id PlanRun - The if of the current plan run Raises: StorageError - If the request to Portia Cloud fails. asave_plan_run_output​ async def asave_plan_run_output(output_name: str, output: Output, plan_run_id: PlanRunUUID) -> Output Save Output from a plan run to Portia Cloud. Arguments: output_name str - The name of the output within the plan output Output - The Output object to save plan_run_id PlanRun - The if of the current plan run Raises: StorageError - If the request to Portia Cloud fails. get_plan_run_output​ def get_plan_run_output(output_name: str, plan_run_id: PlanRunUUID) -> LocalDataValue Retrieve an Output from Portia Cloud. Arguments: output_name - The name of the output to get from memory plan_run_id RunUUID - The ID of the run to retrieve. Returns: Run - The Run object retrieved from Portia Cloud. Raises: StorageError - If the request to Portia Cloud fails or the run does not exist. aget_plan_run_output​ async def aget_plan_run_output(output_name: str, plan_run_id: PlanRunUUID) -> LocalDataValue Retrieve an Output from Portia Cloud. Arguments: output_name - The name of the output to get from memory plan_run_id RunUUID - The ID of the run to retrieve. Returns: Run - The Run object retrieved from Portia Cloud. Raises: StorageError - If the request to Portia Cloud fails or the run does not exist. get_similar_plans​ def get_similar_plans(query: str, threshold: float = 0.5, limit: int = 5) -> list[Plan] Get similar plans to the query. Arguments: query str - The query to get similar plans for. threshold float - The threshold for similarity. limit int - The maximum number of plans to return. Returns: list[Plan] - The list of similar plans. aget_similar_plans​ async def aget_similar_plans(query: str, threshold: float = 0.5, limit: int = 5) -> list[Plan] Get similar plans to the query. Arguments: query str - The query to get similar plans for. threshold float - The threshold for similarity. limit int - The maximum number of plans to return. Returns: list[Plan] - The list of similar plans. save_end_user​ def save_end_user(end_user: EndUser) -> EndUser Save an end_user to Portia Cloud. Arguments: end_user EndUser - The EndUser object to save to the cloud. Raises: StorageError - If the request to Portia Cloud fails. asave_end_user​ async def asave_end_user(end_user: EndUser) -> EndUser Save an end_user to Portia Cloud. Arguments: end_user EndUser - The EndUser object to save to the cloud. Raises: StorageError - If the request to Portia Cloud fails. get_end_user​ def get_end_user(external_id: str) -> EndUser Retrieve an end user from Portia Cloud. Arguments: external_id str - The ID of the end user to retrieve. Returns: EndUser - The EndUser object retrieved from Portia Cloud. Raises: StorageError - If the request to Portia Cloud fails or the plan does not exist. aget_end_user​ async def aget_end_user(external_id: str) -> EndUser | None Retrieve an end user from Portia Cloud. Arguments: external_id str - The ID of the end user to retrieve. Returns: EndUser - The EndUser object retrieved from Portia Cloud. Raises: StorageError - If the request to Portia Cloud fails or the plan does not exist. PlanStorage ObjectsPlanRunListResponse ObjectsRunStorage ObjectsAdditionalStorage ObjectsStorage ObjectsAgentMemory ObjectsInMemoryStorage ObjectsDiskFileStorage ObjectsPortiaCloudStorage Objects",
      "timestamp": "2025-08-24 06:55:11"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-sheets",
      "title": "Google Sheets Tools | Portia AI Docs",
      "content": "Google Sheets Tools | Portia AI Docs Skip to main content Sheets: Get SpreadsheetGets the content of a spreadsheet from Google Sheets by ID. The GoogleDriveSearchTool should be used to search for a spreadsheet by name if an ID is not known.",
      "timestamp": "2025-08-24 06:55:14"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/create-article-comments",
      "title": "Zendesk - Articles: Create Comments | Portia AI Docs",
      "content": "Zendesk - Articles: Create Comments | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:help_center:create_article_comments Tool description: Create a comment on a zendesk article. Args schema: { \"description\": \"Input schema for ZendeskCreateArticleCommentsTool.\", \"properties\": { \"article_id\": { \"description\": \"The unique ID of the article\", \"title\": \"Article Id\", \"type\": \"integer\" }, \"locale\": { \"description\": \"The locale of the article to post the comment on\", \"title\": \"Locale\", \"type\": \"string\" }, \"comment\": { \"description\": \"The comment to post on the article\", \"title\": \"Comment\", \"type\": \"string\" } }, \"required\": [ \"article_id\", \"locale\", \"comment\" ], \"title\": \"ZendeskCreateArticleCommentsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:55:17"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/clarification_handler",
      "title": "portia.clarification_handler | Portia AI Docs",
      "content": "portia.clarification_handler | Portia AI Docs Skip to main contentOn this pageClarification Handler. This module defines the base ClarificationHandler interface that determines how to handle clarifications that arise during the run of a plan. ClarificationHandler Objects​ class ClarificationHandler(ABC) Handles clarifications that arise during the execution of a plan run. handle​ def handle(clarification: Clarification, on_resolution: Callable[[Clarification, object], None], on_error: Callable[[Clarification, object], None]) -> None Handle a clarification by routing it to the appropriate handler. Arguments: clarification - The clarification object to handle on_resolution - Callback function that should be invoked once the clarification has been handled, prompting the plan run to resume. This can either be called synchronously in this function or called async after returning from this function. The callback takes two arguments: the clarification object and the response to the clarification. on_error - Callback function that should be invoked if the clarification handling has failed. This can either be called synchronously in this function or called async after returning from this function. The callback takes two arguments: the clarification object and the error. handle_action_clarification​ def handle_action_clarification( clarification: ActionClarification, on_resolution: Callable[[Clarification, object], None], on_error: Callable[[Clarification, object], None]) -> None Handle an action clarification. handle_input_clarification​ def handle_input_clarification( clarification: InputClarification, on_resolution: Callable[[Clarification, object], None], on_error: Callable[[Clarification, object], None]) -> None Handle a user input clarification. handle_multiple_choice_clarification​ def handle_multiple_choice_clarification( clarification: MultipleChoiceClarification, on_resolution: Callable[[Clarification, object], None], on_error: Callable[[Clarification, object], None]) -> None Handle a multi-choice clarification. handle_value_confirmation_clarification​ def handle_value_confirmation_clarification( clarification: ValueConfirmationClarification, on_resolution: Callable[[Clarification, object], None], on_error: Callable[[Clarification, object], None]) -> None Handle a value confirmation clarification. handle_user_verification_clarification​ def handle_user_verification_clarification( clarification: UserVerificationClarification, on_resolution: Callable[[Clarification, object], None], on_error: Callable[[Clarification, object], None]) -> None Handle a user verification clarification. handle_custom_clarification​ def handle_custom_clarification( clarification: CustomClarification, on_resolution: Callable[[Clarification, object], None], on_error: Callable[[Clarification, object], None]) -> None Handle a custom clarification.ClarificationHandler Objects",
      "timestamp": "2025-08-24 06:55:20"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/calculator_tool",
      "title": "portia.open_source_tools.calculator_tool | Portia AI Docs",
      "content": "portia.open_source_tools.calculator_tool | Portia AI Docs Skip to main contentOn this pageSimple Calculator Implementation. safe_eval​ def safe_eval(node: Any) -> Any Walk expression safely. safe_evaluate​ def safe_evaluate(expression: str) -> float Use ast.safe_eval to evaluate expression. CalculatorToolSchema Objects​ class CalculatorToolSchema(BaseModel) Input for the CalculatorTool. CalculatorTool Objects​ class CalculatorTool(Tool[float]) Takes a basic maths question in natural language and returns the result. Works best for maths expressions containing only numbers and the operators +, -, *, x, /. run​ def run(_: ToolRunContext, math_question: str) -> float Run the CalculatorTool. math_expression​ def math_expression(prompt: str) -> str Convert words and phrases to standard operators.CalculatorToolSchema ObjectsCalculatorTool Objects",
      "timestamp": "2025-08-24 06:55:23"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/",
      "title": "Microsoft Outlook Tools | Portia AI Docs",
      "content": "Microsoft Outlook Tools | Portia AI Docs Skip to main content Outlook: DraftDrafts an email for the recipients indicated. Should not be used with the send email tool. Instead to send a draft email use the send_draft_email_tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Outlook: SearchSearches for emails in the user's Outlook inbox and returns emails content that match the query. Outlook: SendSends an email to the recipients indicated. Should not be used with the draft email tool. Instead to send a draft email use the send_draft_email_tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Outlook: Send DraftSends a previously drafted email with the email title, body and recipients indicated in the draft. Requires a draft id which is obtained from the DraftEmailTool. Only use this tool if you actually want to send an email, not if the user just wants to draft an email.",
      "timestamp": "2025-08-24 06:55:26"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/bright-data",
      "title": "Bright Data | Portia AI Docs",
      "content": "Bright Data | Portia AI Docs Skip to main contentOn this page Description​ Integrates with Bright Data's web scraping infrastructure to provide real-time access to public web data through specialized tools for search engine scraping, webpage extraction, and structured data retrieval from popular websites. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"Bright Data\", command=\"npx\", args=[\"@brightdata/mcp\"], env={\"API_TOKEN\": \"<api_token>\"},) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"Bright Data\", command=\"npx\", args=[\"@brightdata/mcp\"], env={\"API_TOKEN\": \"<api_token>\"},) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:55:29"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/find-message",
      "title": "Slack - Message: Find | Portia AI Docs",
      "content": "Slack - Message: Find | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Slack tools with Portia AI​ You will need to create your own Slack App to use with Portia AI. This is so you can control the name and appearance of slack bot activity initiated via the Portia AI framework. Once your slack app is created you can configure your client ID and secret in the Portia dashboard. Install a Slack app​ Head over to api.slack.com/apps ↗ Create an app from scratch and select the Slack workplace you would like to use it in. Note down the client ID and secret on the Basic Information page. We will need this in a couple of steps from now! In the OAuth & Permissions tab further down in the left hand nav, add as Redirect URL the following URL https://api.portialabs.ai/api/v0/oauth/slack (don't forget to hit that Save URLs button!). Under Bot Token Scopes, be sure to add the scopes channels:history -- View messages and other content in public channels that your Slack app has been added to. channels:read -- View basic information about public channels in a workspace. chat:write -- Send messages as @{your slack app name}. users:read -- View people in a workspace. Under User Token Scopes, be sure to add the scope search:read to support searching workplace content. Now scroll up to the top of the OAuth & Permissions page and hit the Install to {your workplace name} button. Once that is done, open your Slack app and hit 'Add apps` and be sure to select your new app. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the client ID and secret of your Slack app as collected in step 3 of the Slack installation process above. You are now ready to call Slack tools on our cloud! Tool details​ Tool ID: portia:slack:user:find_message Tool description: Search for a message in a Slack channel or chat. Args schema: { \"description\": \"Input for FindMessageTool.\", \"properties\": { \"target\": { \"description\": \"Slack channel ID (e.g. C084F1FSTFC), channel name (e.g. #slack-tool-testing)or user name (e.g. @tom) that the messages were sent to.\", \"title\": \"Target\", \"type\": \"string\" }, \"query\": { \"default\": \"\", \"description\": \"When using the Slack Find Message tool to search for messages you have to adhere to the query string structure of slack strictly. In addition to whatever keywords are relevant from the user's prompt, follow the guidelines below to build the query string and never ever add anything other than that. To look for messages from a specific user you have to refer to their slack user name using @ in the query string like so: 'from:@UserName' e.g. 'from:@nathan' to get messages from nathan. To look for messages sent to me or someone else you have to refer to their Slack username using @ in the query string like so: 'to:@UserName' e.g. 'to:@mounir'. Next, and this should ONLY be used if the user is asking about messages in a specific channel, to look for messages in a specific channel you have to insert 'in:ChannelName' in the query string e.g. 'in:social'\", \"title\": \"Query\", \"type\": \"string\" } }, \"required\": [ \"target\" ], \"title\": \"FindSlackMessageToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Output of the messages found')UsageConfigure your Slack tools with Portia AIInstall a Slack appConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:55:32"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/jetbrains-ide",
      "title": "JetBrains IDE | Portia AI Docs",
      "content": "JetBrains IDE | Portia AI Docs Skip to main contentOn this page Description​ Interact with JetBrains IDEs for code analysis and development tasks. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ This server does not require any extra authentication to use. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"jetbrains\", command=\"npx\", args=[\"-y\", \"@jetbrains/mcp-proxy\"],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"jetbrains\", command=\"npx\", args=[\"-y\", \"@jetbrains/mcp-proxy\"],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:55:36"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar",
      "title": "Google Calendar Tools | Portia AI Docs",
      "content": "Google Calendar Tools | Portia AI Docs Skip to main content Calendar: Check AvailabilityChecks the availability of this authenticated user for a given time range. DO NOT use this to validate availability of people the user wants to meet with. DO NOT use this unless the user specifically asks for availability checking, e.g by saying 'find when I am free', or 'check my availability'. Either the day, end_time, or start_time must be provided. Pay close attention to the task if it says 'before' or 'after'. Calendar: Create EventCreates a Google Calendar event. DO NOT call portia:google:gcalendar:check_availability before using this tool, unless the user explicitly asks you to check their availability. Calendar: Delete EventDeletes the Google Calendar event associated with the ID. Calendar: Get EventGets Google Calendar event using an event ID. Calendar: Get Events By PropertiesGets Google Calendar events by properties, returning the matching event details. You do not need to provide all the properties, only the ones you have provided with. Calendar: Modify EventModifies an existing Google Calendar event. You must provide the event ID to modify, and can optionally provide new values if desired for the title, start time, end time, description, and attendees.",
      "timestamp": "2025-08-24 06:55:39"
    },
    {
      "url": "https://docs.portialabs.ai/examples/redoc/",
      "title": "Portia AI Docs",
      "content": "Portia AI Docs",
      "timestamp": "2025-08-24 06:55:39"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/extract_tool",
      "title": "portia.open_source_tools.extract_tool | Portia AI Docs",
      "content": "portia.open_source_tools.extract_tool | Portia AI Docs Skip to main contentOn this pageTool to extract web page content from one or more URLs. ExtractToolSchema Objects​ class ExtractToolSchema(BaseModel) Input for ExtractTool. ExtractTool Objects​ class ExtractTool(Tool[str]) Extracts the web page content from one or more URLs provided. run​ def run(_: ToolRunContext, urls: list[str], include_images: bool = True, include_favicon: bool = True, extract_depth: str = \"basic\", format: str = \"markdown\") -> str Run the extract tool.ExtractToolSchema ObjectsExtractTool Objects",
      "timestamp": "2025-08-24 06:55:42"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/invideo",
      "title": "Invideo | Portia AI Docs",
      "content": "Invideo | Portia AI Docs Skip to main contentOn this page Description​ Lets agents script end-to-end video creation: writing scripts, fetching stock media, generating clips and subtitling. Authorisation​ This server does not require any extra authentication to use, other than the MCP server URL. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:55:45"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/pdf_reader_tool",
      "title": "portia.open_source_tools.pdf_reader_tool | Portia AI Docs",
      "content": "portia.open_source_tools.pdf_reader_tool | Portia AI Docs Skip to main contentOn this pageTool for reading PDF files and extracting text content using Mistral OCR. PDFReaderToolSchema Objects​ class PDFReaderToolSchema(BaseModel) Input for PDFReaderTool. PDFReaderTool Objects​ class PDFReaderTool(Tool[str]) Read a PDF file and extract its text content using Mistral OCR. run​ def run(_: ToolRunContext, file_path: str) -> str Run the PDFReaderTool.PDFReaderToolSchema ObjectsPDFReaderTool Objects",
      "timestamp": "2025-08-24 06:55:48"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-article-comments",
      "title": "Zendesk - Articles: List Comments | Portia AI Docs",
      "content": "Zendesk - Articles: List Comments | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:help_center:list_article_comments Tool description: Returns up to 100 comments made by all users on a specific article. Args schema: { \"description\": \"Input schema for ZendeskListArticleCommentsTool.\", \"properties\": { \"article_id\": { \"description\": \"The unique ID of the article\", \"title\": \"Article Id\", \"type\": \"integer\" } }, \"required\": [ \"article_id\" ], \"title\": \"ZendeskListArticleCommentsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:55:51"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack",
      "title": "Slack Tools | Portia AI Docs",
      "content": "Slack Tools | Portia AI Docs Skip to main content Conversation: Get HistoryGet the conversation history for a given channel by channel id. Requires an ID typically from the list_conversation_ids tool. Conversation: ListList all conversations meta information only without comments in the slack workspaceThis tool should be used when you need to make api calls to other slack apis that requirea conversation or channel id. DOES NOT RETURN MESSAGES, CONVERSATION HISTORY, OR USER IDS. Message: FindSearch for a message in a Slack channel or chat. Message: SendSend a message to a specific Slack channel or user by ID. Requires an ID provided by other tools. Users: ListList all users in the slack workspace. Returns user meta information: Name, ID, and EmailThis tool should be used when you need to make api calls to other slack apis that requirea user ID.",
      "timestamp": "2025-08-24 06:55:54"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/tool_registry",
      "title": "portia.tool_registry | Portia AI Docs",
      "content": "portia.tool_registry | Portia AI Docs Skip to main contentOn this pageA ToolRegistry represents a source of tools. This module defines various implementations of ToolRegistry, which is responsible for managing and interacting with tools. It provides interfaces for registering, retrieving, and listing tools. The ToolRegistry can also support aggregation of multiple registries and searching for tools based on queries. Classes: ToolRegistry: The base interface for managing tools. AggregatedToolRegistry: A registry that aggregates multiple tool registries. InMemoryToolRegistry: A simple in-memory implementation of ToolRegistry. PortiaToolRegistry: A tool registry that interacts with the Portia API to manage tools. MCPToolRegistry: A tool registry that interacts with a locally running MCP server. ToolRegistry Objects​ class ToolRegistry() ToolRegistry is the base class for managing tools. This class implements the essential methods for interacting with tool registries, including registering, retrieving, and listing tools. Specific tool registries can override these methods and provide additional functionality. Methods: with_tool(tool - Tool, *, overwrite: bool = False) -> None: Inserts a new tool. replace_tool(tool - Tool) -> None: Replaces a tool with a new tool in the current registry. NB. This is a shortcut for with_tool(tool, overwrite=True). get_tool(tool_id - str) -> Tool: Retrieves a tool by its ID. get_tools() -> list[Tool]: Retrieves all tools in the registry. match_tools(query - str | None = None, tool_ids: list[str] | None = None) -> list[Tool]: Optionally, retrieve tools that match a given query and tool_ids. filter_tools(predicate - Callable[[Tool], bool]) -> ToolRegistry: Create a new tool registry with only the tools that match the predicate. Useful to implement tool exclusions. with_tool_description( tool_id - str, updated_description - str, *, overwrite - bool = False, ) -> ToolRegistry: Extend or override the description of a tool in the registry. __init__​ def __init__(tools: dict[str, Tool] | Sequence[Tool] | None = None) -> None Initialize the tool registry with a sequence or dictionary of tools. Arguments: tools dict[str, Tool] | Sequence[Tool] - A sequence of tools or a dictionary of tool IDs to tools. with_tool​ def with_tool(tool: Tool, *, overwrite: bool = False) -> None Update a tool based on tool ID or inserts a new tool. Arguments: tool Tool - The tool to be added or updated. overwrite bool - Whether to overwrite an existing tool with the same ID. Returns: None - The tool registry is updated in place. replace_tool​ def replace_tool(tool: Tool) -> None Replace a tool with a new tool. Arguments: tool Tool - The tool to replace the existing tool with. Returns: None - The tool registry is updated in place. get_tool​ def get_tool(tool_id: str) -> Tool Retrieve a tool's information. Arguments: tool_id str - The ID of the tool to retrieve. Returns: Tool - The requested tool. Raises: ToolNotFoundError - If the tool with the given ID does not exist. get_tools​ def get_tools() -> list[Tool] Get all tools registered with the registry. Returns: list[Tool] - A list of all tools in the registry. match_tools​ def match_tools(query: str | None = None, tool_ids: list[str] | None = None) -> list[Tool] Provide a set of tools that match a given query and tool_ids. Arguments: query str | None - The query to match tools against. tool_ids list[str] | None - The list of tool ids to match. Returns: list[Tool] - A list of tools matching the query. This method is useful to implement tool filtering whereby only a selection of tools are passed to the PlanningAgent based on the query. This method is optional to implement and will default to providing all tools. filter_tools​ def filter_tools(predicate: Callable[[Tool], bool]) -> ToolRegistry Filter the tools in the registry based on a predicate. Arguments: predicate Callable[[Tool], bool] - A predicate to filter the tools. Returns: Self - A new ToolRegistry with the filtered tools. with_tool_description​ def with_tool_description(tool_id: str, updated_description: str, *, overwrite: bool = False) -> ToolRegistry Update a tool with an extension or override of the tool description. Arguments: tool_id str - The id of the tool to update. updated_description str - The tool description to update. If overwrite is False, this will extend the existing tool description, otherwise, the entire tool description will be updated. overwrite bool - Whether to update or extend the existing tool description. Returns: Self - The tool registry is updated in place and returned. Particularly useful for customising tools in MCP servers for usecases. A deep copy is made of the underlying tool such that the tool description is only updated within this registry. Logs a warning if the tool is not found. __add__​ def __add__(other: ToolRegistry | list[Tool]) -> ToolRegistry Return an aggregated tool registry combining two registries or a registry and tool list. Tool IDs must be unique across the two registries otherwise an error will be thrown. Arguments: other ToolRegistry - Another tool registry to be combined. Returns: AggregatedToolRegistry - A new tool registry containing tools from both registries. __radd__​ def __radd__(other: ToolRegistry | list[Tool]) -> ToolRegistry Return an aggregated tool registry combining two registries or a registry and tool list. Tool IDs must be unique across the two registries otherwise an error will be thrown. Arguments: other ToolRegistry - Another tool registry to be combined. Returns: ToolRegistry - A new tool registry containing tools from both registries. __iter__​ def __iter__() -> Iterator[Tool] Iterate over the tools in the registry. __len__​ def __len__() -> int Return the number of tools in the registry. __contains__​ def __contains__(tool_id: str) -> bool Check if a tool is in the registry. InMemoryToolRegistry Objects​ class InMemoryToolRegistry(ToolRegistry) Provides a simple in-memory tool registry. This class stores tools in memory, allowing for quick access without persistence. Warning: This registry is DEPRECATED. Use ToolRegistry instead. from_local_tools​ @classmethoddef from_local_tools(cls, tools: Sequence[Tool]) -> InMemoryToolRegistry Easily create a local tool registry from a sequence of tools. Arguments: tools Sequence[Tool] - A sequence of tools to initialize the registry. Returns: InMemoryToolRegistry - A new in-memory tool registry. PortiaToolRegistry Objects​ class PortiaToolRegistry(ToolRegistry) Provides access to Portia tools. This class interacts with the Portia API to retrieve and manage tools. __init__​ def __init__(config: Config | None = None, client: httpx.Client | None = None, tools: dict[str, Tool] | Sequence[Tool] | None = None) -> None Initialize the PortiaToolRegistry with the given configuration. Arguments: config Config | None - The configuration containing the API key and endpoint. client httpx.Client | None - An optional httpx client to use. If not provided, a new client will be created. tools dict[str, Tool] | None - A dictionary of tool IDs to tools to create the registry with. If not provided, all tools will be loaded from the Portia API. with_default_tool_filter​ def with_default_tool_filter() -> PortiaToolRegistry Create a PortiaToolRegistry with a default tool filter. McpToolRegistry Objects​ class McpToolRegistry(ToolRegistry) Provides access to tools within a Model Context Protocol (MCP) server. See https://modelcontextprotocol.io/introduction for more information on MCP. from_sse_connection​ @classmethoddef from_sse_connection( cls, server_name: str, url: str, headers: dict[str, Any] | None = None, timeout: float = 5, sse_read_timeout: float = 60 * 5, tool_list_read_timeout: float | None = None, tool_call_timeout_seconds: float | None = None) -> McpToolRegistry Create a new MCPToolRegistry using an SSE connection (Sync version). from_sse_connection_async​ @classmethodasync def from_sse_connection_async( cls, server_name: str, url: str, headers: dict[str, Any] | None = None, timeout: float = 5, sse_read_timeout: float = 60 * 5, tool_list_read_timeout: float | None = None, tool_call_timeout_seconds: float | None = None) -> McpToolRegistry Create a new MCPToolRegistry using an SSE connection (Async version). from_stdio_connection​ @classmethoddef from_stdio_connection( cls, server_name: str, command: str, args: list[str] | None = None, env: dict[str, str] | None = None, encoding: str = \"utf-8\", encoding_error_handler: Literal[\"strict\", \"ignore\", \"replace\"] = \"strict\", tool_list_read_timeout: float | None = None, tool_call_timeout_seconds: float | None = None) -> McpToolRegistry Create a new MCPToolRegistry using a stdio connection (Sync version). from_stdio_connection_raw​ @classmethoddef from_stdio_connection_raw( cls, config: str | dict[str, Any], tool_list_read_timeout: float | None = None, tool_call_timeout_seconds: float | None = None) -> McpToolRegistry Create a new MCPToolRegistry using a stdio connection from a string. Parses commonly used mcp client config formats. Arguments: config - The string or dict to parse. tool_list_read_timeout - The timeout for the request. tool_call_timeout_seconds - The timeout for the tool call. Returns: A McpToolRegistry. from_stdio_connection_async​ @classmethodasync def from_stdio_connection_async( cls, server_name: str, command: str, args: list[str] | None = None, env: dict[str, str] | None = None, encoding: str = \"utf-8\", encoding_error_handler: Literal[\"strict\", \"ignore\", \"replace\"] = \"strict\", tool_list_read_timeout: float | None = None, tool_call_timeout_seconds: float | None = None) -> McpToolRegistry Create a new MCPToolRegistry using a stdio connection (Async version). from_streamable_http_connection​ @classmethoddef from_streamable_http_connection( cls, server_name: str, url: str, headers: dict[str, Any] | None = None, timeout: float = 30, sse_read_timeout: float = 60 * 5, *, terminate_on_close: bool = True, auth: httpx.Auth | None = None, tool_list_read_timeout: float | None = None, tool_call_timeout_seconds: float | None = None) -> McpToolRegistry Create a new MCPToolRegistry using a StreamableHTTP connection (Sync version). from_streamable_http_connection_async​ @classmethodasync def from_streamable_http_connection_async( cls, server_name: str, url: str, headers: dict[str, Any] | None = None, timeout: float = 30, sse_read_timeout: float = 60 * 5, *, terminate_on_close: bool = True, auth: httpx.Auth | None = None, tool_list_read_timeout: float | None = None, tool_call_timeout_seconds: float | None = None) -> McpToolRegistry Create a new MCPToolRegistry using a StreamableHTTP connection (Async version). DefaultToolRegistry Objects​ class DefaultToolRegistry(ToolRegistry) A registry providing a default set of tools. This includes the following tools: All open source tools that don't require API keys Search, map, extract, and crawl tools if you have a Tavily API key Weather tool if you have an OpenWeatherMap API key Portia cloud tools if you have a Portia cloud API key __init__​ def __init__(config: Config) -> None Initialize the default tool registry with the given configuration. GeneratedBaseModel Objects​ class GeneratedBaseModel(BaseModel) BaseModel that is generated from a JSON schema. Handles serialization of fields that must omit None values: fields that are not required in the JSON schema, but that are not nullable. Pydantic has no concept of an omissible field, so we must for it to be nullable and then make sure we don't serialize None values. __init_subclass__​ def __init_subclass__(cls) -> None Ensure omissible fields are isolated between models. serialize​ @model_serializer(mode=\"wrap\")def serialize(handler: SerializerFunctionWrapHandler) -> dict[str, Any] Serialize the model to a dictionary, excluding fields for which we must omit None. extend_exclude_unset_fields​ @classmethoddef extend_exclude_unset_fields(cls, fields: list[str]) -> None Extend the list of fields to exclude from serialization. generate_pydantic_model_from_json_schema​ def generate_pydantic_model_from_json_schema( model_name: str, json_schema: dict[str, Any]) -> type[BaseModel] Generate a Pydantic model based on a JSON schema. Arguments: model_name str - The name of the Pydantic model. json_schema dict[str, Any] - The schema to generate the model from. Returns: type[BaseModel] - The generated Pydantic model class. ToolRegistry ObjectsInMemoryToolRegistry ObjectsPortiaToolRegistry ObjectsMcpToolRegistry ObjectsDefaultToolRegistry ObjectsGeneratedBaseModel Objects",
      "timestamp": "2025-08-24 06:55:57"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/llm_tool",
      "title": "portia.open_source_tools.llm_tool | Portia AI Docs",
      "content": "portia.open_source_tools.llm_tool | Portia AI Docs Skip to main contentOn this pageTool for responding to prompts and completing tasks that don't require other tools. LLMToolSchema Objects​ class LLMToolSchema(BaseModel) Input for LLM Tool. LLMTool Objects​ class LLMTool(Tool[str | BaseModel]) General purpose LLM tool. Customizable to user requirements. Won't call other tools. process_task_data​ @staticmethoddef process_task_data(task_data: list[Any] | str | None) -> str Process task_data into a string, handling different input types. Arguments: task_data - Data that can be a None, a string or a list of objects. Returns: A string representation of the data, with list items joined by newlines. run​ def run(ctx: ToolRunContext, task: str, task_data: list[Any] | str | None = None) -> str | BaseModel Run the LLMTool. arun​ async def arun(ctx: ToolRunContext, task: str, task_data: list[Any] | str | None = None) -> str | BaseModel Run the LLMTool asynchronously.LLMToolSchema ObjectsLLMTool Objects",
      "timestamp": "2025-08-24 06:56:00"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/cloud",
      "title": "portia.cloud | Portia AI Docs",
      "content": "portia.cloud | Portia AI Docs Skip to main contentOn this pageCore client for interacting with portia cloud. PortiaCloudClient Objects​ class PortiaCloudClient() Base HTTP client builder for interacting with portia cloud. __init__​ def __init__(config: Config) -> None Initialize the PortiaCloudClient instance. Arguments: config Config - The Portia Configuration instance, containing the API key and endpoint. PortiaCloudClient Objects",
      "timestamp": "2025-08-24 06:56:03"
    },
    {
      "url": "https://docs.portialabs.ai/security",
      "title": "Portia cloud security | Portia AI Docs",
      "content": "Portia cloud security | Portia AI Docs Skip to main contentOn this page Understanding the security of your agentic system is critical to deploying agents in production. Portia uses production-grade security and encryption and offers granular customization of security policies to ensure your data is secure within our systems. OAuth token handling All OAuth tokens provided to Portia from third parties are securely encrypted within the application using a unique Google KMS key per organization. No internal staff member can view decrypted token data. Once a token is expired or consumed (depending on the retention policy - see below) it is deleted from all Portia systems. OAuth token retention Additionally, you can control how long Portia retains these OAuth tokens for. Within the org settings tab in the dashboard you can update your organization retention policy to one of the below options. Default​ Under the default policy, Portia will store the encrypted token until it expires. We will also store any refresh tokens provided by the third party if they support this. This retention policy is best for usability as it minimizes the number of times users will need to go through the OAuth authentication flow. No refresh​ Under the No Refresh policy, Portia will store the encrypted tokens until they expire. However no refresh tokens will be stored. This policy offers a blend of security and usability, with tokens being stored for a far shorter length of time (usually 24 hours though it depends on the third party).DefaultNo refresh",
      "timestamp": "2025-08-24 06:56:07"
    },
    {
      "url": "https://docs.portialabs.ai/evals-steel-thread",
      "title": "Evals and SteelThread | Portia AI Docs",
      "content": "Evals and SteelThread | Portia AI Docs Skip to main content📄️ Introducing Steel ThreadSteel Thread is a lightweight, extensible framework for evaluating LLM agents — designed to help teams measure quality, catch regressions, and improve performance with minimal friction.📄️ Install and quickstartSteelThread relies on access to agent activity in Portia cloud (queries, plans, plan runs). You will need a PORTIAAPIKEY to get started. Head over to (app.portialabs.ai ↗) and navigate to the Manage API keys tab from the left hand nav. There you can generate a new API key.🗃️ 🌊 Streams3 items🗃️ 📈 Evals4 items📄️ Custom backendsSteelThread is designed to allow for metrics to be pushed to other sinks, simply by implementing the correct metrics backend and passing it as config.",
      "timestamp": "2025-08-24 06:56:10"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/image_understanding_tool",
      "title": "portia.open_source_tools.image_understanding_tool | Portia AI Docs",
      "content": "portia.open_source_tools.image_understanding_tool | Portia AI Docs Skip to main contentOn this pageTool for responding to prompts and completing tasks that are related to image understanding. ImageUnderstandingToolSchema Objects​ class ImageUnderstandingToolSchema(BaseModel) Input for Image Understanding Tool. check_image_url_or_file​ @model_validator(mode=\"after\")def check_image_url_or_file() -> Self Check that only one of image_url or image_file is provided. ImageUnderstandingTool Objects​ class ImageUnderstandingTool(Tool[str]) General purpose image understanding tool. Customizable to user requirements. run​ def run(ctx: ToolRunContext, **kwargs: Any) -> str Run the ImageTool.ImageUnderstandingToolSchema ObjectsImageUnderstandingTool Objects",
      "timestamp": "2025-08-24 06:56:13"
    },
    {
      "url": "https://docs.portialabs.ai/manage-end-users",
      "title": "Managing end users | Portia AI Docs",
      "content": "Managing end users | Portia AI Docs Skip to main contentOn this page Whilst building an agent for yourself can be very rewarding most agentic use cases run for many users. For example you may be an engineer creating a new agent for all the staff in your business. It may be important for the agent to know information about the specific member of staff that the agent is running for. Imagine a query like \"Send me a summary of the latest results\". This requires information about who the \"me\" is. Portia has been built from the ground up for production deployments and so has a first class representation of your users within Portia. We call these entities end users, the people or companies that you are running agentic workflows for. TL;DRThe EndUser class can be used to represent your users within Portia. The external_id field in an EndUser object uniquely represents the end user in your system e.g. an internal ID or an email address. names, emails and phone_numbers can all be stored against this object. They can dynamically be updated in tools with changes made to end_user models being persisted in storage. additional_data can be used to pass user specific info that may be relevant to the response such as title and department. Authentication is tied to the end user you use when executing a plan_run. This allows us to re-use Oauth tokens (subject to your token retention policy) improving user experience. Important If you don't provide an end_user the system will generate an end_user to represent you as the developer. This is useful if you're building a system with only one user. You'll see this represented as users with the prefix portia::. End users at Portia​ In Production, you will be running plans for many stakeholders including customers, employees and partners. You may want to pass information specific to these individuals when they submit a prompt and / or information specific to the current context they are operating in (e.g. the particular app they are using when they submit their prompt to initiate a plan run). We refer to these \"person\" entities as end users and represent them through the EndUser model. You can pass either a string or a full EndUser to the plan + run endpoints. The string or external ID can be any value that uniquely represents the end user in your system e.g. an internal ID or an email address. Alongside the end_user_id you can also provide a set of additional attributes in the additional_data field. Pass the EndUser to the plan run​ main.pyfrom dotenv import load_dotenvfrom portia import ( Portia, default_config, example_tool_registry,)from portia.end_user import EndUserload_dotenv()portia = Portia(tools=example_tool_registry)# We can provide it as a stringplan_run = portia.run( \"Get the temperature in Svalbard and write me a personalized greeting with the result.\", end_user=\"my_user_id_123\")# Or provide additional information through the model:plan_run = portia.run( \"Get the temperature in Svalbard and write me a personalized greeting with the result.\", end_user=EndUser(external_id=\"my_user_id_123\", name=\"Nicholas of Patara\"))print(plan_run.model_dump_json(indent=2)) The result of this code block will be the addition of an end_user_id within the PlanRun state, and a final_output that is indeed personalised to Saint Nicholas (known by his stage name Santa Claus): plan_run_state.json{ \"id\": \"prun-d9991518-92d7-447f-bf28-4f7b9b8110ce\", \"plan_id\": \"plan-4f497c60-c33e-40ea-95b4-cd2054559fff\", \"current_step_index\": 1, \"clarifications\": [], \"state\": \"COMPLETE\", \"end_user_id\": \"DemoUser123\", \"step_outputs\": { \"$svalbard_temperature\": { \"value\": \"The current weather in Svalbard is light snow with a temperature of -11.53°C.\" }, \"$personalized_greeting\": { \"value\": \"Hello Nicholas of Patara, I hope you are keeping warm. With the current weather in Svalbard showing light snow and a temperature of -11.53°C, make sure to bundle up and stay cozy!\" } }, \"final_output\": { \"value\": \"Hello Nicholas of Patara, I hope you are keeping warm. With the current weather in Svalbard showing light snow and a temperature of -11.53°C, make sure to bundle up and stay cozy!\" }} Accessing end users in a tool​ End User objects are passed through to the tool run function as part of the ToolRunContext. This allows you to access attributes for your users in tools. You can also update attributes in tools, which will be persisted to storage upon completion of the tool call. This provides a way of storing useful data about the user. main.pyfrom pydantic import BaseModel, Fieldfrom portia.tool import Tool, ToolRunContextclass EndUserUpdateToolSchema(BaseModel): \"\"\"Input for EndUserUpdateTool.\"\"\" name: str | None = Field(default=None, description=\"The new name for the end user.\")class EndUserUpdateTool(Tool): \"\"\"Updates the name of the plan runs end user.\"\"\" id: str = \"end_user_update\" name: str = \"End User Update Tool\" description: str = \"Updates the name of the end user\" args_schema: type[BaseModel] = EndUserUpdateToolSchema output_schema: tuple[str, str] = (\"str\", \"str: The new name\") def run(self, ctx: ToolRunContext, name: str) -> str: \"\"\"Change the name.\"\"\" ctx.end_user.name = name ctx.end_user.set_attribute(\"has_name_update\", \"true\") return name End user state management​ As we mentioned above End Users are first class citizens in the Portia Ecosystem. This means they are independent entities with their own state. Changes you make to them are persisted in storage and we refresh the state before commencing plan_runs. This is particularly relevant for the additional_data field on the End User. This field allows you to store any additional data you like against users. This can either be done through the cloud interface, by providing it when running a plan, or by updating it in a tool. main.pyfrom dotenv import load_dotenvfrom portia import ( Portia, default_config, example_tool_registry,)from portia.end_user import EndUserload_dotenv()portia = Portia(tools=example_tool_registry)plan_run = portia.run( \"Get the temperature in Svalbard and write me a personalized greeting with the result.\", end_user=EndUser(external_id=\"my_user_id_123\", name=\"Nicholas of Patara\", additional_data={\"weather_preferences\": \"I prefer my weather in the form of a Haiku\"})) End user and OAuth tokens​ If you are using Portia Cloud Tools which support user level OAuth tokens, these tokens are stored against the EndUser of the plan_run. If you have the setting enabled (see Security), tokens will be reused for each end user reducing the number of authentication flows they must do. This makes setting an end_user correctly important in this case to avoid token collision issues.End users at PortiaPass the EndUser to the plan runAccessing end users in a toolEnd user state managementEnd user and OAuth tokens",
      "timestamp": "2025-08-24 06:56:15"
    },
    {
      "url": "https://docs.portialabs.ai/custom-backend",
      "title": "Custom backends | Portia AI Docs",
      "content": "Custom backends | Portia AI Docs Skip to main content SteelThread is designed to allow for metrics to be pushed to other sinks, simply by implementing the correct metrics backend and passing it as config. class StreamMetricsBackend(ABC): \"\"\"Abstract interface for saving metrics.\"\"\" @abstractmethod def save_metrics(self, metrics: list[StreamMetric]) -> None: \"\"\"Save a list of tagged metrics for a specific evaluation run. Args: metrics (list[StreamMetricWithTags]): The metrics to save. \"\"\" raise NotImplementedErrorclass MyMetricsBackend(StreamMetricsBackend): def save_metrics(self, metrics: list[StreamMetric]) -> None: return conf = StreamConfig(stream_name=\"stream_v1\", config=config, metrics_backends=[MyMetricsBackend()])",
      "timestamp": "2025-08-24 06:56:18"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-articles",
      "title": "Zendesk - Articles: List | Portia AI Docs",
      "content": "Zendesk - Articles: List | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:help_center:list_articles Tool description: List up to 100 Zendesk articles. An article is a piece of content that is createdby Zendesk. Use this tool to get articles without a search query. Args schema: { \"properties\": {}, \"title\": \"_ArgsSchemaPlaceholder\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:56:21"
    },
    {
      "url": "https://docs.portialabs.ai/streams",
      "title": "🌊 Streams | Portia AI Docs",
      "content": "🌊 Streams | Portia AI Docs Skip to main content📄️ Overview and basic usageStreams are a way to sample real plans and plan runs from your Portia cloud account allowing you to monitor the performance of your agents in production.📄️ Custom Stream evaluatorsEvaluators are responsible for the calculation of metrics. To help you get started quickly, Steel Thread provides a built-in LLMJudgeEvaluator for stream based evaluation using LLM-as-Judge. This explained in the previous section on basic usage.📄️ Visualise Stream resultsStream metrics are pushed to the Portia dashboard. Clicking on any stream will show the latest metrics for it grouped by the time of run to show you the performance of the stream over time.",
      "timestamp": "2025-08-24 06:56:24"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/",
      "title": "Open Source Tools | Portia AI Docs",
      "content": "Open Source Tools | Portia AI Docs Skip to main content Browser UseGeneral purpose browser tool. Can be used to navigate to a URL and complete tasks. Should only be used if the task requires a browser and you are sure of the URL. This tool handles a full end to end task. It is capable of doing multiple things across different URLs within the same root domain as part of the end to end task. As a result, do not call this tool more than once back to back unless it is for different root domains - just call it once with the combined task and the URL set to the root domain. CrawlCrawls websites using graph-based website traversal tool that can explore hundreds of paths in parallel with built-in extraction and intelligent discovery. Provide a starting URL and optional instructions for what to find, and the tool will navigate and extract relevant content from multiple pages. Supports depth control, domain filtering, and path selection for comprehensive site exploration. ExtractExtracts web page content from one or more specified URLs using Tavily Extract and returns the raw content, images, and metadata from those pages. The extract tool can access publicly available web pages but cannot extract content from pages that block automated access File ReaderFinds and reads content from a local file on Disk File WriterWrites content to a file locally Image UnderstandingTool for understanding images from a URL. Capable of tasks like object detection, OCR, scene recognition, and image-based Q&A. This tool uses its native capabilities to analyze images and provide insights. LLMJack of all trades tool to respond to a prompt by relying solely on LLM capabilities. YOU NEVER CALL OTHER TOOLS. You use your native capabilities as an LLM only. This includes using your general knowledge and your in-built reasoning. This tool can be used to summarize the outputs of other tools, make general language model queries or to answer questions. This should be used only as a last resort when no other tool satisfies a step in a task, however if there are no other tools that can be used to complete a step or for steps that don't require a tool call, this SHOULD be used. MAKE SURE the task_data includes ALL INPUT VARIABLES IN THE CONTEXT. DO NOT use this tool if you require input from user. Map WebsiteMaps websites using graph-based traversal that can explore hundreds of paths in parallel with intelligent discovery to generate comprehensive site maps. Provide a URL and the tool will discover and return all accessible pages on that website. Supports depth control, domain filtering, path selection, and various mapping options for comprehensive site reconnaissance and URL discovery. PDF ReaderRead a PDF file and extract its text content using Mistral OCR SearchSearches the internet (using Tavily) to find answers to the search query provided and returns those answers, including images, links and a natural language answer. The search tool has access to general information but can not return specific information on users or information not available on the internet WeatherGet the weather for a given city",
      "timestamp": "2025-08-24 06:56:27"
    },
    {
      "url": "https://docs.portialabs.ai/agent-observability",
      "title": "Agent observability | Portia AI Docs",
      "content": "Agent observability | Portia AI Docs Skip to main contentOn this page Using Langsmith​ With Portia, you can easily instrument your agents with Langsmith in order to gain observability into the calls to the underlying language models. To do this, simply run your agent with the following environment varibles set: LANGCHAIN_TRACING_V2=trueLANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"LANGCHAIN_PROJECT=<INSERT LANGSMITH PROJECT NAME HERE>LANGCHAIN_API_KEY=<INSERT LANGSMITH API KEY HERE> If you don't already have one, you can set up a Langsmith account by following these instructions ↗. This will provide you with the required project name and API key. Once these environment variables are set, all calls that your agent makes to the underlying language models will automatically be traced within Langsmith. Other providers​ If you are using an alternative language model observability provider, please get in touch with us at hello@portialabs.ai and let us know more about your use-case.Using LangsmithOther providers",
      "timestamp": "2025-08-24 06:56:30"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-article",
      "title": "Zendesk - Articles: Show | Portia AI Docs",
      "content": "Zendesk - Articles: Show | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:help_center:show_article Tool description: Shows the properties of a Zendesk article. An article is a piece of content that is created by Zendesk. Args schema: { \"description\": \"Input schema for ZendeskShowArticleTool.\", \"properties\": { \"article_id\": { \"description\": \"The unique ID of the article\", \"title\": \"Article Id\", \"type\": \"integer\" } }, \"required\": [ \"article_id\" ], \"title\": \"ZendeskShowArticleToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:56:33"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/",
      "title": "Portia Tool Catalogue | Portia AI Docs",
      "content": "Portia Tool Catalogue | Portia AI Docs Skip to main content Portia offer both open source and cloud base tools. See the tools docs ↗ to get started using tools. Open Source Browser UseGeneral purpose browser tool. Can be used to navigate to a URL and complete tasks. Should only be used if the task requires a browser and you are sure of the URL. This tool handles a full end to end task. It is capable of doing multiple things across different URLs within the same root domain as part of the end to end task. As a result, do not call this tool more than once back to back unless it is for different root domains - just call it once with the combined task and the URL set to the root domain. CrawlCrawls websites using graph-based website traversal tool that can explore hundreds of paths in parallel with built-in extraction and intelligent discovery. Provide a starting URL and optional instructions for what to find, and the tool will navigate and extract relevant content from multiple pages. Supports depth control, domain filtering, and path selection for comprehensive site exploration. ExtractExtracts web page content from one or more specified URLs using Tavily Extract and returns the raw content, images, and metadata from those pages. The extract tool can access publicly available web pages but cannot extract content from pages that block automated access File ReaderFinds and reads content from a local file on Disk File WriterWrites content to a file locally Image UnderstandingTool for understanding images from a URL. Capable of tasks like object detection, OCR, scene recognition, and image-based Q&A. This tool uses its native capabilities to analyze images and provide insights. LLMJack of all trades tool to respond to a prompt by relying solely on LLM capabilities. YOU NEVER CALL OTHER TOOLS. You use your native capabilities as an LLM only. This includes using your general knowledge and your in-built reasoning. This tool can be used to summarize the outputs of other tools, make general language model queries or to answer questions. This should be used only as a last resort when no other tool satisfies a step in a task, however if there are no other tools that can be used to complete a step or for steps that don't require a tool call, this SHOULD be used. MAKE SURE the task_data includes ALL INPUT VARIABLES IN THE CONTEXT. DO NOT use this tool if you require input from user. Map WebsiteMaps websites using graph-based traversal that can explore hundreds of paths in parallel with intelligent discovery to generate comprehensive site maps. Provide a URL and the tool will discover and return all accessible pages on that website. Supports depth control, domain filtering, path selection, and various mapping options for comprehensive site reconnaissance and URL discovery. PDF ReaderRead a PDF file and extract its text content using Mistral OCR SearchSearches the internet (using Tavily) to find answers to the search query provided and returns those answers, including images, links and a natural language answer. The search tool has access to general information but can not return specific information on users or information not available on the internet WeatherGet the weather for a given cityPortia Cloud GitHubFind and interact with GitHub repositories. Google CalendarCreate and modify events in Google Calendar. Google DocsFetch documents from Google Docs. Google DriveSearch for files in Google Drive. Google GmailSend and find emails via Google Gmail. Google SheetsFetch spreadsheets from Google Sheets. Microsoft OutlookSend and find emails via Microsoft Outlook. SlackSend messages and search channels and chats in a Slack workspace. ZendeskInteract with Zendesk support tickets, articles, and more.Remote MCP Apify ActorsUse 4,000+ pre-built cloud tools, known as Actors, to extract data from websites, e-commerce, social media, search engines, maps, and more. AsanaOpens the Asana Work Graph to AI assistants, enabling task and project operations through an authenticated MCP interface.. CloudflareManage your Cloudflare DNS records, Cloudflare Workers, audit logs, and more. DeepWikiProvides AI assistants with access to GitHub repository documentation and search capabilities for code understanding, architecture exploration, and technical question answering. FirecrawlIntegration with FireCrawl to provide advanced web scraping capabilities for extracting structured data from complex websites. Hugging FaceIntegrates with Hugging Face's ecosystem to search models, datasets, and papers while dynamically connecting to Gradio-based tools hosted on Spaces for extended ML capabilities. IntercomEnables AI systems to securely access Intercom's customer conversation data, user profiles, and tickets in real-time for identifying patterns, troubleshooting issues, and driving business decisions. InvideoLets agents script end-to-end video creation: writing scripts, fetching stock media, generating clips and subtitling. LinearAccess your Linear data to manage your projects and issues in a simple and secure way. MakeConnects AI systems to Make automation workflows, enabling assistants to trigger scenarios with parameters and receive structured JSON output from your existing Make account. PosthogIntegrates with PostHog to enable querying analytics, errors, running SQL insights, and managing feature flags through natural language interactions. SemgrepIntegrates with Semgrep's static analysis engine to scan code for security vulnerabilities and coding issues, enabling developers to identify and fix potential problems directly within their coding workflow. SentryExposes 16+ tools to query issues, search errors and even invoke Seer for automated fixes. ShopifyIntegrates with individual Shopify stores to enable product catalog search, cart management, and policy inquiries for complete shopping experiences from discovery to checkout. SquareProvides a bridge between Square's complete API ecosystem and conversational interfaces, enabling comprehensive e-commerce and payment processing capabilities including payments, orders, inventory, and customer management. StripeIntegrates with Stripe's API to enable payment processing, customer management, and financial operations for e-commerce and billing workflows. SupermemoryPersonal knowledge platform that helps collect, organize, and recall information from various sources with end-to-end encryption and optional self-hosting. WebflowIntegration with the Webflow Data API. WixEnables website creation and management with Wix business solutions including eCommerce, booking systems, payment processing, and CRM functionality through natural language commands. YepCodeEnables secure execution of LLM-generated scripts and processes in isolated environments with environment variable management for teams needing to run code directly from AI assistants.Local MCP AWS Cost AnalysisAnalyze AWS service costs and generate cost reports. AWS DocumentationProvides tools to access AWS documentation, search for content, and get recommendations. Basic MemoryKnowledge management system that builds a persistent semantic graph in markdown, locally. BioMCPIntegrates with biomedical databases including ClinicalTrials.gov, PubMed, and MyVariant.info to provide structured access to clinical trials, research articles, and genetic variants with intelligent data rendering and source attribution. Bright DataIntegrates with Bright Data's web scraping infrastructure to provide real-time access to public web data through specialized tools for search engine scraping, webpage extraction, and structured data retrieval from popular websites. BrowserbaseAutomate web browsers remotely on a cloud environment. ChargebeeIntegration with Chargebee products and API services to facilitate billing for subscription businesses. ChromaIntegrates with Chroma vector database to enable collection management, document operations, and vector search capabilities for knowledge bases and context-aware conversations. DBHubProvides a universal database gateway for connecting to PostgreSQL, MySQL, SQLite, and DuckDB, enabling table browsing, schema inspection, and read-only SQL queries with built-in safety checks ElevenLabsIntegrates with ElevenLabs to provide high-quality text-to-speech, voice cloning, and conversational capabilities with customizable voice profiles and audio processing features. GCP Cloud RunDeploys applications to Google Cloud Run through automated containerization, project setup, and service management with support for both local files and provided content. GitHubIntegration with GitHub Issues, Pull Requests, and more. GrafanaIntegrates with Grafana to enable searching dashboards, fetching datasource information, querying Prometheus metrics, and managing incidents through both stdio and SSE transport modes. HubSpotIntegrates with HubSpot CRM to enable secure access to contact information, company records, deal data, and task management with customizable data access through Private App scopes. HyperbrowserEnables web browsing capabilities through tools for content extraction, link following, and browser automation with customizable parameters for scraping, data collection, and web crawling tasks. JetBrains IDEInteract with JetBrains IDEs for code analysis and development tasks. MiniMaxEnables high-quality text-to-speech, voice cloning, and video generation capabilities through MiniMax's API with robust error handling and file management features. Monday.comIntegrates with monday.com API to enable direct access to boards, workflows, and data for automating tasks and managing resources without context switching. MongoDBProvides a bridge between MongoDB databases and conversational interfaces, enabling comprehensive database operations, collection management, schema inspection, and Atlas cloud service interactions with authentication and telemetry support. NetlifyIntegrates with Netlify's platform for complete site management including project operations, deployments with zip uploads, team administration, extension configuration, and documentation access across hosting, build, and collaboration workflows. NotionBridges to the Notion API for searching content, querying databases, and managing pages and comments without requiring complex API interaction code PerplexityConnector for the Perplexity API, to enable web search without leaving the MCP ecosystem. PlaywrightEnables web browser control for navigating websites, capturing page snapshots, interacting with elements, and taking screenshots through Playwright's automation capabilities. QdrantStore and retrieve vector-based memories for AI systems. Shopify DevIntegrates with Shopify Dev. Supports various tools to interact with different Shopify APIs. SupabaseConnects directly to Supabase projects for managing databases, executing SQL queries, applying migrations, and handling configurations through natural language commands. TwilioIntegrates with Twilio's API ecosystem to enable messaging, voice, conversations, and serverless functions through authenticated access with automatic AccountSid population and context filtering capabilities. XeroProvides a bridge to the Xero accounting API, enabling financial data interactions and accounting operations through OAuth2 custom connections for automated workflow management.",
      "timestamp": "2025-08-24 06:56:36"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/webflow",
      "title": "Webflow | Portia AI Docs",
      "content": "Webflow | Portia AI Docs Skip to main contentOn this page Description​ Integration with the Webflow Data API. Authorisation​ This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail here (↗). Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to authorise with the server via OAuth when you enable it. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:56:39"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/plan",
      "title": "portia.plan | Portia AI Docs",
      "content": "portia.plan | Portia AI Docs Skip to main contentOn this pagePlan primitives used to define and execute runs. This module defines the core objects that represent the plan for executing a PlanRun. The Plan class is the main structure that holds a series of steps (Step) to be executed by an agent in response to a query. Each step can have inputs, an associated tool, and an output. Variables can be used within steps to reference other parts of the plan or constants. Classes in this file include: Variable: A variable used in the plan, referencing outputs of previous steps or constants. Step: Defines a single task that an agent will execute, including inputs and outputs. ReadOnlyStep: A read-only version of a Step used for passing steps to agents. PlanContext: Provides context about the plan, including the original query and available tools. Plan: Represents the entire series of steps required to execute a query. These classes facilitate the definition of runs that can be dynamically adjusted based on the tools, inputs, and outputs defined in the plan. PlanBuilder Objects​ class PlanBuilder() A builder for creating plans. This class provides an interface for constructing plans step by step. Requires a step to be added to the plan before building it. Example: plan = PlanBuilder() .step(\"Step 1\", \"tool_id_1\", \"output_1\") .step(\"Step 2\", \"tool_id_2\", \"output_2\") .input(\"input_1\", \"value_1\") .build() __init__​ def __init__(query: str | None = None, structured_output_schema: type[BaseModel] | None = None) -> None Initialize the builder with the plan query. Arguments: query str - The original query given by the user. structured_output_schema type[BaseModel] | None - The optional structured output schema for the query. step​ def step( task: str, tool_id: str | None = None, output: str | None = None, inputs: list[Variable] | None = None, condition: str | None = None, structured_output_schema: type[BaseModel] | None = None) -> PlanBuilder Add a step to the plan. Arguments: task str - The task to be completed by the step. tool_id str | None - The ID of the tool used in this step, if applicable. output str | None - The unique output ID for the result of this step. inputs list[Variable] | None - The inputs to the step condition str | None - A human readable condition which controls if the step should run or not. structured_output_schema type[BaseModel] | None - The optional structured output schema for the step. Will override the tool output schema if provided by calling step summarizer with structured response. Returns: PlanBuilder - The builder instance with the new step added. input​ def input(name: str, description: str | None = None, step_index: int | None = None) -> PlanBuilder Add an input variable to the chosen step in the plan (default is the last step). Inputs are outputs from previous steps. Arguments: name str - The name of the input. description str | None - The description of the input. step_index int | None - The index of the step to add the input to. If not provided, the input will be added to the last step. Returns: PlanBuilder - The builder instance with the new input added. plan_input​ def plan_input(name: str, description: str) -> PlanBuilder Add an input variable to the plan. Arguments: name str - The name of the input. description str - The description of the input. Returns: PlanBuilder - The builder instance with the new plan input added. condition​ def condition(condition: str, step_index: int | None = None) -> PlanBuilder Add a condition to the chosen step in the plan (default is the last step). Arguments: condition str - The condition to be added to the chosen step. step_index int | None - The index of the step to add the condition to. If not provided, the condition will be added to the last step. Returns: PlanBuilder - The builder instance with the new condition added. build​ def build() -> Plan Build the plan. Returns: Plan - The built plan. Variable Objects​ class Variable(BaseModel) A reference to an output of a step. Arguments: name str - The name of the output or plan input to reference, e.g. $best_offers. description str - A description of the output or plan input. pretty_print​ def pretty_print() -> str Return the pretty print representation of the variable. Returns: str - A pretty print representation of the variable's name, and description. PlanInput Objects​ class PlanInput(BaseModel) An input to a plan. Arguments: name str - The name of the input, e.g. $api_key. description str - A description of the input. pretty_print​ def pretty_print() -> str Return the pretty print representation of the plan input. Returns: str - A pretty print representation of the input's name, and description. Step Objects​ class Step(BaseModel) A step in a PlanRun. A step represents a task in the run to be executed. It contains inputs (variables) and outputs, and may reference a tool to complete the task. Arguments: task str - The task that needs to be completed by this step. inputs list[Variable] - The input to the step, as a reference to an output of a previous step or a plan input tool_id str | None - The ID of the tool used in this step, if applicable. output str - The unique output ID for the result of this step. pretty_print​ def pretty_print() -> str Return the pretty print representation of the step. Returns: str - A pretty print representation of the step's task, inputs, tool_id, and output. ReadOnlyStep Objects​ class ReadOnlyStep(Step) A read-only copy of a step, passed to agents for reference. This class creates an immutable representation of a step, which is used to ensure agents do not modify the original plan during execution. Arguments: step Step - A step object from which to create a read-only version. from_step​ @classmethoddef from_step(cls, step: Step) -> ReadOnlyStep Create a read-only step from a normal step. Arguments: step Step - The step to be converted to read-only. Returns: ReadOnlyStep - A new read-only step. PlanContext Objects​ class PlanContext(BaseModel) Context for a plan. The plan context contains information about the original query and the tools available for the planning agent to use when generating the plan. Arguments: query str - The original query given by the user. tool_ids list[str] - A list of tool IDs available to the planning agent. serialize_tool_ids​ @field_serializer(\"tool_ids\")def serialize_tool_ids(tool_ids: list[str]) -> list[str] Serialize the tool_ids to a sorted list. Returns: list[str] - The tool_ids as a sorted list. Plan Objects​ class Plan(BaseModel) A plan represents a series of steps that an agent should follow to execute the query. A plan defines the entire sequence of steps required to process a query and generate a result. It also includes the context in which the plan was created. Arguments: id PlanUUID - A unique ID for the plan. plan_context PlanContext - The context for when the plan was created. steps list[Step] - The set of steps that make up the plan. inputs list[PlanInput] - The inputs required by the plan. __str__​ def __str__() -> str Return the string representation of the plan. Returns: str - A string representation of the plan's ID, context, and steps. from_response​ @classmethoddef from_response(cls, response_json: dict) -> Plan Create a plan from a response. Arguments: response_json dict - The response from the API. Returns: Plan - The plan. pretty_print​ def pretty_print() -> str Return the pretty print representation of the plan. Returns: str - A pretty print representation of the plan's ID, context, and steps. validate_plan​ @model_validator(mode=\"after\")def validate_plan() -> Self Validate the plan. Checks that all outputs + conditions are unique. Returns: Plan - The validated plan. ReadOnlyPlan Objects​ class ReadOnlyPlan(Plan) A read-only copy of a plan, passed to agents for reference. This class provides a non-modifiable view of a plan instance, ensuring that agents can access plan details without altering them. from_plan​ @classmethoddef from_plan(cls, plan: Plan) -> ReadOnlyPlan Create a read-only plan from a normal plan. Arguments: plan Plan - The original plan instance to create a read-only copy from. Returns: ReadOnlyPlan - A new read-only instance of the provided plan. PlanBuilder ObjectsVariable ObjectsPlanInput ObjectsStep ObjectsReadOnlyStep ObjectsPlanContext ObjectsPlan ObjectsReadOnlyPlan Objects",
      "timestamp": "2025-08-24 06:56:42"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs",
      "title": "Google Docs Tools | Portia AI Docs",
      "content": "Google Docs Tools | Portia AI Docs Skip to main content Docs: Get DocumentGet a document from Google Docs in plain text format by ID. The GoogleDriveSearchTool should be used to search for a document by name if an ID is not known. Docs: Get Structured DocumentGet a document from Google Docs in a machine readable format. Do not use unless you reallyneed a structured document.",
      "timestamp": "2025-08-24 06:56:45"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/tool",
      "title": "portia.tool | Portia AI Docs",
      "content": "portia.tool | Portia AI Docs Skip to main contentOn this pageTools module. This module defines an abstract base class for tools, providing a structure for creating custom tools that can integrate with external systems. It includes an implementation of a base Tool class that defines common attributes and behaviors, such as a unique ID and name. Child classes should implement the run method to define the specific logic for interacting with the external systems or performing actions. The module also contains PortiaRemoteTool, a subclass of Tool, which implements the logic to interact with Portia Cloud, including handling API responses and tool errors. The tools in this module are designed to be extendable, allowing users to create their own tools while relying on common functionality provided by the base class. ToolRunContext Objects​ class ToolRunContext(BaseModel) Context passed to tools when running. Attributes: plan_run(PlanRun) - The run the tool run is part of. plan(Plan) - The plan the tool run is part of. config(Config) - The config for the SDK as a whole. clarifications(ClarificationListType) - Relevant clarifications for this tool plan_run. ReadyResponse Objects​ class ReadyResponse(BaseModel) Response from the /ready endpoint. Tool Objects​ class Tool(BaseModel, Generic[SERIALIZABLE_TYPE_VAR]) Abstract base class for a tool. This class serves as the blueprint for all tools. Child classes must implement the run method. Attributes: id str - A unique identifier for the tool. This must be unique as collisions in a tool registry will lead to errors. name str - The name of the tool. The name is informational only but useful for debugging. description str - Purpose of the tool and usage. This is important information for the planning_agent module to know when and how to use this tool. args_schema type[BaseModel] - The schema defining the expected input arguments for the tool. We use Pydantic models to define these types. output_schema tuple[str, str] - A tuple containing the type and description of the tool's output. To maximize the advantages of using an agentic approach this doesn't need to be tightly defined. Instead it should give just a high level overview of the type and contents of the tools output. should_summarize bool - Indicates whether the tool's output should be automatically summarized by the summarizer agent. For some tools summarization is useful (for example: a tool that fetches the latest news) whereas other tools it's not (for example: a tool that fetches raw price data). ready​ def ready(ctx: ToolRunContext) -> ReadyResponse Check whether the tool can be plan_run. This method can be implemented by subclasses to allow checking if the tool can be plan_run. It may run any authentication logic or other required checks before returning its status. If left unimplemented will always return true. Arguments: ctx ToolRunContext - Co ntext of the tool run Returns: ReadyResponse - Whether the tool is ready to run and any clarifications that need to be resolved run​ @abstractmethoddef run(ctx: ToolRunContext, *args: Any, **kwargs: Any) -> SERIALIZABLE_TYPE_VAR | Clarification Run the tool. This method must be implemented by subclasses to define the tool's specific behavior. Arguments: ctx ToolRunContext - Context of the tool execution args Any - The arguments passed to the tool for execution. kwargs Any - The keyword arguments passed to the tool for execution. Returns: Any - The result of the tool's execution which can be any serializable type or a clarification. arun​ async def arun(ctx: ToolRunContext, *args: Any, **kwargs: Any) -> SERIALIZABLE_TYPE_VAR | Clarification Async run the tool. This is the method that tools should implement if they want to provide an async method for running the tool. When calling this method, you should likely call the _arun method instead. Arguments: ctx ToolRunContext - The context for the tool. *args Any - Additional positional arguments for the tool function. **kwargs Any - Additional keyword arguments for the tool function. Returns: SERIALIZABLE_TYPE_VAR | Clarification: The result of the tool's execution which can be any serializable type or a clarification. check_description_length​ @model_validator(mode=\"after\")def check_description_length() -> Self Check that the description is less than 16384 characters. OpenAI has a maximum function description length of 16384 characters. This validator ensures that the tool description does not exceed this limit. Returns: Self - The current instance of the tool. Raises: InvalidToolDescriptionError - If the description exceeds the maximum length. check_run_method_signature​ @model_validator(mode=\"after\")def check_run_method_signature() -> Self Ensure the run method signature matches the args_schema. to_langchain​ def to_langchain(ctx: ToolRunContext, sync: bool = True) -> StructuredTool Return a LangChain representation of this tool. This function provides a LangChain-compatible version of the tool. The response format is the default one without including artifacts. The ExecutionContext is baked into the StructuredTool via a partial run function. Arguments: ctx ToolRunContext - The context for the tool. sync bool - Whether to use the sync or async version of the tool. Returns: StructuredTool - The LangChain-compatible representation of the tool, including the tool's name, description, and argument schema, with the execution context baked into the function. to_langchain_with_artifact​ def to_langchain_with_artifact(ctx: ToolRunContext, sync: bool = True) -> StructuredTool Return a LangChain representation of this tool with content and artifact. This function provides a LangChain-compatible version of the tool, where the response format includes both the content and the artifact. The ToolRunContext is baked into the StructuredTool via a partial run function for capturing output directly. Arguments: ctx ToolRunContext - The context for the tool. sync bool - Whether to use the sync or async version of the tool. Returns: StructuredTool - The LangChain-compatible representation of the tool, including the tool's name, description, argument schema, and the ability to return both content and artifact. args_json_schema​ def args_json_schema() -> dict[str, Any] Return the json_schema for the tool args. This function retrieves the JSON schema for the tool's arguments, which defines the expected input structure. Returns: dict[str, Any]: The JSON schema representing the tool's arguments. __str__​ def __str__() -> str Return the string representation. This method generates a string representation of the tool, including its ID, name, description, argument schema, and output schema. Returns: str - A string representation of the tool. serialize_args_schema​ @field_serializer(\"args_schema\")def serialize_args_schema(value: type[BaseModel]) -> str Serialize the args_schema by returning its class name. This function serializes the arguments schema by returning the class name of the schema. Arguments: value type[BaseModel] - The argument schema class. Returns: str - The class name of the argument schema. pretty​ def pretty() -> str Return a pretty string representation of the tool. PortiaRemoteTool Objects​ class PortiaRemoteTool(Tool, Generic[SERIALIZABLE_TYPE_VAR]) Tool that passes run execution to Portia Cloud. parse_response​ def parse_response(ctx: ToolRunContext, response: dict[str, Any]) -> Output Parse a JSON response into domain models or errors. This method handles the response from the Portia Cloud API, converting it into domain specific models. It also handles errors, including ToolSoftError and ToolHardError, as well as clarifications of different types. Arguments: ctx ToolRunContext - Context of the environment response dict[str, Any] - The JSON response returned by the Portia Cloud API. Returns: Output - The parsed output wrapped in an Output object. Raises: ToolSoftError - If a soft error is encountered in the response. ToolHardError - If a hard error is encountered in the response. ready​ def ready(ctx: ToolRunContext) -> ReadyResponse Check if the remote tool is ready by calling the /ready endpoint. Arguments: ctx ToolRunContext - Context of the environment Returns: ReadyResponse - Whether the tool is ready to run and any clarifications that need to be resolved run​ def run(ctx: ToolRunContext, *args: Any, **kwargs: Any) -> SERIALIZABLE_TYPE_VAR | None | Clarification Invoke the run endpoint and handle the response. This method sends the execution request to the Portia Cloud API, passing the arguments and execution context. It then processes the response by calling parse_response. Errors during the request or parsing are raised as ToolHardError. Arguments: ctx ToolRunContext - The context of the execution, including end user ID, run ID and additional data. *args Any - The positional arguments for the tool. **kwargs Any - The keyword arguments for the tool. Returns: SERIALIZABLE_TYPE_VAR | None | Clarification: The result of the run execution, which could either be a serialized value, None, or a Clarification object. Raises: ToolHardError - If the request fails or there is an error parsing the response. batch_ready_check​ @classmethoddef batch_ready_check(cls, config: Config, tool_ids: set[str], tool_run_context: ToolRunContext) -> ReadyResponse Batch check readiness for Portia cloud tools. Arguments: config Config - The config for the SDK as a whole. tool_ids set[str] - The list of tool IDs to check readiness for. tool_run_context ToolRunContext - The context of the execution. Returns: ReadyResponse - The readiness response for the tools. PortiaMcpTool Objects​ class PortiaMcpTool(Tool[str]) A Portia Tool wrapper for an MCP server-based tool. run​ def run(_: ToolRunContext, **kwargs: Any) -> str Invoke the tool by dispatching to the MCP server. Arguments: _ - The tool run context **kwargs - The arguments to pass to the MCP tool invocation Returns: str - The result of the tool call arun​ async def arun(_: ToolRunContext, **kwargs: Any) -> str Invoke the tool by dispatching to the MCP server asynchronously. call_remote_mcp_tool​ async def call_remote_mcp_tool(name: str, arguments: dict | None = None) -> str Call a tool using the MCP session. There are issues with the implementation of the mcp client which mean that the read_timeout_seconds still waits for a response from the server before raising a timeout, which is entirely defeating the purpose of the timeout on our side. This method implements a custom timeout using asyncio.wait, allowing us to raise the correct exception when the deadline is reached. flatten_exceptions​ def flatten_exceptions(exc_group: BaseExceptionGroup[Any], exc_type: type[ExceptionT]) -> list[ExceptionT] Flatten an ExceptionGroup into a list of exceptions of a given type.ToolRunContext ObjectsReadyResponse ObjectsTool ObjectsPortiaRemoteTool ObjectsPortiaMcpTool Objects",
      "timestamp": "2025-08-24 06:56:48"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/perplexity",
      "title": "Perplexity | Portia AI Docs",
      "content": "Perplexity | Portia AI Docs Skip to main contentOn this page Description​ Connector for the Perplexity API, to enable web search without leaving the MCP ecosystem. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"perplexity-ask\", command=\"npx\", args=[\"-y\", \"server-perplexity-ask\"], env={\"PERPLEXITY_API_KEY\": \"<api_key>\"},) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"perplexity-ask\", command=\"npx\", args=[\"-y\", \"server-perplexity-ask\"], env={\"PERPLEXITY_API_KEY\": \"<api_key>\"},) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:56:51"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/utils/final_output_summarizer",
      "title": "portia.execution_agents.utils.final_output_summarizer | Portia AI Docs",
      "content": "portia.execution_agents.utils.final_output_summarizer | Portia AI Docs Skip to main contentOn this pageUtility class for final output summarizer. FinalOutputSummarizer Objects​ class FinalOutputSummarizer() Utility class responsible for summarizing the run outputs for final output's summary. Attributes: config Config - The configuration for the llm. agent_memory AgentMemory - The agent memory to use for the summarizer. __init__​ def __init__(config: Config, agent_memory: AgentMemory) -> None Initialize the summarizer agent. Arguments: config Config - The configuration for the llm. agent_memory AgentMemory - The agent memory to use for the summarizer. get_output_value​ def get_output_value(output: Output) -> str | None Get the value to use for the specified output. This ensures that introspection outputs and outputs that are too large for the LLM context window are handled correctly. create_summary​ def create_summary(plan: Plan, plan_run: PlanRun) -> str | BaseModel | None Execute the summarizer llm and return the summary as a string. Arguments: plan Plan - The plan containing the steps. plan_run PlanRun - The run to summarize. Returns: str | BaseModel | None: The generated summary or None if generation fails.FinalOutputSummarizer Objects",
      "timestamp": "2025-08-24 06:56:54"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/memory_extraction",
      "title": "portia.execution_agents.memory_extraction | Portia AI Docs",
      "content": "portia.execution_agents.memory_extraction | Portia AI Docs Skip to main contentOn this pageMemory extraction step for execution agents. This module provides a step that extracts memory from previous outputs for use in execution agents. MemoryExtractionStep Objects​ class MemoryExtractionStep() A step that extracts memory from the context. __init__​ def __init__(agent: BaseExecutionAgent) -> None Initialize the memory extraction step. Arguments: agent BaseExecutionAgent - The agent using the memory extraction step. invoke​ def invoke(_: dict[str, Any]) -> dict[str, Any] Invoke the model with the given message state. Returns: dict[str, Any]: The LangGraph state update to step_inputsMemoryExtractionStep Objects",
      "timestamp": "2025-08-24 06:56:57"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/base_execution_agent",
      "title": "portia.execution_agents.base_execution_agent | Portia AI Docs",
      "content": "portia.execution_agents.base_execution_agent | Portia AI Docs Skip to main contentOn this pageAgents are responsible for executing steps of a PlanRun. The BaseAgent class is the base class that all agents must extend. BaseExecutionAgent Objects​ class BaseExecutionAgent() An ExecutionAgent is responsible for carrying out the task defined in the given Step. This BaseExecutionAgent is the class all ExecutionAgents must extend. Critically, ExecutionAgents must implement the execute_sync function which is responsible for actually carrying out the task as given in the step. They have access to copies of the step, plan_run and config but changes to those objects are forbidden. Optionally, new execution agents may also override the get_context function, which is responsible for building the system context for the agent. This should be done with thought, as the details of the system context are critically important for LLM performance. __init__​ def __init__(plan: Plan, plan_run: PlanRun, config: Config, end_user: EndUser, agent_memory: AgentMemory, tool: Tool | None = None, execution_hooks: ExecutionHooks | None = None) -> None Initialize the base agent with the given args. Importantly, the models here are frozen copies of those used by the Portia instance. They are meant as read-only references, useful for execution of the task but cannot be edited. The agent should return output via the response of the execute_sync method. Arguments: plan Plan - The plan containing the steps. plan_run PlanRun - The run that contains the step and related data. config Config - The configuration settings for the agent. end_user EndUser - The end user for the execution. agent_memory AgentMemory - The agent memory for persisting outputs. tool Tool | None - An optional tool associated with the agent (default is None). execution_hooks - Optional hooks for extending execution functionality. step​ @propertydef step() -> Step Get the current step from the plan. execute_sync​ @abstractmethoddef execute_sync() -> Output Run the core execution logic of the task synchronously. Implementation of this function is deferred to individual agent implementations, making it simple to write new ones. Returns: Output - The output of the task execution. execute_async​ async def execute_async() -> Output Run the core execution logic of the task asynchronously. Implementation of this function is deferred to individual agent implementations, making it simple to write new ones. If not implemented, the agent will return a threaded version of the execute_sync method. Returns: Output - The output of the task execution. get_system_context​ def get_system_context(ctx: ToolRunContext, step_inputs: list[StepInput]) -> str Build a generic system context string from the step and run provided. This function retrieves the execution context and generates a system context based on the step and run provided to the agent. Arguments: ctx ToolRunContext - The tool run ctx. step_inputs list[StepInput] - The inputs for the step. Returns: str - A string containing the system context for the agent. next_state_after_tool_call​ def next_state_after_tool_call( config: Config, state: MessagesState, tool: Tool | None = None) -> Literal[AgentNode.TOOL_AGENT, AgentNode.SUMMARIZER, END] Determine the next state after a tool call. This function checks the state after a tool call to determine if the run should proceed to the tool agent again, to the summarizer, or end. Arguments: config Config - The configuration for the run. state MessagesState - The current state of the messages. tool Tool | None - The tool involved in the call, if any. Returns: Literal[AgentNode.TOOL_AGENT, AgentNode.SUMMARIZER, END]: The next state to transition to. Raises: ToolRetryError - If the tool has an error and the maximum retry limit has not been reached. BaseExecutionAgent Objects",
      "timestamp": "2025-08-24 06:57:00"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/",
      "title": "Remote MCP Servers | Portia AI Docs",
      "content": "Remote MCP Servers | Portia AI Docs Skip to main content This is a list of official remote MCP servers that can be added to your DefaultToolRegistry from the dashboard. Apify ActorsUse 4,000+ pre-built cloud tools, known as Actors, to extract data from websites, e-commerce, social media, search engines, maps, and more. AsanaOpens the Asana Work Graph to AI assistants, enabling task and project operations through an authenticated MCP interface.. CloudflareManage your Cloudflare DNS records, Cloudflare Workers, audit logs, and more. DeepWikiProvides AI assistants with access to GitHub repository documentation and search capabilities for code understanding, architecture exploration, and technical question answering. FirecrawlIntegration with FireCrawl to provide advanced web scraping capabilities for extracting structured data from complex websites. Hugging FaceIntegrates with Hugging Face's ecosystem to search models, datasets, and papers while dynamically connecting to Gradio-based tools hosted on Spaces for extended ML capabilities. IntercomEnables AI systems to securely access Intercom's customer conversation data, user profiles, and tickets in real-time for identifying patterns, troubleshooting issues, and driving business decisions. InvideoLets agents script end-to-end video creation: writing scripts, fetching stock media, generating clips and subtitling. LinearAccess your Linear data to manage your projects and issues in a simple and secure way. MakeConnects AI systems to Make automation workflows, enabling assistants to trigger scenarios with parameters and receive structured JSON output from your existing Make account. PosthogIntegrates with PostHog to enable querying analytics, errors, running SQL insights, and managing feature flags through natural language interactions. SemgrepIntegrates with Semgrep's static analysis engine to scan code for security vulnerabilities and coding issues, enabling developers to identify and fix potential problems directly within their coding workflow. SentryExposes 16+ tools to query issues, search errors and even invoke Seer for automated fixes. ShopifyIntegrates with individual Shopify stores to enable product catalog search, cart management, and policy inquiries for complete shopping experiences from discovery to checkout. SquareProvides a bridge between Square's complete API ecosystem and conversational interfaces, enabling comprehensive e-commerce and payment processing capabilities including payments, orders, inventory, and customer management. StripeIntegrates with Stripe's API to enable payment processing, customer management, and financial operations for e-commerce and billing workflows. SupermemoryPersonal knowledge platform that helps collect, organize, and recall information from various sources with end-to-end encryption and optional self-hosting. WebflowIntegration with the Webflow Data API. WixEnables website creation and management with Wix business solutions including eCommerce, booking systems, payment processing, and CRM functionality through natural language commands. YepCodeEnables secure execution of LLM-generated scripts and processes in isolated environments with environment variable management for teams needing to run code directly from AI assistants.",
      "timestamp": "2025-08-24 06:57:03"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/crawl_tool",
      "title": "portia.open_source_tools.crawl_tool | Portia AI Docs",
      "content": "portia.open_source_tools.crawl_tool | Portia AI Docs Skip to main contentOn this pageTool to crawl websites. CrawlToolSchema Objects​ class CrawlToolSchema(BaseModel) Input for CrawlTool. CrawlTool Objects​ class CrawlTool(Tool[str]) Crawls websites using graph-based traversal tool. run​ def run(_: ToolRunContext, url: str, instructions: str | None = None, max_depth: int = DEFAULT_MAX_DEPTH, max_breadth: int = DEFAULT_MAX_BREADTH, limit: int = DEFAULT_LIMIT, select_paths: list[str] | None = None, select_domains: list[str] | None = None, exclude_paths: list[str] | None = None, exclude_domains: list[str] | None = None, allow_external: bool = False) -> str Run the crawl tool.CrawlToolSchema ObjectsCrawlTool Objects",
      "timestamp": "2025-08-24 06:57:06"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/cloudflare",
      "title": "Cloudflare | Portia AI Docs",
      "content": "Cloudflare | Portia AI Docs Skip to main contentOn this page Description​ Manage your Cloudflare DNS records, Cloudflare Workers, audit logs, and more. Authorisation​ This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail here (↗). Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to authorise with the server via OAuth when you enable it. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:57:09"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/builder/conditionals",
      "title": "portia.builder.conditionals | Portia AI Docs",
      "content": "portia.builder.conditionals | Portia AI Docs Skip to main contentOn this pageTypes to support Conditionals. ConditionalBlock Objects​ class ConditionalBlock(BaseModel) A conditional block in the plan. This object is used to track the position of steps in the conditional tree, if one is present. Arguments: clause_step_indexes - The indexes of the conditional steps (i.e. the if_, else_if_, else_, endif steps). parent_conditional_block - The parent branch of this branch. If None, this is a root branch. ConditionalBlockClauseType Objects​ class ConditionalBlockClauseType(StrEnum) The type of conditional block clause. ConditionalStepResult Objects​ class ConditionalStepResult(BaseModel) Output of a conditional step. Arguments: type - The type of conditional block clause that was executed. conditional_result - The result of the conditional predicate evaluation. next_clause_step_index - The step index of the next clause conditional to jump to if the conditional result is false. end_condition_block_step_index - The step index of the end condition block (endif). ConditionalBlock ObjectsConditionalBlockClauseType ObjectsConditionalStepResult Objects",
      "timestamp": "2025-08-24 06:57:12"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/builder/reference",
      "title": "portia.builder.reference | Portia AI Docs",
      "content": "portia.builder.reference | Portia AI Docs Skip to main contentOn this pageReferences to values in a plan. default_step_name​ def default_step_name(step_index: int) -> str Return the default name for the step. Reference Objects​ class Reference(BaseModel, ABC) A reference to a value. get_legacy_name​ @abstractmethoddef get_legacy_name(plan: PlanV2) -> str Get the name of the reference to use with legacy Portia plans. get_value​ @abstractmethoddef get_value(run_data: RunContext) -> ReferenceValue | None Get the value of the reference. StepOutput Objects​ class StepOutput(Reference) A reference to the output of a previous step. When building your plan, you can use this class to reference the output of a previous step. The output from the specified step will then be substituted in when the plan is run. See the example usage in example_builder.py for more details. __init__​ def __init__(step: str | int) -> None Initialize the step output. get_legacy_name​ @overridedef get_legacy_name(plan: PlanV2) -> str Get the name of the reference to use with legacy Portia plans. __str__​ def __str__() -> str Get the string representation of the step output. get_value​ @overridedef get_value(run_data: RunContext) -> ReferenceValue | None Get the value of the step output. Input Objects​ class Input(Reference) A reference to a plan input. When building your plan, you can specify plan inputs using the PlanBuilder.input() method. These are inputs whose values you provide when running the plan, rather than when building the plan. You can then use this to reference those inputs later in your plan. When you do this, the values will be substituted in when the plan is run. See the example usage in example_builder.py for more details. __init__​ def __init__(name: str) -> None Initialize the input. get_legacy_name​ @overridedef get_legacy_name(plan: PlanV2) -> str Get the name of the reference to use with legacy Portia plans. get_value​ @overridedef get_value(run_data: RunContext) -> ReferenceValue | None Get the value of the input. __str__​ def __str__() -> str Get the string representation of the input. ReferenceValue Objects​ class ReferenceValue(BaseModel) Value that can be referenced.Reference ObjectsStepOutput ObjectsInput ObjectsReferenceValue Objects",
      "timestamp": "2025-08-24 06:57:15"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-send-email",
      "title": "Microsoft Outlook - Outlook: Send | Portia AI Docs",
      "content": "Microsoft Outlook - Outlook: Send | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Selecting Microsoft Tools​ Microsoft tools are included in Portia's cloud registry but are not included in the default DefaultToolRegistry class. This is due to tool clashes with the Google tools (i.e. the agent wouldn't know whether to check Gmail or Outlook for email tasks). In order to use Microsoft tools rather than Google tools, simply filter out the Google tools from the Portia cloud registry rather than using the default registry: from portia import PortiaToolRegistry, default_configregistry = PortiaToolRegistry(default_config()).filter_tools(lambda tool: not tool.id.startswith(\"portia:google:\"))registry = PortiaToolRegistry(default_config()).filter_tools( lambda tool: not tool.id.startswith(\"portia:google:\")) Tool details​ Tool ID: portia:microsoft:outlook:send_email Tool description: Sends an email to the recipients indicated. Should not be used with the draft email tool. Instead to send a draft email use the send_draft_email_tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Args schema: { \"description\": \"Input for SendEmailTool.\", \"properties\": { \"recipients\": { \"description\": \"The recipients that the email should be sent to (should be a list of email addresses)\", \"items\": { \"type\": \"string\" }, \"title\": \"Recipients\", \"type\": \"array\" }, \"email_title\": { \"description\": \"The title of the email to be sent\", \"title\": \"Email Title\", \"type\": \"string\" }, \"email_body\": { \"description\": \"The body of the email to be sent\", \"title\": \"Email Body\", \"type\": \"string\" } }, \"required\": [ \"recipients\", \"email_title\", \"email_body\" ], \"title\": \"SendEmailToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Output of the email sent')UsageSelecting Microsoft ToolsTool details",
      "timestamp": "2025-08-24 06:57:18"
    },
    {
      "url": "https://docs.portialabs.ai/evals-custom-evaluators",
      "title": "Custom evaluators | Portia AI Docs",
      "content": "Custom evaluators | Portia AI Docs Skip to main content Evaluators are responsible for the calculation of metrics. To help you get started quickly, Steel Thread provides a multitude of built-in evaluators you can configure from the dashboard and then pass to your EvalRun via the DefaultEvaluator class. This explained in the previous section on basic usage. You can add your own custom evaluators, be it LLM-as-Judge or deterministic ones. Evaluator implements a single methods. from portia import Plan, PlanRunfrom steelthread.evals import EvalTestCase, EvalMetric, PlanRunMetadatadef eval_test_case( self, test_case: EvalTestCase, final_plan: Plan, final_plan_run: PlanRun, additional_data: PlanRunMetadata,) -> list[EvalMetric] | EvalMetric | None: We have seen how to implement a custom LLM-as-Judge as part of the default evaluators from the dashboard so let's focus on using custom assertions to implement a custom, deterministic evaluator. To do that you can attach an assertion to your test case from the dashboard, then use a custom evaluator to assess whether your Eval run complied with it: From the dashboard, navigate to your Eval set and then to the specific test case. Click on the edit icon on the right end of the row. Scroll to the bottom and under 'Add Evaluators' select Run some custom logic based on tags. Enter word_count_limit in the Key textbox and 50 in the Value textbox. This assertion is basically offering this key:value pair as the ground truth reference. Don't forget to scroll back up and hit that 'Save Changes' button (yeah we need to fix the UX so you don't need to scroll so much!). Next we will write a custom evaluator that detects whenever a test case includes an expected_emojis custom assertion so make sure you set that up for one or more test cases in your desired dataset. The custom evaluator loads the value of the custom assertion using the get_custom_assertion method and compares the plan run outputs to it. In this case we are counting the emojis in the final plan run output final_plan_run.outputs.final_output.get_value(), and comparing it to the expected_emojis number entered in the custom assertion via dashboard. from portia import Config, Portia, Plan, PlanRunfrom steelthread.steelthread import SteelThread, EvalConfigfrom steelthread.evals import EvalMetric, Evaluator, EvalTestCase, PlanRunMetadataimport re# Custom evaluator implementation to count emojisclass EmojiEvaluator(Evaluator): def eval_test_case( self, test_case: EvalTestCase, final_plan: Plan, final_plan_run: PlanRun, additional_data: PlanRunMetadata, ) -> list[EvalMetric] | EvalMetric | None: # Load plan run output value string_to_score = ( f\"{final_plan_run.outputs.final_output.get_value()}\" if final_plan_run.outputs.final_output else \"\" ) # Count emojis in the loaded output emoji_pattern = re.compile( \"[\\U0001f600-\\U0001f64f\" # emoticons \"\\U0001f300-\\U0001f5ff\" # symbols & pictographs \"\\U0001f680-\\U0001f6ff\" # transport & map symbols \"\\U0001f1e0-\\U0001f1ff\" # flags \"]+\", flags=re.UNICODE, ) emojis = emoji_pattern.findall(string_to_score) emoji_count = len(emojis) # Compare to the custom assertion expected = int(test_case.get_custom_assertion(\"expected_emojis\") or 2) score = min(emoji_count / expected, 1.0) return EvalMetric.from_test_case( test_case=test_case, name=\"emoji_score\", score=score, description=\"Returns a number lower than 1 if the final output is below max emoji count\" explanation=f\"Target: {expected}, Found: {emoji_count}\", )# Initialize Portiaconfig = Config.from_default()portia = Portia(config=config)# Initialize SteelThread with our custom evaluator to run on your datasetst = SteelThread()st.run_evals( portia, EvalConfig( eval_dataset_name=\"your-eval-dataset-name-here\", config=config, iterations=5, evaluators=[EmojiEvaluator(config)], ),) You should now be able to see emoji_score as a new metric for your dataset in the dashboard.",
      "timestamp": "2025-08-24 06:57:21"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/mcp_session",
      "title": "portia.mcp_session | Portia AI Docs",
      "content": "portia.mcp_session | Portia AI Docs Skip to main contentOn this pageConfiguration and client code for interactions with Model Context Protocol (MCP) servers. This module provides a context manager for creating MCP ClientSessions, which are used to interact with MCP servers. It supports SSE, stdio, and StreamableHTTP transports. NB. The MCP Python SDK is asynchronous, so care must be taken when using MCP functionality from this module in an async context. Classes: SseMcpClientConfig: Configuration for an MCP client that connects via SSE. StdioMcpClientConfig: Configuration for an MCP client that connects via stdio. StreamableHttpMcpClientConfig: Configuration for an MCP client that connects via StreamableHTTP. McpClientConfig: The configuration to connect to an MCP server. SseMcpClientConfig Objects​ class SseMcpClientConfig(BaseModel) Configuration for an MCP client that connects via SSE. StdioMcpClientConfig Objects​ class StdioMcpClientConfig(BaseModel) Configuration for an MCP client that connects via stdio. from_raw​ @classmethoddef from_raw(cls, config: str | dict[str, Any]) -> StdioMcpClientConfig Create a StdioMcpClientConfig from a string. This method is used to create a StdioMcpClientConfig from a string. It supports mcpServers and servers keys methods commonly used in MCP client configs. Arguments: config - The string or dict to parse. Returns: A StdioMcpClientConfig. Raises: ValueError - If the string is not valid JSON or does not contain a valid MCP config. StreamableHttpMcpClientConfig Objects​ class StreamableHttpMcpClientConfig(BaseModel) Configuration for an MCP client that connects via StreamableHTTP. get_mcp_session​ @asynccontextmanagerasync def get_mcp_session( mcp_client_config: McpClientConfig) -> AsyncIterator[ClientSession] Context manager for an MCP ClientSession. Arguments: mcp_client_config - The configuration to connect to an MCP server Returns: An MCP ClientSessionSseMcpClientConfig ObjectsStdioMcpClientConfig ObjectsStreamableHttpMcpClientConfig Objects",
      "timestamp": "2025-08-24 06:57:24"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-request-comments",
      "title": "Zendesk - Request Comments: List | Portia AI Docs",
      "content": "Zendesk - Request Comments: List | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:requests:list_comments Tool description: Lists comments on a Zendesk request. Returns a maximum of 100 comments. A request in Zendesk is intended to be initiated by or on behalf of end users e.g. a customer. A request may be paired with a ticket (an admin/agent perspective of the same request). Args schema: { \"description\": \"Input schema for ZendeskListRequestCommentsTool.\", \"properties\": { \"request_id\": { \"description\": \"The ID of the request\", \"title\": \"Request Id\", \"type\": \"integer\" }, \"since\": { \"anyOf\": [ { \"type\": \"string\" }, { \"type\": \"null\" } ], \"default\": null, \"description\": \"Filters the comments from the given datetime. The datetime must be in ISO 8601 format. Example: 2019-01-01T00:00:00Z\", \"title\": \"Since\" } }, \"required\": [ \"request_id\" ], \"title\": \"ZendeskListRequestCommentsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:57:27"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-ticket",
      "title": "Zendesk - Tickets: Show | Portia AI Docs",
      "content": "Zendesk - Tickets: Show | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:tickets:show Tool description: Returns a number of ticket properties though not the ticket comments. To get the comments, use the ZendeskListTicketCommentsTool. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Args schema: { \"description\": \"Input schema for ZendeskShowTicketTool.\", \"properties\": { \"ticket_id\": { \"description\": \"The ID of the ticket\", \"title\": \"Ticket Id\", \"type\": \"integer\" } }, \"required\": [ \"ticket_id\" ], \"title\": \"ZendeskShowTicketToolSchema\", \"type\": \"object\"} Output schema: ('application/json', \"application/json: Payload from API about a single Zendesk ticket. This includes (but is not limited to) the ticket's subject, description, requester, and status.\")UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:57:30"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-user",
      "title": "Zendesk - Users: Show | Portia AI Docs",
      "content": "Zendesk - Users: Show | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:users:show Tool description: Returns information about a specific user in Zendesk. Args schema: { \"description\": \"Input schema for ZendeskShowUserTool.\", \"properties\": { \"user_id\": { \"description\": \"The ID of the user\", \"title\": \"User Id\", \"type\": \"integer\" } }, \"required\": [ \"user_id\" ], \"title\": \"ZendeskShowUserToolSchema\", \"type\": \"object\"} Output schema: ('application/json', \"application/json: Payload from API containing information about a specific user in Zendesk. A user can be an end-user, agent, or admin. This may include (but is not limited to) the user's name, contact information, role, locale, organization, and other information.\")UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:57:33"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/sentry",
      "title": "Sentry | Portia AI Docs",
      "content": "Sentry | Portia AI Docs Skip to main contentOn this page Description​ Exposes 16+ tools to query issues, search errors and even invoke Seer for automated fixes. Authorisation​ This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail here (↗). Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to authorise with the server via OAuth when you enable it. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:57:36"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/",
      "title": "Local MCP Servers | Portia AI Docs",
      "content": "Local MCP Servers | Portia AI Docs Skip to main content This is a list of official MCP servers that the Portia team have tested. You will find the code snippet to easily load them into Portia in each section. AWS Cost AnalysisAnalyze AWS service costs and generate cost reports. AWS DocumentationProvides tools to access AWS documentation, search for content, and get recommendations. Basic MemoryKnowledge management system that builds a persistent semantic graph in markdown, locally. BioMCPIntegrates with biomedical databases including ClinicalTrials.gov, PubMed, and MyVariant.info to provide structured access to clinical trials, research articles, and genetic variants with intelligent data rendering and source attribution. Bright DataIntegrates with Bright Data's web scraping infrastructure to provide real-time access to public web data through specialized tools for search engine scraping, webpage extraction, and structured data retrieval from popular websites. BrowserbaseAutomate web browsers remotely on a cloud environment. ChargebeeIntegration with Chargebee products and API services to facilitate billing for subscription businesses. ChromaIntegrates with Chroma vector database to enable collection management, document operations, and vector search capabilities for knowledge bases and context-aware conversations. DBHubProvides a universal database gateway for connecting to PostgreSQL, MySQL, SQLite, and DuckDB, enabling table browsing, schema inspection, and read-only SQL queries with built-in safety checks ElevenLabsIntegrates with ElevenLabs to provide high-quality text-to-speech, voice cloning, and conversational capabilities with customizable voice profiles and audio processing features. GCP Cloud RunDeploys applications to Google Cloud Run through automated containerization, project setup, and service management with support for both local files and provided content. GitHubIntegration with GitHub Issues, Pull Requests, and more. GrafanaIntegrates with Grafana to enable searching dashboards, fetching datasource information, querying Prometheus metrics, and managing incidents through both stdio and SSE transport modes. HubSpotIntegrates with HubSpot CRM to enable secure access to contact information, company records, deal data, and task management with customizable data access through Private App scopes. HyperbrowserEnables web browsing capabilities through tools for content extraction, link following, and browser automation with customizable parameters for scraping, data collection, and web crawling tasks. JetBrains IDEInteract with JetBrains IDEs for code analysis and development tasks. MiniMaxEnables high-quality text-to-speech, voice cloning, and video generation capabilities through MiniMax's API with robust error handling and file management features. Monday.comIntegrates with monday.com API to enable direct access to boards, workflows, and data for automating tasks and managing resources without context switching. MongoDBProvides a bridge between MongoDB databases and conversational interfaces, enabling comprehensive database operations, collection management, schema inspection, and Atlas cloud service interactions with authentication and telemetry support. NetlifyIntegrates with Netlify's platform for complete site management including project operations, deployments with zip uploads, team administration, extension configuration, and documentation access across hosting, build, and collaboration workflows. NotionBridges to the Notion API for searching content, querying databases, and managing pages and comments without requiring complex API interaction code PerplexityConnector for the Perplexity API, to enable web search without leaving the MCP ecosystem. PlaywrightEnables web browser control for navigating websites, capturing page snapshots, interacting with elements, and taking screenshots through Playwright's automation capabilities. QdrantStore and retrieve vector-based memories for AI systems. Shopify DevIntegrates with Shopify Dev. Supports various tools to interact with different Shopify APIs. SupabaseConnects directly to Supabase projects for managing databases, executing SQL queries, applying migrations, and handling configurations through natural language commands. TwilioIntegrates with Twilio's API ecosystem to enable messaging, voice, conversations, and serverless functions through authenticated access with automatic AccountSid population and context filtering capabilities. XeroProvides a bridge to the Xero accounting API, enabling financial data interactions and accounting operations through OAuth2 custom connections for automated workflow management.",
      "timestamp": "2025-08-24 06:57:39"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/posthog",
      "title": "Posthog | Portia AI Docs",
      "content": "Posthog | Portia AI Docs Skip to main contentOn this page Description​ Integrates with PostHog to enable querying analytics, errors, running SQL insights, and managing feature flags through natural language interactions. Authorisation​ To use this MCP server, you need API credentials in your environment. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to provide your API key when you enable the server. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:57:42"
    },
    {
      "url": "https://docs.portialabs.ai/",
      "title": "Portia AI Docs",
      "content": "Portia AI Docs Skip to main contentOn this page Welcome to our docs! Portia AI is an open source developer framework. We want to allow any developer to deploy agents that are transparent, steerable and authenticated. Try out our product and give us some feedback on our Discord channel (↗). Overview of Portia AI​ The core product accessible in our Github repository (↗) is extensible with our complimentary cloud features which are aimed at making production deployments easier and faster. With our open source capabilities you should be able to: Ingest a user query and leverage our system prompting to generate a structured plan. Run a plan, invoking tools and tracking the plan run state at every step. Build your own tools. Define clarifications to interrupt a plan run and solicit structured human / machine input when necessary, e.g. to handle required authentication or missing input. Our cloud offering, which can be enabled from the Portia dashboard (↗) works seamlessly with our open source library. It will give you the ability to: Store and retrieve plan run states and review historical plan runs. Invoke tools from remote MCP servers and other cloud-hosted applications, with authentication handled for you. Access the tool call logs of your plan runs. Why Portia AI​ We are beginning our journey as a developer framework by focusing on this problem set. Shout if you think we should add to this list 🙏 ProblemPortia's solutionPlanning: Many use cases require visibility into the LLM’s reasoning, particularly for complex tasks requiring multiple steps and tools. LLMs also struggle picking the right tools as their tool set grows.Pre-expressed plans: Our open source, multi-shot prompter guides your LLM to produce an explicit Plan in response to a prompt, weaving the relevant tools, inputs, and outputs for every step.Execution: Tracking an LLM’s progress mid-task is difficult, making it harder to intervene when guidance is needed. This is especially critical for enforcing company policies or correcting hallucinations (hello, missing arguments in tool calls!)Stateful, steerable agents: Portia will spin up a multi-agent plan to execute and track its state throughout execution via a PlanRun. Using our Clarification abstraction you can define points where you want to take control of plan runs e.g. to resolve missing information or multiple choice decisions. Portia serialises the plan run state, and you can manage its storage / retrieval yourself or use our cloud offering for simplicity.Authentication: Existing solutions often disrupt the user experience with cumbersome authentication flows or require pre-emptive, full access to every tool—an approach that doesn’t scale for multi-agent assistants.Extensible, authenticated tool calling: Bring your own tools on our extensible Tool abstraction, or use our growing plug and play authenticated tool library, which will include a number of popular SaaS providers over time (Google, Zendesk, Hubspot, Github etc.). All Portia tools feature just-in-time authentication with token refresh, offering security without compromising on user experience. Alright let's roll our sleeves up and get you spinning up them agents 🤖! Next up we'll install the SDK locally and validate your setup, before creating a Portia cloud account. 🎉 I'm feeling luckyIf you prefer to just dive right into an example, why not head over to the intro example in our examples repo (↗). Setup and configuration​ Install and setupGet setup and run a query. Set up a Portia accountSign up for a Portia cloud account. Manage your configLearn how to configure your Portia.Overview of Portia AIWhy Portia AISetup and configuration",
      "timestamp": "2025-08-24 06:57:45"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-post-comments",
      "title": "Zendesk - Posts: List Comments | Portia AI Docs",
      "content": "Zendesk - Posts: List Comments | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:help_center:list_post_comments Tool description: Lists all comments on a specific post. Args schema: { \"description\": \"Input schema for ZendeskListPostCommentsTool.\", \"properties\": { \"post_id\": { \"description\": \"The unique ID of the post\", \"title\": \"Post Id\", \"type\": \"integer\" } }, \"required\": [ \"post_id\" ], \"title\": \"ZendeskListPostCommentsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:57:48"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-section",
      "title": "Zendesk - Sections: Show | Portia AI Docs",
      "content": "Zendesk - Sections: Show | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:help_center:show_section Tool description: Returns a section of the Zendesk Help Center articles. Sections group related articles together. Args schema: { \"description\": \"Input schema for ZendeskShowSectionTool.\", \"properties\": { \"section_id\": { \"description\": \"The unique ID of the section\", \"title\": \"Section Id\", \"type\": \"integer\" } }, \"required\": [ \"section_id\" ], \"title\": \"ZendeskShowSectionToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:57:51"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/open-source/file-reader",
      "title": "Open Source - File Reader | Portia AI Docs",
      "content": "Open Source - File Reader | Portia AI Docs Skip to main contentOn this page Usage​ Portia offers both open source tools as well as a cloud-hosted library of tools to save you development time. You can dig into the specs of those tools in our open source repo (SDK repo ↗). You can import our open source tools into your project using from portia.open_source_tools.registry import open_source_tool_registry and load them into an InMemoryToolRegistry object. You can also combine their use with cloud or custom tools as explained in the docs (Add custom tools ↗). Tool details​ Tool ID: file_reader_tool Tool description: Finds and reads content from a local file on Disk Args schema: { \"description\": \"Schema defining the inputs for the FileReaderTool.\", \"properties\": { \"filename\": { \"description\": \"The path (either full or relative) where the file should be read from\", \"title\": \"Filename\", \"type\": \"string\" } }, \"required\": [ \"filename\" ], \"title\": \"FileReaderToolSchema\", \"type\": \"object\"} Output schema: ('str', 'A string dump or JSON of the file content')UsageTool details",
      "timestamp": "2025-08-24 06:57:54"
    },
    {
      "url": "https://docs.portialabs.ai/running-in-production",
      "title": "Running in production | Portia AI Docs",
      "content": "Running in production | Portia AI Docs Skip to main content📄️ Using agent memoryWith Portia, agents can leverage memory by default.📄️ Agent observabilityUsing Langsmith📄️ Managing end usersWhilst building an agent for yourself can be very rewarding most agentic use cases run for many users. For example you may be an engineer creating a new agent for all the staff in your business. It may be important for the agent to know information about the specific member of staff that the agent is running for. Imagine a query like \"Send me a summary of the latest results\". This requires information about who the \"me\" is.📄️ Execution hooksExecution hooks provide the ability for users to extend, intervene in or modify the running of agents in Portia, including allowing human control to be overlayed into the multi-agent plan run deterministically.",
      "timestamp": "2025-08-24 06:57:57"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-ticket-comments",
      "title": "Zendesk - Tickets: List Comments | Portia AI Docs",
      "content": "Zendesk - Tickets: List Comments | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:tickets:list_comments Tool description: Returns the comments added to the ticket. Each comment may include a content_url for an attachment or a recording_url for a voice comment that points to a file that may be hosted externally. A ticket in Zendesk is intended to be used by agents or admins. They can be used to track and resolve requests raised by end users (e.g. customer service) or for internal issue tracking. Args schema: { \"description\": \"Input schema for ZendeskListTicketCommentsTool.\", \"properties\": { \"ticket_id\": { \"description\": \"The ID of the ticket\", \"title\": \"Ticket Id\", \"type\": \"integer\" } }, \"required\": [ \"ticket_id\" ], \"title\": \"ZendeskListTicketCommentsToolSchema\", \"type\": \"object\"} Output schema: ('application/json', 'application/json: Payload from API containing a list of comments on a Zendesk ticket.')UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:58:00"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/get-conversation",
      "title": "Slack - Conversation: Get History | Portia AI Docs",
      "content": "Slack - Conversation: Get History | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Slack tools with Portia AI​ You will need to create your own Slack App to use with Portia AI. This is so you can control the name and appearance of slack bot activity initiated via the Portia AI framework. Once your slack app is created you can configure your client ID and secret in the Portia dashboard. Install a Slack app​ Head over to api.slack.com/apps ↗ Create an app from scratch and select the Slack workplace you would like to use it in. Note down the client ID and secret on the Basic Information page. We will need this in a couple of steps from now! In the OAuth & Permissions tab further down in the left hand nav, add as Redirect URL the following URL https://api.portialabs.ai/api/v0/oauth/slack (don't forget to hit that Save URLs button!). Under Bot Token Scopes, be sure to add the scopes channels:history -- View messages and other content in public channels that your Slack app has been added to. channels:read -- View basic information about public channels in a workspace. chat:write -- Send messages as @{your slack app name}. users:read -- View people in a workspace. Under User Token Scopes, be sure to add the scope search:read to support searching workplace content. Now scroll up to the top of the OAuth & Permissions page and hit the Install to {your workplace name} button. Once that is done, open your Slack app and hit 'Add apps` and be sure to select your new app. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the client ID and secret of your Slack app as collected in step 3 of the Slack installation process above. You are now ready to call Slack tools on our cloud! Tool details​ Tool ID: portia:slack:user:conversation_history Tool description: Get the conversation history for a given channel by channel id. Requires an ID typically from the list_conversation_ids tool. Args schema: { \"description\": \"Input for GetSlackConversationTool.\", \"properties\": { \"channel_id\": { \"description\": \"The channel/group/private message id to get the conversation history for.\", \"title\": \"Channel Id\", \"type\": \"string\" }, \"limit\": { \"default\": 20, \"description\": \"The maximum number of messages to return. Default is 20. Too many messages cancause the context window to be exceeded.\", \"title\": \"Limit\", \"type\": \"integer\" } }, \"required\": [ \"channel_id\" ], \"title\": \"GetSlackConversationToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Object per message with text, user, and replies if follow_threads is true')UsageConfigure your Slack tools with Portia AIInstall a Slack appConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:58:03"
    },
    {
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/one_shot_agent",
      "title": "portia.execution_agents.one_shot_agent | Portia AI Docs",
      "content": "portia.execution_agents.one_shot_agent | Portia AI Docs Skip to main contentOn this pageA simple OneShotAgent optimized for simple tool calling tasks. This agent invokes the OneShotToolCallingModel up to four times, but each individual attempt is a one-shot call. It is useful when the tool call is simple, minimizing cost. However, for more complex tool calls, the DefaultExecutionAgent is recommended as it will be more successful than the OneShotAgent. ExecutionState Objects​ class ExecutionState(MessagesState) State for the execution agent. OneShotToolCallingModel Objects​ class OneShotToolCallingModel() One-shot model for calling a given tool. This model directly passes the tool and context to the language model (LLM) to generate a response. It is suitable for simple tasks where the arguments are already correctly formatted and complete. This model does not validate arguments (e.g., it will not catch missing arguments). It is recommended to use the DefaultExecutionAgent for more complex tasks. Arguments: model GenerativeModel - The language model to use for generating responses. tools list[StructuredTool] - A list of tools that can be used during the task. agent OneShotAgent - The agent responsible for managing the task. Methods: invoke(MessagesState) - Invokes the LLM to generate a response based on the query, context, and past errors. __init__​ def __init__(model: GenerativeModel, tools: list[StructuredTool], agent: OneShotAgent, tool_context: ToolRunContext) -> None Initialize the OneShotToolCallingModel. Arguments: model GenerativeModel - The language model to use for generating responses. tools list[StructuredTool] - A list of tools that can be used during the task. agent OneShotAgent - The agent that is managing the task. tool_context ToolRunContext - The context for the tool. invoke​ def invoke(state: ExecutionState) -> dict[str, Any] Invoke the model with the given message state. This method formats the input for the language model using the query, context, and past errors, then generates a response by invoking the model. Arguments: state ExecutionState - The state containing the messages and other necessary data. Returns: dict[str, Any]: A dictionary containing the model's generated response. ainvoke​ async def ainvoke(state: ExecutionState) -> dict[str, Any] Async implementation of invoke. This method formats the input for the language model using the query, context, and past errors, then generates a response by invoking the model. Arguments: state ExecutionState - The state containing the messages and other necessary data. Returns: dict[str, Any]: A dictionary containing the model's generated response. OneShotAgent Objects​ class OneShotAgent(BaseExecutionAgent) Agent responsible for achieving a task by using langgraph. This agent performs the following steps: Extracts inputs from agent memory (if applicable) Calls the tool with unverified arguments. Retries tool calls up to 4 times. Methods: execute_sync() - Executes the core logic of the agent's task, using the provided tool __init__​ def __init__(plan: Plan, plan_run: PlanRun, config: Config, agent_memory: AgentMemory, end_user: EndUser, tool: Tool | None = None, execution_hooks: ExecutionHooks | None = None) -> None Initialize the OneShotAgent. Arguments: plan Plan - The plan containing the steps. plan_run PlanRun - The run that defines the task execution process. config Config - The configuration settings for the agent. agent_memory AgentMemory - The agent memory for persisting outputs. end_user EndUser - The end user for the execution. tool Tool | None - The tool to be used for the task (optional). execution_hooks ExecutionHooks | None - The execution hooks for the agent. execute_sync​ def execute_sync() -> Output Run the core execution logic of the task. This method will invoke the tool with arguments Returns: Output - The result of the agent's execution, containing the tool call result. execute_async​ async def execute_async() -> Output Run the core execution logic of the task. This method will invoke the tool with arguments Returns: Output - The result of the agent's execution, containing the tool call result. ExecutionState ObjectsOneShotToolCallingModel ObjectsOneShotAgent Objects",
      "timestamp": "2025-08-24 06:58:06"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-draft-email",
      "title": "Microsoft Outlook - Outlook: Draft | Portia AI Docs",
      "content": "Microsoft Outlook - Outlook: Draft | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Selecting Microsoft Tools​ Microsoft tools are included in Portia's cloud registry but are not included in the default DefaultToolRegistry class. This is due to tool clashes with the Google tools (i.e. the agent wouldn't know whether to check Gmail or Outlook for email tasks). In order to use Microsoft tools rather than Google tools, simply filter out the Google tools from the Portia cloud registry rather than using the default registry: from portia import PortiaToolRegistry, default_configregistry = PortiaToolRegistry(default_config()).filter_tools(lambda tool: not tool.id.startswith(\"portia:google:\"))registry = PortiaToolRegistry(default_config()).filter_tools( lambda tool: not tool.id.startswith(\"portia:google:\")) Tool details​ Tool ID: portia:microsoft:outlook:draft_email Tool description: Drafts an email for the recipients indicated. Should not be used with the send email tool. Instead to send a draft email use the send_draft_email_tool. If the user hasn't given you an explicit title or body to the email, choose something appropriate based on the context of the email. Args schema: { \"description\": \"Input for DraftEmailTool.\", \"properties\": { \"recipients\": { \"description\": \"The recipients that the email should be drafted for (should be a list of email addresses)\", \"items\": { \"type\": \"string\" }, \"title\": \"Recipients\", \"type\": \"array\" }, \"email_title\": { \"description\": \"The title of the email draft\", \"title\": \"Email Title\", \"type\": \"string\" }, \"email_body\": { \"description\": \"The body of the email draft\", \"title\": \"Email Body\", \"type\": \"string\" } }, \"required\": [ \"recipients\", \"email_title\", \"email_body\" ], \"title\": \"DraftEmailToolSchema\", \"type\": \"object\"} Output schema: ('dict', 'dict: Output of the email drafted')UsageSelecting Microsoft ToolsTool details",
      "timestamp": "2025-08-24 06:58:09"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/hugging-face",
      "title": "Hugging Face | Portia AI Docs",
      "content": "Hugging Face | Portia AI Docs Skip to main contentOn this page Description​ Integrates with Hugging Face's ecosystem to search models, datasets, and papers while dynamically connecting to Gradio-based tools hosted on Spaces for extended ML capabilities. Authorisation​ This server does not require any extra authentication to use, other than the MCP server URL. Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:58:12"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/twilio",
      "title": "Twilio | Portia AI Docs",
      "content": "Twilio | Portia AI Docs Skip to main contentOn this page Description​ Integrates with Twilio's API ecosystem to enable messaging, voice, conversations, and serverless functions through authenticated access with automatic AccountSid population and context filtering capabilities. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"twilio\", command=\"npx\", args=[\"-y\", \"@twilio-alpha/mcp\", \"YOUR_ACCOUNT_SID/YOUR_API_KEY:YOUR_API_SECRET\"],) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"twilio\", command=\"npx\", args=[\"-y\", \"@twilio-alpha/mcp\", \"YOUR_ACCOUNT_SID/YOUR_API_KEY:YOUR_API_SECRET\"],) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:58:15"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/aws-cost-analysis",
      "title": "AWS Cost Analysis | Portia AI Docs",
      "content": "AWS Cost Analysis | Portia AI Docs Skip to main contentOn this page Description​ Analyze AWS service costs and generate cost reports. Visit the server homepage (↗) for more information about how to use this MCP server. Authorisation​ To use this MCP server, you need API credentials in your environment. Please refer to the server homepage (↗) for more information. Usage​ To use this MCP server in your Portia project, you need to create an McpToolRegistry instance and pass it to the Portia constructor. McpToolRegistry.from_stdio_connection( server_name=\"awslabs.cost-analysis-mcp-server\", command=\"uvx\", args=[\"awslabs.cost-analysis-mcp-server@latest\"], env={\"FASTMCP_LOG_LEVEL\": \"ERROR\", \"AWS_PROFILE\": \"<aws_profile>\"},) Complete exampleEquip your Portia instance with the tools from the MCP server, in addition to the default tools from the DefaultToolRegistry:from portia import DefaultToolRegistry, McpToolRegistry, Portia, Configconfig = Config.from_default()tool_registry = DefaultToolRegistry(config) + McpToolRegistry.from_stdio_connection( server_name=\"awslabs.cost-analysis-mcp-server\", command=\"uvx\", args=[\"awslabs.cost-analysis-mcp-server@latest\"], env={\"FASTMCP_LOG_LEVEL\": \"ERROR\", \"AWS_PROFILE\": \"<aws_profile>\"},) portia = Portia(config=config, tools=tool_registry) Copy to clipboardClick the \"copy\" icon in the top right corner of the code block to copy the code to your clipboard. See more information about integrating MCP servers here (↗).DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:58:18"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-organization",
      "title": "Zendesk - Organizations: Show | Portia AI Docs",
      "content": "Zendesk - Organizations: Show | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Configure your Zendesk tools with Portia AI​ You will need to provide the subdomain of your Zendesk account to use with Portia AI. This is because Zendesk creates a unique subdomain for each account. Configure access in Portia AI​ Log into your Portia dashboard ↗ Navigate to the Manage Org tab. Enter the subdomain of your Zendesk account. Your subdomain is the part of your Zendesk URL before the .zendesk.com domain. For example, if your Zendesk URL is https://portialabs.zendesk.com, your subdomain is portialabs. You are now ready to call Zendesk tools on our cloud! Tool details​ Tool ID: portia:zendesk:organizations:show Tool description: Gets information about a specific organization in Zendesk. Args schema: { \"description\": \"Input schema for ZendeskShowOrganizationTool.\", \"properties\": { \"organization_id\": { \"description\": \"The ID of an organization\", \"title\": \"Organization Id\", \"type\": \"integer\" } }, \"required\": [ \"organization_id\" ], \"title\": \"ZendeskShowOrganizationToolSchema\", \"type\": \"object\"} Output schema: ('application/json', \"application/json: Payload from API containing information about a specific organization in Zendesk. This includes (but is not limited to) the organization's name, details, and domain.\")UsageConfigure your Zendesk tools with Portia AIConfigure access in Portia AITool details",
      "timestamp": "2025-08-24 06:58:21"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/square",
      "title": "Square | Portia AI Docs",
      "content": "Square | Portia AI Docs Skip to main contentOn this page Description​ Provides a bridge between Square's complete API ecosystem and conversational interfaces, enabling comprehensive e-commerce and payment processing capabilities including payments, orders, inventory, and customer management. Authorisation​ This server uses OAuth2 for authentication. The first time an end-user uses a tool from this server in a plan run, a clarification will be raised which redirects them to the server provider's login page. This process is described in more detail here (↗). Usage​ Remote MCP servers are available in the Portia cloud dashboard. After you have created your Portia account (↗), you can enable the server via the Portia cloud tool registry (↗). You will be requested to authorise with the server via OAuth when you enable it. Once enabled, set your Portia API key in your environment and the tools will be available to use in the DefaultToolRegistry. Listing the tools with the CLI: $ PORTIA_API_KEY=<your-api-key> portia-cli list-tools Using the DefaultToolRegistry in your code: from portia import DefaultToolRegistry, Portia, Configconfig = Config.from_default()portia = Portia(config=config, tools=DefaultToolRegistry(config))DescriptionAuthorisationUsage",
      "timestamp": "2025-08-24 06:58:24"
    },
    {
      "url": "https://docs.portialabs.ai/evals-results",
      "title": "Visualise Eval results | Portia AI Docs",
      "content": "Visualise Eval results | Portia AI Docs Skip to main content Results from Evals are pushed to the Portia UI for visualization. This allows you to quickly see trends over time and to drill into why metrics may have changed. Clicking into a dataset will show you a summary of the current metrics for that dataset. Metrics are plotted by run. You can expand each graph to get a detailed view of the metric. This also allows you to group the metric by any tags that were attached. Clicking on a specific run will bring up the detailed summary of each test case from that run. Finally clicking on a specific test case will show you the details of each metric.",
      "timestamp": "2025-08-24 06:58:27"
    },
    {
      "url": "https://docs.portialabs.ai/streams-overview",
      "title": "Overview and basic usage | Portia AI Docs",
      "content": "Overview and basic usage | Portia AI Docs Skip to main contentOn this page Streams are a way to sample real plans and plan runs from your Portia cloud account allowing you to monitor the performance of your agents in production. The overall flow is: From the Portia dashboard, create a new stream including the desired sampling rate. You can rely on the default evaluators offered by Portia or create your own. Process your stream periodically to pick up all plan runs that haven't been sampled yet. Steel Thread will process each Plan or PlanRun in the stream using your preferred evaluators. Visualize the metrics from each run in the Portia UI. Get your Portia API keyPlease make sure you have a PORTIA_API_KEY set up in your environment to use Steel Thread, as it relies on plans and plan runs stored in Portia cloud. Basic usage​ Let's create a Stream from the 'Observability' tab in the dashboard: Give your stream a memorable name we can refer to in the code. Select 'Plan Runs' as your Stream source -- SteelThread allows you to monitor Plans more specifically if you wanted to. Select 100% as your sampling rate for this demo -- We allow you to dial up or down your sampling rate depending on how close an eye you need to keep on your agents. Now that our Stream is created, it can be used to sample future runs and score based on a number of evaluators. Make sure you have some plan run data generated after the stream is created so that we can sample it as shown below. from portia import Configfrom steelthread.steelthread import SteelThread, StreamConfigfrom dotenv import load_dotenvload_dotenv(override=True)config = Config.from_default()# Setup SteelThread instance and process streamst = SteelThread()st.process_stream( StreamConfig( # The stream name is the name of the stream we created in the dashboard. stream_name=\"your-stream-name-here\", config=config, )) Default evaluators​ The StreamConfig object above takes a list of evaluators (of type StreamEvaluator) as an argument. SteelThread's LLMJudgeEvaluator is available off the shelf and is used by default when no evaluators are specified. It is an LLM-as-judge evaluator and it computes the list of metrics below: If you're sampling plans:​ MetricDescriptioncorrectnessAre the steps logically valid?completenessAre all necessary steps included?clearnessAre the steps clearly written and easy to follow? If you're sampling plan runs:​ MetricDescriptionsuccessDid the run accomplish its intended goal?efficiencyWere the steps necessary and minimal? Once you process a stream you should be able to see the results in the dashboard, from the 'Observabilitytab. Navigate to your stream's results by clicking on your stream name from there. You should seesuccessandefficiency` metrics aggregated at the stream processing time stamp. You can drill into the sampled plan runs under each timestamp by clicking on the relevant row in the table. How sampling works with StreamsEvery time you process a stream (by running the process_stream method above), SteelThread evaluates all plan runs since the last stream processing timestamp. Think of it as a FIFO queue of plans / plan runs where items are inserted every time you generate a plan / plan run and removed every time you process the stream.Basic usageDefault evaluators",
      "timestamp": "2025-08-24 06:58:33"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/",
      "title": "Slack Tools | Portia AI Docs",
      "content": "Slack Tools | Portia AI Docs Skip to main content Conversation: Get HistoryGet the conversation history for a given channel by channel id. Requires an ID typically from the list_conversation_ids tool. Conversation: ListList all conversations meta information only without comments in the slack workspaceThis tool should be used when you need to make api calls to other slack apis that requirea conversation or channel id. DOES NOT RETURN MESSAGES, CONVERSATION HISTORY, OR USER IDS. Message: FindSearch for a message in a Slack channel or chat. Message: SendSend a message to a specific Slack channel or user by ID. Requires an ID provided by other tools. Users: ListList all users in the slack workspace. Returns user meta information: Name, ID, and EmailThis tool should be used when you need to make api calls to other slack apis that requirea user ID.",
      "timestamp": "2025-08-24 06:58:36"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github/search-repos",
      "title": "GitHub - Repository: Search | Portia AI Docs",
      "content": "GitHub - Repository: Search | Portia AI Docs Skip to main contentOn this page Usage​ All Portia tools using API endpoints that require OAuth are built with plug and play authentication support. They use Portia client credentials including client ID, client name and redirect URL. Such tools will raise a Action Clarification with an OAuth link as the action URL. The portia.wait_for_ready() method must be used in this scenario: Portia's OAuth server will listen for the authentication result and resolve the concerned clarification, allowing your plan run to resume again. For more on this, please visit to the section on running Portia tools (↗). Tool details​ Tool ID: portia:github::search_repos Tool description: Searches all public repositories for a specific term. Args schema: { \"description\": \"Schema for the SearchGitHubReposTool input.\", \"properties\": { \"search_term\": { \"description\": \"The term to search for.\", \"title\": \"Search Term\", \"type\": \"string\" } }, \"required\": [ \"search_term\" ], \"title\": \"SearchGitHubReposSchema\", \"type\": \"object\"} Output schema: ('list', 'A list of public repositories that match.')UsageTool details",
      "timestamp": "2025-08-24 06:58:39"
    },
    {
      "url": "https://docs.portialabs.ai/manage-config",
      "title": "Manage your config | Portia AI Docs",
      "content": "Manage your config | Portia AI Docs Skip to main contentOn this page Learn how to use your Portia instance's Config to configure LLM and agent execution options, and select different plan and plan run storage options. TL;DRThe Config class of your Portia instance allows you to: Configure your LLM provider, model and API key Save plans and runs to disk or the Portia cloud Manage logging behaviour Configure LLM options​ The Config class (SDK reference ↗) allows you to control various LLM and agent execution options. LLM provider​ Portia uses providers such as OpenAI and Anthropic for usage of generative AI models. You can configure the provider that Portia will use with the llm_provider config setting. If set, this decides which generative AI models are used in Portia defined Agents and Tools. Portia has built-in defaults for which models to use for each provider, so at a minimum you only need to set this property. Options for setting the LLM provider are: OptionValuesLLMProvider enumLLMProvider.OPENAILLMProvider.ANTHROPICLLMProvider.MISTRALAILLMProvider.GOOGLELLMProvider.AZURE_OPENAILLMProvider.OLLAMA LLMProvider.AMAZONProvider name (str)\"openai\"\"anthropic\"\"mistralai\"\"google\"\"azure-openai\"\"ollama\"\"amazon\"Inferred from environment variableOPENAI_API_KEYANTHROPIC_API_KEYMISTRAL_API_KEYGOOGLE_API_KEYAZURE_OPENAI_API_KEYAWS_ACCESS_KEY_IDAWS_SECRET_KEY_IDAWS_DEFAULT_REGIONAWS_CREDENTIALS_PROFILE_NAME Examples:​ Open AIAnthropicMistral AIGoogleAzure OpenAIAmazon BedrockUsing the LLMProvider enum:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=LLMProvider.OPENAI)Passing the Provider name as a string value:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=\"anthropic\")Inferred from environment variables (if OPENAI_API_KEY=sk-... is in the environment variables):from portia import LLMProvider, Configconfig = Config.from_default() # config.llm_provider => LLMProvider.OPENAIUsing the LLMProvider enum:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=LLMProvider.ANTHROPIC)Passing the Provider name as a string value:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=\"anthropic\")Inferred from environment variables (if ANTHROPIC_API_KEY=sk-... is in the environment variables):from portia import LLMProvider, Configconfig = Config.from_default() # config.llm_provider => LLMProvider.ANTHROPICUsing the LLMProvider enum:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=LLMProvider.MISTRALAI)Passing the Provider name as a string value:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=\"mistralai\")Inferred from environment variables (if MISTRAL_API_KEY=sk-... is in the environment variables):from portia import LLMProvider, Configconfig = Config.from_default() # config.llm_provider => LLMProvider.MISTRALAIUsing the LLMProvider enum:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=LLMProvider.GOOGLE)Passing the Provider name as a string value:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=\"google\")Inferred from environment variables (if GOOGLE_API_KEY=sk-... is in the environment variables):from portia import LLMProvider, Configconfig = Config.from_default() # config.llm_provider => LLMProvider.GOOGLEUsing the LLMProvider enum:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=LLMProvider.AZURE_OPENAI)Passing the Provider name as a string value:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=\"azure-openai\")Inferred from environment variables (if AZURE_OPENAI_API_KEY=sk-... and AZURE_OPENAI_ENDPOINT=https://... are in the environment variables):from portia import LLMProvider, Configconfig = Config.from_default() # config.llm_provider => LLMProvider.AZURE_OPENAIUsing the LLMProvider enum:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=LLMProvider.AMAZON)Passing the Provider name as a string value:from portia import LLMProvider, Configconfig = Config.from_default(llm_provider=\"amazon\")Inferred from environment variables (if AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_DEFAULT_REGION OR AWS_CREDENTIALS_PROFILE_NAME):from portia import LLMProvider, Configconfig = Config.from_default() # config.llm_provider => LLMProvider.AMAZON API keys​ The API keys for the LLM Providers can be set via Config class properties or environment variables. OptionValuesConfig propertyopenai_api_keyanthropic_api_keymistralai_api_keygoogle_api_keyazure_openai_api_key aws_access_key_idaws_secret_key_idaws_default_regionaws_credentials_profile_nameEnvironment variableOPENAI_API_KEYANTHROPIC_API_KEYMISTRAL_API_KEYGOOGLE_API_KEYAZURE_OPENAI_API_KEYAWS_ACCESS_KEY_IDAWS_SECRET_KEY_IDAWS_DEFAULT_REGIONAWS_CREDENTIALS_PROFILE_NAME Examples:​ OpenAIAnthropicMistral AIGoogleAzure OpenAIAmazon BedrockPassing the API key to the Config class:from portia import Configconfig = Config.from_default(openai_api_key=\"sk-...\")Passing the API key to the Config class:from portia import Configconfig = Config.from_default(anthropic_api_key=\"sk-...\")Passing the API key to the Config class:from portia import Configconfig = Config.from_default(mistralai_api_key=\"sk-...\")Passing the API key to the Config class:from portia import Configconfig = Config.from_default(google_api_key=\"sk-...\")Passing the API key to the Config class:from portia import Config# NB You must also set the Azure OpenAI endpoint to your Azure OpenAI instance!config = Config.from_default(azure_openai_api_key=\"sk-...\", azure_openai_endpoint=\"https://...\")Passing the API key to the Config class:from portia import Config# NB You must provide (aws_access_key_id, aws_secret_access_key and aws_default_region) OR aws_credentials_profile_name.config = Config.from_default(aws_access_key_id='..', aws_secret_access_key='...', ..) Model overrides​ You can configure Portia to use specific models for different components, overriding the default model for the LLM provider. You might do this if you want to: Trade off cost against performance, for example using a cheaper model for planning Extend Portia to support an LLM provider that we do not natively support Mix and match models from different providers, for example using OpenAI o3-mini for planning and Anthropic Claude 3.7 Sonnet for everything else The preferred way to do this is via the Config.from_default(...) method, which allows you to specify the models using the following arguments: default_model - The fallback default model for all use-cases if not specified elsewhere planning_model - The model used for the Planning process execution_model - The model used for the execution of a step introspection_model - The model used for evaluating conditionals summarizer_model - The model used for summarizing the output of a step You can configure each of these models in the following ways: OptionValueModel name (str)A str in the form provider/model_name, for example openai/gpt-4.1. See tip below for more examples.Model object (GenerativeModel)An instance of a GenerativeModel class. See the Bring your own models section below for more details. Alternatively, if setting the models directly in the Config class, you should use the models property, which is a GenerativeModelsConfig object (SDK reference ↗). See the example below for more details. Configuring models with model namesModel strings are in the format provider/model_name, where the provider is the string value of the LLM provider (e.g. openai) and the model_name is the name of the model you want to use. Examples: openai/gpt-4.1 anthropic/claude-3-5-sonnet mistralai/mistral-large-latest google/gemini-1.5-flash azure-openai/gpt-4o amazon/eu.anthropic.claude-3-7-sonnet-20250219-v1:0 Examples:​ Open AIAnthropicMistral AIGoogleAzure OpenAIAmazon BedrockSetting the default model by its name:from portia import Configconfig = Config.from_default(default_model=\"openai/gpt-4.1\")Setting the default model by its name:from portia import Configconfig = Config.from_default(default_model=\"anthropic/claude-3-5-sonnet-latest\")Setting the default model by its name:from portia import Configconfig = Config.from_default(default_model=\"mistralai/mistral-large-latest\")Setting the default model by its name:from portia import Configconfig = Config.from_default(default_model=\"google/gemini-2.0-flash\")Setting the default model by its name:from portia import Configconfig = Config.from_default(default_model=\"azure-openai/gpt-4o\")Setting the default model by its name:from portia import Configconfig = Config.from_default(default_model=\"amazon/eu.anthropic.claude-3-7-sonnet-20250219-v1:0\") Mixing and matching models from different providers. Make sure that the relevant API keys are set in the environment variables, or passed along with the model name: from portia import Configconfig = Config.from_default(default_model=\"openai/gpt-4.1\", planning_model=\"anthropic/claude-3-5-sonnet\") Models for tools​ A couple of the tools provided in the Portia SDK use generative models to complete tasks, specifically: LLMTool (SDK reference ↗) ImageUnderstandingTool (SDK reference ↗) You can replace the tool in the DefaultToolRegistry with your own instance of the tool that uses a different model by passing a model directly to the tool constructor: Open AIAnthropicMistral AIGoogleAzure OpenAIAmazon Bedrockimport dotenvfrom portia import Config, DefaultToolRegistry, LLMTool, Portiadotenv.load_dotenv()config = Config.from_default()tool_registry = DefaultToolRegistry(config).replace_tool( LLMTool(model=\"openai/gpt-4.1-mini\"))portia = Portia(config=config, tools=tool_registry)import dotenvfrom portia import Config, DefaultToolRegistry, LLMTool, Portiadotenv.load_dotenv()config = Config.from_default()tool_registry = DefaultToolRegistry(config).replace_tool( LLMTool(model=\"anthropic/claude-3-5-sonnet-latest\"))portia = Portia(config=config, tools=tool_registry)import dotenvfrom portia import Config, DefaultToolRegistry, LLMTool, Portiadotenv.load_dotenv()config = Config.from_default()tool_registry = DefaultToolRegistry(config).replace_tool( LLMTool(model=\"mistralai/mistral-large-latest\"))portia = Portia(config=config, tools=tool_registry)import dotenvfrom portia import Config, DefaultToolRegistry, LLMTool, Portiadotenv.load_dotenv()config = Config.from_default()tool_registry = DefaultToolRegistry(config).replace_tool( LLMTool(model=\"google/gemini-2.0-flash\"))portia = Portia(config=config, tools=tool_registry)import dotenvfrom portia import Config, DefaultToolRegistry, LLMTool, Portiadotenv.load_dotenv()config = Config.from_default()tool_registry = DefaultToolRegistry(config).replace_tool( LLMTool(model=\"azure-openai/gpt-4o\"))portia = Portia(config=config, tools=tool_registry)import dotenvfrom portia import Config, DefaultToolRegistry, LLMTool, Portiadotenv.load_dotenv()config = Config.from_default()tool_registry = DefaultToolRegistry(config).replace_tool( LLMTool(model=\"amazon/eu.anthropic.claude-sonnet-4-20250514-v1:0\"))portia = Portia(config=config, tools=tool_registry) NBIf you do not provide a model, the default model for the LLM provider will be used. Bring your own models​ You can bring your own models to Portia by implementing the GenerativeModel base class (SDK reference ↗) and passing an instance of your class to the Config class. from typing import TypeVarfrom portia import Config, GenerativeModel, LLMProvider, Messagefrom pydantic import BaseModelfrom langchain_core.language_models.chat_models import BaseChatModelBaseModelT = TypeVar(\"BaseModelT\", bound=BaseModel)class MyGenerativeModel(GenerativeModel): provider: LLMProvider = LLMProvider.CUSTOM def get_response(self, messages: list[Message]) -> Message: \"\"\"Requires implementation\"\"\" def get_structured_response( self, messages: list[Message], schema: type[BaseModelT], ) -> BaseModelT: \"\"\"Requires implementation\"\"\" def to_langchain(self) -> BaseChatModel: \"\"\"Requires implementation\"\"\"config = Config.from_default( default_model=MyGenerativeModel(\"my-model-name\")) In this case you do not need to set the llm_provider config setting, or provide any API keys. NBCurrently Portia relies on LangChain BaseChatModel clients in several places, so we are limited to the models that LangChain supports. Thankfully, this is a very broad set of models, so there is a good chance that your model of choice is supported. Manage storage options​ You can control where you store and retrieve plan run states using the storage_class property in the Config class (SDK reference ↗), which is an ENUM accessible from the StorageClass class: MEMORY allows you to use working memory (default if PORTIA_API_KEY is not specified). DISK allows you to use local storage. You will need to set the storage_dir appropriately (defaults to .portia in the directory you are running Portia from). CLOUD uses the Portia cloud (Use Portia cloud ↗ - default if PORTIA_API_KEY is specified). Manage logging​ You can control logging behaviour with the following Config properties (SDK reference ↗): PropertyPurposedefault_log_levelControls the minimal log level, i.e. setting it to DEBUG will print all logs whereas setting it to ERROR will only display ERROR logs and above. This defaults to INFO. The ENUM is accessible via the LogLevel classdefault_log_sinkControls where logs are sent. By default this string is set to \"sys.stdout\" (STDOUT) but can also be set to \"sys.stderr\" (STDERR) or to a file by setting this to a file path e.g. \"./logs.txt\"json_log_serializeSets whether logs are JSON serialized before sending them to the log sink. Manage caching​ PropertyPurposellm_redis_cache_urlYou can specify a URL for a redis instance for the purposes of LLM caching using the llm_redis_cache_url property of your Portia client Config. This can also be set with the LLM_REDIS_CACHE_URL environment variable. If this is set, then we will hit this cache instance before any calls to LLMs. The URL should include any auth details that are needed for access to the redis including username/password e.g. redis://default:$PASSWORD@localhost:6379 Bringing it all together​ Tavily API key requiredWe will use a simple GET endpoint from Tavily in this section. Please sign up to obtain an API key from them (↗) and set it in the environment variable TAVILY_API_KEY. Let's test out a couple of these parameters. We will start first by loading the default config values within the Config class using the from_default method. This method uses the default_config within the Config class as the baseline and allows you to tweak specific attributes: We will explicitly save plans and runs to disk in a demo_runs directory. In the default config the storage_class is set to MEMORY so we will change it to DISK We will set the default_log_level to DEBUG, which will result in the generated plan, every change in the plan run state and all tool calls appearing in the logs. main.pyfrom dotenv import load_dotenvfrom portia import ( Config, LogLevel, Portia, StorageClass,)from portia.open_source_tools.registry import example_tool_registryload_dotenv()# Load the default config with specified storage, logging and caching optionsmy_config = Config.from_default( storage_class=StorageClass.DISK, storage_dir='demo_runs', # Amend this based on where you'd like your plans and plan runs saved! default_log_level=LogLevel.DEBUG, llm_redis_cache_url=\"redis://localhost:6379\")# Instantiate a Portia instance. Load it with the default config and with some example toolsportia = Portia(config=my_config, tools=example_tool_registry)# Execute the plan run from the user queryoutput = portia.run('Which stock price grew faster in 2024, Amazon or Google?')# Serialise into JSON and print the outputprint(output.model_dump_json(indent=2)) In your demo_runs directory, you should now be able to see a plan and a plan run written to disk per the changes made to the Config. Generated planPlan run in final stateplan-72cb538e-6d2b-42ca-a6c2-511a9a4c4f0e.json{ \"id\": \"plan-72cb538e-6d2b-42ca-a6c2-511a9a4c4f0e\", \"plan_context\": { \"query\": \"Which stock price grew faster in 2024, Amazon or Google?\", \"tool_ids\": [ \"calculator_tool\", \"weather_tool\", \"search_tool\" ] }, \"steps\": [ { \"task\": \"Search for the stock price growth of Amazon in 2024.\", \"inputs\": [], \"tool_id\": \"search_tool\", \"output\": \"$amazon_stock_growth_2024\" }, { \"task\": \"Search for the stock price growth of Google in 2024.\", \"inputs\": [], \"tool_id\": \"search_tool\", \"output\": \"$google_stock_growth_2024\" }, { \"task\": \"Compare the stock price growth of Amazon and Google in 2024.\", \"inputs\": [ { \"name\": \"$amazon_stock_growth_2024\", \"description\": \"The stock price growth of Amazon in 2024.\" }, { \"name\": \"$google_stock_growth_2024\", \"description\": \"The stock price growth of Google in 2024.\" } ], \"tool_id\": \"llm_tool\", \"output\": \"$faster_growth\" } ]}prun-e3a77013-2bd4-459c-898c-6a8cc9e77d12.json{ \"id\": \"prun-e3a77013-2bd4-459c-898c-6a8cc9e77d12\", \"plan_id\": \"plan-72cb538e-6d2b-42ca-a6c2-511a9a4c4f0e\", \"current_step_index\": 2, \"state\": \"COMPLETE\", \"outputs\": { \"clarifications\": [], \"step_outputs\": { \"$amazon_stock_growth_2024\": { \"value\": \"In 2024, Amazon's stock price reached an all-time high closing price of $214.10 in November, having risen consistently since the start of 2023. Analysts remain optimistic, with many maintaining a 'Buy' rating and predicting further growth. By the end of 2024, Amazon's stock was expected to continue its upward trend, with projections varying but generally positive. The latest closing stock price as of November 14, 2024, was $211.48, just below the all-time high of $214.10.\", \"summary\": null }, \"$google_stock_growth_2024\": { \"value\": \"As of today, January 23, 2025, Google's stock has experienced an 18% increase since the beginning of the year, starting at $139.56 and trading at $164.74. Analysts predict the stock price to reach $208 by the end of 2024, marking a year-on-year growth rate of 49.03%. The forecast for the end of 2024 is an estimated increase of 18.18% from today's price.\", \"summary\": null }, \"$faster_growth\": { \"value\": \"In 2024, Amazon's stock price growth was positive, reaching an all-time high closing price of $214.10 in November. Google's stock price growth in 2024 was also strong, with a year-on-year growth rate of 49.03% and a forecasted increase of 18.18% by the end of the year.\", \"summary\": null } }, \"final_output\": { \"value\": \"In 2024, Amazon's stock price growth was positive, reaching an all-time high closing price of $214.10 in November. Google's stock price growth in 2024 was also strong, with a year-on-year growth rate of 49.03% and a forecasted increase of 18.18% by the end of the year.\", \"summary\": null } }} Now let's start exploring the developer abstractions Portia offers in more detail!Configure LLM optionsLLM providerAPI keysModel overridesModels for toolsBring your own modelsManage storage optionsManage loggingManage cachingBringing it all together",
      "timestamp": "2025-08-24 06:58:42"
    },
    {
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/",
      "title": "Portia Cloud Tools | Portia AI Docs",
      "content": "Portia Cloud Tools | Portia AI Docs Skip to main content GitHubFind and interact with GitHub repositories. Google CalendarCreate and modify events in Google Calendar. Google DocsFetch documents from Google Docs. Google DriveSearch for files in Google Drive. Google GmailSend and find emails via Google Gmail. Google SheetsFetch spreadsheets from Google Sheets. Microsoft OutlookSend and find emails via Microsoft Outlook. SlackSend messages and search channels and chats in a Slack workspace. ZendeskInteract with Zendesk support tickets, articles, and more.",
      "timestamp": "2025-08-24 06:58:45"
    }
  ],
  "sitemap": {
    "https://docs.portialabs.ai/": {
      "title": "Portia AI Docs",
      "url": "https://docs.portialabs.ai/",
      "discovered_at": "2025-08-24 06:35:27"
    },
    "https://docs.portialabs.ai/evals-steel-thread": {
      "title": "Evals and SteelThread | Portia AI Docs",
      "url": "https://docs.portialabs.ai/evals-steel-thread",
      "discovered_at": "2025-08-24 06:35:30"
    },
    "https://docs.portialabs.ai/security": {
      "title": "Portia cloud security | Portia AI Docs",
      "url": "https://docs.portialabs.ai/security",
      "discovered_at": "2025-08-24 06:35:33"
    },
    "https://docs.portialabs.ai/extend-run-tools": {
      "title": "Extend and run tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/extend-run-tools",
      "discovered_at": "2025-08-24 06:35:35"
    },
    "https://docs.portialabs.ai/portia-tools": {
      "title": "Portia Tool Catalogue | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools",
      "discovered_at": "2025-08-24 06:35:38"
    },
    "https://docs.portialabs.ai/setup-account": {
      "title": "Set up your Portia account | Portia AI Docs",
      "url": "https://docs.portialabs.ai/setup-account",
      "discovered_at": "2025-08-24 06:35:41"
    },
    "https://docs.portialabs.ai/generate-plan": {
      "title": "Generate a plan | Portia AI Docs",
      "url": "https://docs.portialabs.ai/generate-plan",
      "discovered_at": "2025-08-24 06:35:44"
    },
    "https://docs.portialabs.ai/intro-to-tools": {
      "title": "Introduction to tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/intro-to-tools",
      "discovered_at": "2025-08-24 06:35:46"
    },
    "https://docs.portialabs.ai/understand-clarifications": {
      "title": "Understand clarifications | Portia AI Docs",
      "url": "https://docs.portialabs.ai/understand-clarifications",
      "discovered_at": "2025-08-24 06:35:49"
    },
    "https://docs.portialabs.ai/SDK/portia/builder/conditionals": {
      "title": "portia.builder.conditionals | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/builder/conditionals",
      "discovered_at": "2025-08-24 06:35:52"
    },
    "https://docs.portialabs.ai/telemetry": {
      "title": "Telemetry Overview | Portia AI Docs",
      "url": "https://docs.portialabs.ai/telemetry",
      "discovered_at": "2025-08-24 06:35:55"
    },
    "https://docs.portialabs.ai/run-plan": {
      "title": "Run a plan | Portia AI Docs",
      "url": "https://docs.portialabs.ai/run-plan",
      "discovered_at": "2025-08-24 06:35:58"
    },
    "https://docs.portialabs.ai/install": {
      "title": "Install and setup | Portia AI Docs",
      "url": "https://docs.portialabs.ai/install",
      "discovered_at": "2025-08-24 06:36:01"
    },
    "https://docs.portialabs.ai/getting-started-tour": {
      "title": "A tour of our SDK | Portia AI Docs",
      "url": "https://docs.portialabs.ai/getting-started-tour",
      "discovered_at": "2025-08-24 06:36:05"
    },
    "https://docs.portialabs.ai/run-portia-tools": {
      "title": "Run Portia tools with authentication | Portia AI Docs",
      "url": "https://docs.portialabs.ai/run-portia-tools",
      "discovered_at": "2025-08-24 06:36:08"
    },
    "https://docs.portialabs.ai/running-in-production": {
      "title": "Running in production | Portia AI Docs",
      "url": "https://docs.portialabs.ai/running-in-production",
      "discovered_at": "2025-08-24 06:36:10"
    },
    "https://docs.portialabs.ai/generate-and-run-plans": {
      "title": "Generate and run plans | Portia AI Docs",
      "url": "https://docs.portialabs.ai/generate-and-run-plans",
      "discovered_at": "2025-08-24 06:36:13"
    },
    "https://docs.portialabs.ai/handle-auth-clarifications": {
      "title": "Handle auth and clarifications | Portia AI Docs",
      "url": "https://docs.portialabs.ai/handle-auth-clarifications",
      "discovered_at": "2025-08-24 06:36:16"
    },
    "https://docs.portialabs.ai/examples/redoc/": {
      "title": "Portia AI Docs",
      "url": "https://docs.portialabs.ai/examples/redoc/",
      "discovered_at": "2025-08-24 06:36:16"
    },
    "https://docs.portialabs.ai/manage-config": {
      "title": "Manage your config | Portia AI Docs",
      "url": "https://docs.portialabs.ai/manage-config",
      "discovered_at": "2025-08-24 06:36:19"
    },
    "https://docs.portialabs.ai/evals": {
      "title": "📈 Evals | Portia AI Docs",
      "url": "https://docs.portialabs.ai/evals",
      "discovered_at": "2025-08-24 06:36:22"
    },
    "https://docs.portialabs.ai/custom-backend": {
      "title": "Custom backends | Portia AI Docs",
      "url": "https://docs.portialabs.ai/custom-backend",
      "discovered_at": "2025-08-24 06:36:25"
    },
    "https://docs.portialabs.ai/steel-thread-quickstart": {
      "title": "Install and quickstart | Portia AI Docs",
      "url": "https://docs.portialabs.ai/steel-thread-quickstart",
      "discovered_at": "2025-08-24 06:36:28"
    },
    "https://docs.portialabs.ai/streams": {
      "title": "🌊 Streams | Portia AI Docs",
      "url": "https://docs.portialabs.ai/streams",
      "discovered_at": "2025-08-24 06:36:31"
    },
    "https://docs.portialabs.ai/steel-thread-intro": {
      "title": "Introducing Steel Thread | Portia AI Docs",
      "url": "https://docs.portialabs.ai/steel-thread-intro",
      "discovered_at": "2025-08-24 06:36:33"
    },
    "https://docs.portialabs.ai/browser-tools": {
      "title": "Using browser tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/browser-tools",
      "discovered_at": "2025-08-24 06:36:36"
    },
    "https://docs.portialabs.ai/clarifications-in-tools": {
      "title": "Use clarifications in custom tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/clarifications-in-tools",
      "discovered_at": "2025-08-24 06:36:39"
    },
    "https://docs.portialabs.ai/cloud-tool-registry": {
      "title": "Remote MCP and cloud tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/cloud-tool-registry",
      "discovered_at": "2025-08-24 06:36:43"
    },
    "https://docs.portialabs.ai/integrating-tools": {
      "title": "Integrating tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/integrating-tools",
      "discovered_at": "2025-08-24 06:36:46"
    },
    "https://docs.portialabs.ai/add-custom-tools": {
      "title": "Add custom tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/add-custom-tools",
      "discovered_at": "2025-08-24 06:36:49"
    },
    "https://docs.portialabs.ai/mcp-servers": {
      "title": "Integrating an MCP server with the SDK | Portia AI Docs",
      "url": "https://docs.portialabs.ai/mcp-servers",
      "discovered_at": "2025-08-24 06:36:51"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/browserbase": {
      "title": "Browserbase | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/browserbase",
      "discovered_at": "2025-08-24 06:36:54"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail": {
      "title": "Google Gmail Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail",
      "discovered_at": "2025-08-24 06:36:57"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/linear": {
      "title": "Linear | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/linear",
      "discovered_at": "2025-08-24 06:36:59"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-drive/": {
      "title": "Google Drive Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-drive/",
      "discovered_at": "2025-08-24 06:37:02"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/": {
      "title": "Google Gmail Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/",
      "discovered_at": "2025-08-24 06:37:05"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/elevenlabs": {
      "title": "ElevenLabs | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/elevenlabs",
      "discovered_at": "2025-08-24 06:37:07"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/minimax": {
      "title": "MiniMax | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/minimax",
      "discovered_at": "2025-08-24 06:37:10"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/intercom": {
      "title": "Intercom | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/intercom",
      "discovered_at": "2025-08-24 06:37:13"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/yepcode": {
      "title": "YepCode | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/yepcode",
      "discovered_at": "2025-08-24 06:37:16"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/shopify-dev": {
      "title": "Shopify Dev | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/shopify-dev",
      "discovered_at": "2025-08-24 06:37:18"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/aws-documentation": {
      "title": "AWS Documentation | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/aws-documentation",
      "discovered_at": "2025-08-24 06:37:21"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/": {
      "title": "Zendesk Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/",
      "discovered_at": "2025-08-24 06:37:24"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/browser": {
      "title": "Open Source - Browser Use | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/browser",
      "discovered_at": "2025-08-24 06:37:26"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/file-writer": {
      "title": "Open Source - File Writer | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/file-writer",
      "discovered_at": "2025-08-24 06:37:29"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/llm": {
      "title": "Open Source - LLM | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/llm",
      "discovered_at": "2025-08-24 06:37:32"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/chargebee": {
      "title": "Chargebee | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/chargebee",
      "discovered_at": "2025-08-24 06:37:35"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/pdf-reader": {
      "title": "Open Source - PDF Reader | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/pdf-reader",
      "discovered_at": "2025-08-24 06:37:37"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/": {
      "title": "Google Calendar Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/",
      "discovered_at": "2025-08-24 06:37:40"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/deepwiki": {
      "title": "DeepWiki | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/deepwiki",
      "discovered_at": "2025-08-24 06:37:43"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/monday.com": {
      "title": "Monday.com | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/monday.com",
      "discovered_at": "2025-08-24 06:37:46"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/gcp-cloud-run": {
      "title": "GCP Cloud Run | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/gcp-cloud-run",
      "discovered_at": "2025-08-24 06:37:48"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/mongodb": {
      "title": "MongoDB | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/mongodb",
      "discovered_at": "2025-08-24 06:37:51"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/basic-memory": {
      "title": "Basic Memory | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/basic-memory",
      "discovered_at": "2025-08-24 06:37:54"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/shopify": {
      "title": "Shopify | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/shopify",
      "discovered_at": "2025-08-24 06:37:56"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/wix": {
      "title": "Wix | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/wix",
      "discovered_at": "2025-08-24 06:37:59"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/semgrep": {
      "title": "Semgrep | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/semgrep",
      "discovered_at": "2025-08-24 06:38:02"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/make": {
      "title": "Make | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/make",
      "discovered_at": "2025-08-24 06:38:04"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-sheets/": {
      "title": "Google Sheets Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-sheets/",
      "discovered_at": "2025-08-24 06:38:07"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/biomcp": {
      "title": "BioMCP | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/biomcp",
      "discovered_at": "2025-08-24 06:38:10"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/search": {
      "title": "Open Source - Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/search",
      "discovered_at": "2025-08-24 06:38:12"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/netlify": {
      "title": "Netlify | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/netlify",
      "discovered_at": "2025-08-24 06:38:15"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/github": {
      "title": "GitHub Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github",
      "discovered_at": "2025-08-24 06:38:18"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/asana": {
      "title": "Asana | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/asana",
      "discovered_at": "2025-08-24 06:38:21"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/supabase": {
      "title": "Supabase | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/supabase",
      "discovered_at": "2025-08-24 06:38:23"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/apify": {
      "title": "Apify Actors | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/apify",
      "discovered_at": "2025-08-24 06:38:26"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/github/": {
      "title": "GitHub Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github/",
      "discovered_at": "2025-08-24 06:38:29"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/crawl": {
      "title": "Open Source - Crawl | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/crawl",
      "discovered_at": "2025-08-24 06:38:32"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/hyperbrowser": {
      "title": "Hyperbrowser | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/hyperbrowser",
      "discovered_at": "2025-08-24 06:38:34"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/stripe": {
      "title": "Stripe | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/stripe",
      "discovered_at": "2025-08-24 06:38:37"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/xero": {
      "title": "Xero | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/xero",
      "discovered_at": "2025-08-24 06:38:40"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/image-understanding": {
      "title": "Open Source - Image Understanding | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/image-understanding",
      "discovered_at": "2025-08-24 06:38:43"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/weather": {
      "title": "Open Source - Weather | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/weather",
      "discovered_at": "2025-08-24 06:38:45"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-drive": {
      "title": "Google Drive Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-drive",
      "discovered_at": "2025-08-24 06:38:48"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/supermemory": {
      "title": "Supermemory | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/supermemory",
      "discovered_at": "2025-08-24 06:38:51"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/chroma": {
      "title": "Chroma | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/chroma",
      "discovered_at": "2025-08-24 06:38:53"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk": {
      "title": "Zendesk Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk",
      "discovered_at": "2025-08-24 06:38:56"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs/": {
      "title": "Google Docs Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs/",
      "discovered_at": "2025-08-24 06:38:59"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/playwright": {
      "title": "Playwright | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/playwright",
      "discovered_at": "2025-08-24 06:39:02"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/grafana": {
      "title": "Grafana | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/grafana",
      "discovered_at": "2025-08-24 06:39:04"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/qdrant": {
      "title": "Qdrant | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/qdrant",
      "discovered_at": "2025-08-24 06:39:07"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/hubspot": {
      "title": "HubSpot | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/hubspot",
      "discovered_at": "2025-08-24 06:39:10"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/github": {
      "title": "GitHub | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/github",
      "discovered_at": "2025-08-24 06:39:12"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/extract": {
      "title": "Open Source - Extract | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/extract",
      "discovered_at": "2025-08-24 06:39:15"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/dbhub": {
      "title": "DBHub | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/dbhub",
      "discovered_at": "2025-08-24 06:39:18"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook": {
      "title": "Microsoft Outlook Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook",
      "discovered_at": "2025-08-24 06:39:21"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/notion": {
      "title": "Notion | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/notion",
      "discovered_at": "2025-08-24 06:39:23"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/firecrawl": {
      "title": "Firecrawl | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/firecrawl",
      "discovered_at": "2025-08-24 06:39:26"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/map-website": {
      "title": "Open Source - Map Website | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/map-website",
      "discovered_at": "2025-08-24 06:39:29"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-sheets": {
      "title": "Google Sheets Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-sheets",
      "discovered_at": "2025-08-24 06:39:32"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/": {
      "title": "Microsoft Outlook Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/",
      "discovered_at": "2025-08-24 06:39:34"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/bright-data": {
      "title": "Bright Data | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/bright-data",
      "discovered_at": "2025-08-24 06:39:37"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/jetbrains-ide": {
      "title": "JetBrains IDE | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/jetbrains-ide",
      "discovered_at": "2025-08-24 06:39:40"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar": {
      "title": "Google Calendar Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar",
      "discovered_at": "2025-08-24 06:39:42"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/invideo": {
      "title": "Invideo | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/invideo",
      "discovered_at": "2025-08-24 06:39:45"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/slack": {
      "title": "Slack Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack",
      "discovered_at": "2025-08-24 06:39:48"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/": {
      "title": "Open Source Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/",
      "discovered_at": "2025-08-24 06:39:51"
    },
    "https://docs.portialabs.ai/portia-tools/": {
      "title": "Portia Tool Catalogue | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/",
      "discovered_at": "2025-08-24 06:39:53"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/webflow": {
      "title": "Webflow | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/webflow",
      "discovered_at": "2025-08-24 06:39:56"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs": {
      "title": "Google Docs Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs",
      "discovered_at": "2025-08-24 06:39:59"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/perplexity": {
      "title": "Perplexity | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/perplexity",
      "discovered_at": "2025-08-24 06:40:01"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/": {
      "title": "Remote MCP Servers | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/",
      "discovered_at": "2025-08-24 06:40:04"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/cloudflare": {
      "title": "Cloudflare | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/cloudflare",
      "discovered_at": "2025-08-24 06:40:07"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/sentry": {
      "title": "Sentry | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/sentry",
      "discovered_at": "2025-08-24 06:40:09"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/": {
      "title": "Local MCP Servers | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/",
      "discovered_at": "2025-08-24 06:40:12"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/posthog": {
      "title": "Posthog | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/posthog",
      "discovered_at": "2025-08-24 06:40:14"
    },
    "https://docs.portialabs.ai/portia-tools/open-source/file-reader": {
      "title": "Open Source - File Reader | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/open-source/file-reader",
      "discovered_at": "2025-08-24 06:40:17"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/hugging-face": {
      "title": "Hugging Face | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/hugging-face",
      "discovered_at": "2025-08-24 06:40:20"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/twilio": {
      "title": "Twilio | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/twilio",
      "discovered_at": "2025-08-24 06:40:23"
    },
    "https://docs.portialabs.ai/portia-tools/local-mcp/aws-cost-analysis": {
      "title": "AWS Cost Analysis | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/local-mcp/aws-cost-analysis",
      "discovered_at": "2025-08-24 06:40:25"
    },
    "https://docs.portialabs.ai/portia-tools/remote-mcp/square": {
      "title": "Square | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/remote-mcp/square",
      "discovered_at": "2025-08-24 06:40:29"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/": {
      "title": "Slack Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/",
      "discovered_at": "2025-08-24 06:40:32"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/": {
      "title": "Portia Cloud Tools | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/",
      "discovered_at": "2025-08-24 06:40:34"
    },
    "https://docs.portialabs.ai/build-plan": {
      "title": "Build a plan manually | Portia AI Docs",
      "url": "https://docs.portialabs.ai/build-plan",
      "discovered_at": "2025-08-24 06:40:37"
    },
    "https://docs.portialabs.ai/SDK/portia/plan": {
      "title": "portia.plan | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/plan",
      "discovered_at": "2025-08-24 06:40:40"
    },
    "https://docs.portialabs.ai/store-retrieve-plan-runs": {
      "title": "Plan run states on Portia cloud | Portia AI Docs",
      "url": "https://docs.portialabs.ai/store-retrieve-plan-runs",
      "discovered_at": "2025-08-24 06:40:42"
    },
    "https://docs.portialabs.ai/SDK/portia/": {
      "title": "portia.portia | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/",
      "discovered_at": "2025-08-24 06:40:45"
    },
    "https://docs.portialabs.ai/inputs-outputs": {
      "title": "Inputs and Outputs | Portia AI Docs",
      "url": "https://docs.portialabs.ai/inputs-outputs",
      "discovered_at": "2025-08-24 06:40:48"
    },
    "https://docs.portialabs.ai/manage-end-users": {
      "title": "Managing end users | Portia AI Docs",
      "url": "https://docs.portialabs.ai/manage-end-users",
      "discovered_at": "2025-08-24 06:40:51"
    },
    "https://docs.portialabs.ai/SDK/portia/tool": {
      "title": "portia.tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/tool",
      "discovered_at": "2025-08-24 06:40:54"
    },
    "https://docs.portialabs.ai/SDK/portia/clarification": {
      "title": "portia.clarification | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/clarification",
      "discovered_at": "2025-08-24 06:40:56"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_hooks": {
      "title": "portia.execution_hooks | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_hooks",
      "discovered_at": "2025-08-24 06:40:59"
    },
    "https://docs.portialabs.ai/SDK/portia/tool_decorator": {
      "title": "portia.tool_decorator | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/tool_decorator",
      "discovered_at": "2025-08-24 06:41:02"
    },
    "https://docs.portialabs.ai/SDK/portia/tool_wrapper": {
      "title": "portia.tool_wrapper | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/tool_wrapper",
      "discovered_at": "2025-08-24 06:41:05"
    },
    "https://docs.portialabs.ai/SDK/portia/builder/reference": {
      "title": "portia.builder.reference | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/builder/reference",
      "discovered_at": "2025-08-24 06:41:08"
    },
    "https://docs.portialabs.ai/SDK/portia/builder/plan_v2": {
      "title": "portia.builder.plan_v2 | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/builder/plan_v2",
      "discovered_at": "2025-08-24 06:41:10"
    },
    "https://docs.portialabs.ai/SDK/portia/errors": {
      "title": "portia.errors | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/errors",
      "discovered_at": "2025-08-24 06:41:13"
    },
    "https://docs.portialabs.ai/SDK/portia/mcp_session": {
      "title": "portia.mcp_session | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/mcp_session",
      "discovered_at": "2025-08-24 06:41:16"
    },
    "https://docs.portialabs.ai/SDK/portia/end_user": {
      "title": "portia.end_user | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/end_user",
      "discovered_at": "2025-08-24 06:41:19"
    },
    "https://docs.portialabs.ai/SDK/portia/tool_call": {
      "title": "portia.tool_call | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/tool_call",
      "discovered_at": "2025-08-24 06:41:21"
    },
    "https://docs.portialabs.ai/SDK/portia/token_check": {
      "title": "portia.token_check | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/token_check",
      "discovered_at": "2025-08-24 06:41:24"
    },
    "https://docs.portialabs.ai/SDK/portia/gemini_langsmith_wrapper": {
      "title": "portia.gemini_langsmith_wrapper | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/gemini_langsmith_wrapper",
      "discovered_at": "2025-08-24 06:41:27"
    },
    "https://docs.portialabs.ai/SDK/portia/config": {
      "title": "portia.config | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/config",
      "discovered_at": "2025-08-24 06:41:30"
    },
    "https://docs.portialabs.ai/SDK/portia/builder/plan_builder_v2": {
      "title": "portia.builder.plan_builder_v2 | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/builder/plan_builder_v2",
      "discovered_at": "2025-08-24 06:41:33"
    },
    "https://docs.portialabs.ai/SDK/portia/version": {
      "title": "portia.version | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/version",
      "discovered_at": "2025-08-24 06:41:36"
    },
    "https://docs.portialabs.ai/SDK/portia/logger": {
      "title": "portia.logger | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/logger",
      "discovered_at": "2025-08-24 06:41:38"
    },
    "https://docs.portialabs.ai/SDK/portia/plan_run": {
      "title": "portia.plan_run | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/plan_run",
      "discovered_at": "2025-08-24 06:41:41"
    },
    "https://docs.portialabs.ai/SDK/portia/builder/step_v2": {
      "title": "portia.builder.step_v2 | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/builder/step_v2",
      "discovered_at": "2025-08-24 06:41:44"
    },
    "https://docs.portialabs.ai/SDK/portia/storage": {
      "title": "portia.storage | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/storage",
      "discovered_at": "2025-08-24 06:41:47"
    },
    "https://docs.portialabs.ai/SDK/portia/clarification_handler": {
      "title": "portia.clarification_handler | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/clarification_handler",
      "discovered_at": "2025-08-24 06:41:50"
    },
    "https://docs.portialabs.ai/SDK/portia/model": {
      "title": "portia.model | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/model",
      "discovered_at": "2025-08-24 06:41:53"
    },
    "https://docs.portialabs.ai/SDK/portia/tool_registry": {
      "title": "portia.tool_registry | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/tool_registry",
      "discovered_at": "2025-08-24 06:41:56"
    },
    "https://docs.portialabs.ai/SDK/portia/cloud": {
      "title": "portia.cloud | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/cloud",
      "discovered_at": "2025-08-24 06:41:58"
    },
    "https://docs.portialabs.ai/agent-memory": {
      "title": "Using agent memory | Portia AI Docs",
      "url": "https://docs.portialabs.ai/agent-memory",
      "discovered_at": "2025-08-24 06:42:01"
    },
    "https://docs.portialabs.ai/agent-observability": {
      "title": "Agent observability | Portia AI Docs",
      "url": "https://docs.portialabs.ai/agent-observability",
      "discovered_at": "2025-08-24 06:42:04"
    },
    "https://docs.portialabs.ai/execution-hooks": {
      "title": "Execution hooks | Portia AI Docs",
      "url": "https://docs.portialabs.ai/execution-hooks",
      "discovered_at": "2025-08-24 06:42:07"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/image_understanding_tool": {
      "title": "portia.open_source_tools.image_understanding_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/image_understanding_tool",
      "discovered_at": "2025-08-24 06:42:10"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/llm_tool": {
      "title": "portia.open_source_tools.llm_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/llm_tool",
      "discovered_at": "2025-08-24 06:42:12"
    },
    "https://docs.portialabs.ai/streams-results": {
      "title": "Visualise Stream results | Portia AI Docs",
      "url": "https://docs.portialabs.ai/streams-results",
      "discovered_at": "2025-08-24 06:42:15"
    },
    "https://docs.portialabs.ai/evals-overview": {
      "title": "Overview and basic usage | Portia AI Docs",
      "url": "https://docs.portialabs.ai/evals-overview",
      "discovered_at": "2025-08-24 06:42:18"
    },
    "https://docs.portialabs.ai/evals-custom-evaluators": {
      "title": "Custom evaluators | Portia AI Docs",
      "url": "https://docs.portialabs.ai/evals-custom-evaluators",
      "discovered_at": "2025-08-24 06:42:24"
    },
    "https://docs.portialabs.ai/evals-tool-stubbing": {
      "title": "Tool stubbing | Portia AI Docs",
      "url": "https://docs.portialabs.ai/evals-tool-stubbing",
      "discovered_at": "2025-08-24 06:42:27"
    },
    "https://docs.portialabs.ai/evals-results": {
      "title": "Visualise Eval results | Portia AI Docs",
      "url": "https://docs.portialabs.ai/evals-results",
      "discovered_at": "2025-08-24 06:42:30"
    },
    "https://docs.portialabs.ai/streams-custom-evaluators": {
      "title": "Custom Stream evaluators | Portia AI Docs",
      "url": "https://docs.portialabs.ai/streams-custom-evaluators",
      "discovered_at": "2025-08-24 06:42:32"
    },
    "https://docs.portialabs.ai/streams-overview": {
      "title": "Overview and basic usage | Portia AI Docs",
      "url": "https://docs.portialabs.ai/streams-overview",
      "discovered_at": "2025-08-24 06:42:42"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/browser_tool": {
      "title": "portia.open_source_tools.browser_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/browser_tool",
      "discovered_at": "2025-08-24 06:42:45"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-send-email": {
      "title": "Google Gmail - Gmail: Send | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-send-email",
      "discovered_at": "2025-08-24 06:42:47"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-search-email": {
      "title": "Google Gmail - Gmail: Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-search-email",
      "discovered_at": "2025-08-24 06:42:50"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-send-draft-email": {
      "title": "Google Gmail - Gmail: Send Draft | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-send-draft-email",
      "discovered_at": "2025-08-24 06:42:53"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-draft-email": {
      "title": "Google Gmail - Gmail: Draft | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-gmail/gmail-draft-email",
      "discovered_at": "2025-08-24 06:42:56"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-drive/drive-search": {
      "title": "Google Drive - Drive: Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-drive/drive-search",
      "discovered_at": "2025-08-24 06:42:59"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs/docs-get-structured-document": {
      "title": "Google Docs - Docs: Get Structured Document | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs/docs-get-structured-document",
      "discovered_at": "2025-08-24 06:43:01"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-users-for-group": {
      "title": "Zendesk - Groups: List Users | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-users-for-group",
      "discovered_at": "2025-08-24 06:43:04"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/update-ticket": {
      "title": "Zendesk - Tickets: Update | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/update-ticket",
      "discovered_at": "2025-08-24 06:43:07"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-organizations": {
      "title": "Zendesk - Organizations: Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-organizations",
      "discovered_at": "2025-08-24 06:43:10"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-request": {
      "title": "Zendesk - Requests: Show | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-request",
      "discovered_at": "2025-08-24 06:43:13"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/count-ticket-comments": {
      "title": "Zendesk - Tickets: Count Comments | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/count-ticket-comments",
      "discovered_at": "2025-08-24 06:43:16"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-request-comment": {
      "title": "Zendesk - Request Comments: Show | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-request-comment",
      "discovered_at": "2025-08-24 06:43:19"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-group": {
      "title": "Zendesk - Groups: Show | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-group",
      "discovered_at": "2025-08-24 06:43:22"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-users": {
      "title": "Zendesk - Users: Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-users",
      "discovered_at": "2025-08-24 06:43:25"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-post": {
      "title": "Zendesk - Posts: Show | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-post",
      "discovered_at": "2025-08-24 06:43:27"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-articles-by-section": {
      "title": "Zendesk - Sections: List Articles | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-articles-by-section",
      "discovered_at": "2025-08-24 06:43:30"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-ticket-metrics": {
      "title": "Zendesk - Tickets: Show Metrics | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-ticket-metrics",
      "discovered_at": "2025-08-24 06:43:33"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/list-users": {
      "title": "Slack - Users: List | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/list-users",
      "discovered_at": "2025-08-24 06:43:36"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-groups": {
      "title": "Zendesk - Groups: Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-groups",
      "discovered_at": "2025-08-24 06:43:39"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/article-search": {
      "title": "Zendesk - Articles: Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/article-search",
      "discovered_at": "2025-08-24 06:43:42"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-groups-for-user": {
      "title": "Zendesk - Groups: List for User | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-groups-for-user",
      "discovered_at": "2025-08-24 06:43:44"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/create-ticket": {
      "title": "Zendesk - Tickets: Create | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/create-ticket",
      "discovered_at": "2025-08-24 06:43:47"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-tickets": {
      "title": "Zendesk - Tickets: Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-tickets",
      "discovered_at": "2025-08-24 06:43:50"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-requests": {
      "title": "Zendesk - Requests: Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/search-requests",
      "discovered_at": "2025-08-24 06:43:53"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/count-tickets": {
      "title": "Zendesk - Tickets: Count | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/count-tickets",
      "discovered_at": "2025-08-24 06:43:56"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/create-article-comments": {
      "title": "Zendesk - Articles: Create Comments | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/create-article-comments",
      "discovered_at": "2025-08-24 06:43:59"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-article-comments": {
      "title": "Zendesk - Articles: List Comments | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-article-comments",
      "discovered_at": "2025-08-24 06:44:01"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-articles": {
      "title": "Zendesk - Articles: List | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-articles",
      "discovered_at": "2025-08-24 06:44:04"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-article": {
      "title": "Zendesk - Articles: Show | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-article",
      "discovered_at": "2025-08-24 06:44:07"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-request-comments": {
      "title": "Zendesk - Request Comments: List | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-request-comments",
      "discovered_at": "2025-08-24 06:44:09"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-ticket": {
      "title": "Zendesk - Tickets: Show | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-ticket",
      "discovered_at": "2025-08-24 06:44:12"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-user": {
      "title": "Zendesk - Users: Show | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-user",
      "discovered_at": "2025-08-24 06:44:15"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-post-comments": {
      "title": "Zendesk - Posts: List Comments | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-post-comments",
      "discovered_at": "2025-08-24 06:44:18"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-section": {
      "title": "Zendesk - Sections: Show | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-section",
      "discovered_at": "2025-08-24 06:44:21"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-ticket-comments": {
      "title": "Zendesk - Tickets: List Comments | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/list-ticket-comments",
      "discovered_at": "2025-08-24 06:44:24"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-organization": {
      "title": "Zendesk - Organizations: Show | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/zendesk/show-organization",
      "discovered_at": "2025-08-24 06:44:27"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-delete-event": {
      "title": "Google Calendar - Calendar: Delete Event | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-delete-event",
      "discovered_at": "2025-08-24 06:44:30"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-check-availability": {
      "title": "Google Calendar - Calendar: Check Availability | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-check-availability",
      "discovered_at": "2025-08-24 06:44:32"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-get-events-by-properties": {
      "title": "Google Calendar - Calendar: Get Events By Properties | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-get-events-by-properties",
      "discovered_at": "2025-08-24 06:44:36"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-modify-event": {
      "title": "Google Calendar - Calendar: Modify Event | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-modify-event",
      "discovered_at": "2025-08-24 06:44:38"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-get-event-details": {
      "title": "Google Calendar - Calendar: Get Event | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-get-event-details",
      "discovered_at": "2025-08-24 06:44:41"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/github/star-repo": {
      "title": "GitHub - Repository: Star | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github/star-repo",
      "discovered_at": "2025-08-24 06:44:44"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-create-event": {
      "title": "Google Calendar - Calendar: Create Event | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-calendar/calendar-create-event",
      "discovered_at": "2025-08-24 06:44:46"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-sheets/sheets-get-spreadsheet": {
      "title": "Google Sheets - Sheets: Get Spreadsheet | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-sheets/sheets-get-spreadsheet",
      "discovered_at": "2025-08-24 06:44:49"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/github/list-repo-issues": {
      "title": "GitHub - Issue: List | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github/list-repo-issues",
      "discovered_at": "2025-08-24 06:44:52"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/github/list-repos": {
      "title": "GitHub - Repository: List | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github/list-repos",
      "discovered_at": "2025-08-24 06:44:55"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/github/search-repos": {
      "title": "GitHub - Repository: Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/github/search-repos",
      "discovered_at": "2025-08-24 06:44:57"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs/docs-get-document": {
      "title": "Google Docs - Docs: Get Document | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/google-docs/docs-get-document",
      "discovered_at": "2025-08-24 06:45:00"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-send-email": {
      "title": "Microsoft Outlook - Outlook: Send | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-send-email",
      "discovered_at": "2025-08-24 06:45:03"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-search-email": {
      "title": "Microsoft Outlook - Outlook: Search | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-search-email",
      "discovered_at": "2025-08-24 06:45:06"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-draft-email": {
      "title": "Microsoft Outlook - Outlook: Draft | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-draft-email",
      "discovered_at": "2025-08-24 06:45:09"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-send-draft-email": {
      "title": "Microsoft Outlook - Outlook: Send Draft | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/microsoft-outlook/outlook-send-draft-email",
      "discovered_at": "2025-08-24 06:45:11"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/list-conversations": {
      "title": "Slack - Conversation: List | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/list-conversations",
      "discovered_at": "2025-08-24 06:45:14"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/send-message": {
      "title": "Slack - Message: Send | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/send-message",
      "discovered_at": "2025-08-24 06:45:17"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/get-conversation": {
      "title": "Slack - Conversation: Get History | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/get-conversation",
      "discovered_at": "2025-08-24 06:45:19"
    },
    "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/find-message": {
      "title": "Slack - Message: Find | Portia AI Docs",
      "url": "https://docs.portialabs.ai/portia-tools/portia-cloud/slack/find-message",
      "discovered_at": "2025-08-24 06:45:22"
    },
    "https://docs.portialabs.ai/SDK/portia/telemetry/views": {
      "title": "portia.telemetry.views | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/telemetry/views",
      "discovered_at": "2025-08-24 06:45:25"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/utils/final_output_summarizer": {
      "title": "portia.execution_agents.utils.final_output_summarizer | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/utils/final_output_summarizer",
      "discovered_at": "2025-08-24 06:45:28"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/crawl_tool": {
      "title": "portia.open_source_tools.crawl_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/crawl_tool",
      "discovered_at": "2025-08-24 06:45:31"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/local_file_reader_tool": {
      "title": "portia.open_source_tools.local_file_reader_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/local_file_reader_tool",
      "discovered_at": "2025-08-24 06:45:34"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/local_file_writer_tool": {
      "title": "portia.open_source_tools.local_file_writer_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/local_file_writer_tool",
      "discovered_at": "2025-08-24 06:45:38"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/weather": {
      "title": "portia.open_source_tools.weather | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/weather",
      "discovered_at": "2025-08-24 06:45:40"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/map_tool": {
      "title": "portia.open_source_tools.map_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/map_tool",
      "discovered_at": "2025-08-24 06:45:43"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/calculator_tool": {
      "title": "portia.open_source_tools.calculator_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/calculator_tool",
      "discovered_at": "2025-08-24 06:45:46"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/search_tool": {
      "title": "portia.open_source_tools.search_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/search_tool",
      "discovered_at": "2025-08-24 06:45:49"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/extract_tool": {
      "title": "portia.open_source_tools.extract_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/extract_tool",
      "discovered_at": "2025-08-24 06:45:52"
    },
    "https://docs.portialabs.ai/SDK/portia/open_source_tools/pdf_reader_tool": {
      "title": "portia.open_source_tools.pdf_reader_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/open_source_tools/pdf_reader_tool",
      "discovered_at": "2025-08-24 06:45:55"
    },
    "https://docs.portialabs.ai/SDK/portia/introspection_agents/introspection_agent": {
      "title": "portia.introspection_agents.introspection_agent | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/introspection_agents/introspection_agent",
      "discovered_at": "2025-08-24 06:45:58"
    },
    "https://docs.portialabs.ai/SDK/portia/telemetry/telemetry_service": {
      "title": "portia.telemetry.telemetry_service | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/telemetry/telemetry_service",
      "discovered_at": "2025-08-24 06:46:01"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/clarification_tool": {
      "title": "portia.execution_agents.clarification_tool | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/clarification_tool",
      "discovered_at": "2025-08-24 06:46:03"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/memory_extraction": {
      "title": "portia.execution_agents.memory_extraction | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/memory_extraction",
      "discovered_at": "2025-08-24 06:46:06"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/execution_utils": {
      "title": "portia.execution_agents.execution_utils | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/execution_utils",
      "discovered_at": "2025-08-24 06:46:09"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/base_execution_agent": {
      "title": "portia.execution_agents.base_execution_agent | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/base_execution_agent",
      "discovered_at": "2025-08-24 06:46:11"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/context": {
      "title": "portia.execution_agents.context | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/context",
      "discovered_at": "2025-08-24 06:46:14"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/output": {
      "title": "portia.execution_agents.output | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/output",
      "discovered_at": "2025-08-24 06:46:17"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/conditional_evaluation_agent": {
      "title": "portia.execution_agents.conditional_evaluation_agent | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/conditional_evaluation_agent",
      "discovered_at": "2025-08-24 06:46:20"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/one_shot_agent": {
      "title": "portia.execution_agents.one_shot_agent | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/one_shot_agent",
      "discovered_at": "2025-08-24 06:46:23"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/utils/step_summarizer": {
      "title": "portia.execution_agents.utils.step_summarizer | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/utils/step_summarizer",
      "discovered_at": "2025-08-24 06:46:26"
    },
    "https://docs.portialabs.ai/SDK/portia/execution_agents/default_execution_agent": {
      "title": "portia.execution_agents.default_execution_agent | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/execution_agents/default_execution_agent",
      "discovered_at": "2025-08-24 06:46:29"
    },
    "https://docs.portialabs.ai/SDK/portia/planning_agents/base_planning_agent": {
      "title": "portia.planning_agents.base_planning_agent | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/planning_agents/base_planning_agent",
      "discovered_at": "2025-08-24 06:46:32"
    },
    "https://docs.portialabs.ai/SDK/portia/introspection_agents/default_introspection_agent": {
      "title": "portia.introspection_agents.default_introspection_agent | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/introspection_agents/default_introspection_agent",
      "discovered_at": "2025-08-24 06:46:34"
    },
    "https://docs.portialabs.ai/SDK/portia/planning_agents/default_planning_agent": {
      "title": "portia.planning_agents.default_planning_agent | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/planning_agents/default_planning_agent",
      "discovered_at": "2025-08-24 06:46:37"
    },
    "https://docs.portialabs.ai/SDK/portia/planning_agents/context": {
      "title": "portia.planning_agents.context | Portia AI Docs",
      "url": "https://docs.portialabs.ai/SDK/portia/planning_agents/context",
      "discovered_at": "2025-08-24 06:46:40"
    }
  }
}